
@online{haris_iqbal_plotneuralnet_2020,
	title = {{PlotNeuralNet}},
	url = {https://github.com/HarisIqbal88/PlotNeuralNet},
	shorttitle = {{HarisIqbal}88/{PlotNeuralNet}},
	abstract = {Latex code for making neural networks diagrams.},
	titleaddon = {{GitHub}},
	author = {{Haris Iqbal}},
	urldate = {2024-12-10},
	date = {2020-11-06},
	langid = {english},
}

@article{duQiandaoEar22HighqualityNoise2024,
	title = {{QiandaoEar}22: a high-quality noise dataset for identifying specific ship from multiple underwater acoustic targets using ship-radiated noise},
	volume = {2024},
	issn = {1687-6180},
	url = {https://asp-eurasipjournals.springeropen.com/articles/10.1186/s13634-024-01181-9},
	doi = {10.1186/s13634-024-01181-9},
	shorttitle = {{QiandaoEar}22},
	pages = {96},
	number = {1},
	journaltitle = {{EURASIP} Journal on Advances in Signal Processing},
	shortjournal = {{EURASIP} J. Adv. Signal Process.},
	author = {Du, Xiaoyang and Hong, Feng},
	urldate = {2024-12-09},
	date = {2024-11-08},
	langid = {english},
	note = {0 citations (Crossref) [2024-12-09]},
}

@inproceedings{liu_using_2018,
	title = {Using Shifted Real Spectrum Mask as Training Target for Supervised Speech Separation},
	url = {https://www.isca-archive.org/interspeech_2018/liu18e_interspeech.html},
	doi = {10.21437/Interspeech.2018-1650},
	eventtitle = {Interspeech 2018},
	pages = {1151--1155},
	booktitle = {Interspeech 2018},
	publisher = {{ISCA}},
	author = {Liu, Yun and Zhang, Hui and Zhang, Xueliang},
	urldate = {2024-12-05},
	date = {2018-09-02},
	langid = {english},
	note = {3 citations (Crossref) [2024-12-05]},
}

@inproceedings{maas_rectifier_2013,
	title = {Rectifier Nonlinearities Improve Neural Network Acoustic Models},
	url = {https://www.semanticscholar.org/paper/Rectifier-Nonlinearities-Improve-Neural-Network-Maas/367f2c63a6f6a10b3b64b8729d601e69337ee3cc},
	abstract = {Deep neural network acoustic models produce substantial gains in large vocabulary continuous speech recognition systems. Emerging work with rectiﬁed linear ({ReL}) hidden units demonstrates additional gains in ﬁnal system performance relative to more commonly used sigmoidal nonlinearities. In this work, we explore the use of deep rectiﬁer networks as acoustic models for the 300 hour Switchboard conversational speech recognition task. Using simple training procedures without pretraining, networks with rectiﬁer nonlinearities produce 2\% absolute reductions in word error rates over their sigmoidal counterparts. We analyze hidden layer representations to quantify diﬀerences in how {ReL} units encode inputs as compared to sigmoidal units. Finally, we evaluate a variant of the {ReL} unit with a gradient more amenable to optimization in an attempt to further improve deep rectiﬁer networks.},
	author = {Maas, Andrew L.},
	urldate = {2024-12-03},
	date = {2013},
}

@misc{he_delving_2015,
	title = {Delving Deep into Rectifiers: Surpassing Human-Level Performance on {ImageNet} Classification},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/1502.01852},
	doi = {10.48550/ARXIV.1502.01852},
	shorttitle = {Delving Deep into Rectifiers},
	abstract = {Rectified activation units (rectifiers) are essential for state-of-the-art neural networks. In this work, we study rectifier neural networks for image classification from two aspects. First, we propose a Parametric Rectified Linear Unit ({PReLU}) that generalizes the traditional rectified unit. {PReLU} improves model fitting with nearly zero extra computational cost and little overfitting risk. Second, we derive a robust initialization method that particularly considers the rectifier nonlinearities. This method enables us to train extremely deep rectified models directly from scratch and to investigate deeper or wider network architectures. Based on our {PReLU} networks ({PReLU}-nets), we achieve 4.94\% top-5 test error on the {ImageNet} 2012 classification dataset. This is a 26\% relative improvement over the {ILSVRC} 2014 winner ({GoogLeNet}, 6.66\%). To our knowledge, our result is the first to surpass human-level performance (5.1\%, Russakovsky et al.) on this visual recognition challenge.},
	publisher = {{arXiv}},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	urldate = {2024-12-03},
	date = {2015},
	note = {Version Number: 1},
	keywords = {Artificial Intelligence (cs.{AI}), Computer Vision and Pattern Recognition (cs.{CV}), {FOS}: Computer and information sciences, Machine Learning (cs.{LG})},
}

@misc{mao_image_2016,
	title = {Image Restoration Using Very Deep Convolutional Encoder-Decoder Networks with Symmetric Skip Connections},
	url = {http://arxiv.org/abs/1603.09056},
	doi = {10.48550/arXiv.1603.09056},
	abstract = {In this paper, we propose a very deep fully convolutional encoding-decoding framework for image restoration such as denoising and super-resolution. The network is composed of multiple layers of convolution and de-convolution operators, learning end-to-end mappings from corrupted images to the original ones. The convolutional layers act as the feature extractor, which capture the abstraction of image contents while eliminating noises/corruptions. De-convolutional layers are then used to recover the image details. We propose to symmetrically link convolutional and de-convolutional layers with skip-layer connections, with which the training converges much faster and attains a higher-quality local optimum. First, The skip connections allow the signal to be back-propagated to bottom layers directly, and thus tackles the problem of gradient vanishing, making training deep networks easier and achieving restoration performance gains consequently. Second, these skip connections pass image details from convolutional layers to de-convolutional layers, which is beneficial in recovering the original image. Significantly, with the large capacity, we can handle different levels of noises using a single model. Experimental results show that our network achieves better performance than all previously reported state-of-the-art methods.},
	number = {{arXiv}:1603.09056},
	publisher = {{arXiv}},
	author = {Mao, Xiao-Jiao and Shen, Chunhua and Yang, Yu-Bin},
	urldate = {2024-12-03},
	date = {2016-09-01},
	eprinttype = {arxiv},
	eprint = {1603.09056},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@incollection{brito-loeza_novel_2020,
	location = {Cham},
	title = {A Novel Feature Extraction Model to Enhance Underwater Image Classification},
	volume = {1187},
	isbn = {978-3-030-43363-5},
	url = {http://link.springer.com/10.1007/978-3-030-43364-2_8},
	pages = {78--91},
	booktitle = {Intelligent Computing Systems},
	publisher = {Springer International Publishing},
	author = {Irfan, Muhammad and Zheng, Jiangbin and Iqbal, Muhammad and Arif, Muhammad Hassan},
	editor = {Brito-Loeza, Carlos and Espinosa-Romero, Arturo and Martin-Gonzalez, Anabel and Safi, Asad},
	urldate = {2024-08-14},
	date = {2020},
	langid = {english},
	doi = {10.1007/978-3-030-43364-2_8},
	note = {Series Title: Communications in Computer and Information Science},
}

@article{russakovsky_imagenet_2015,
	title = {{ImageNet} Large Scale Visual Recognition Challenge},
	volume = {115},
	issn = {0920-5691, 1573-1405},
	url = {http://link.springer.com/10.1007/s11263-015-0816-y},
	doi = {10.1007/s11263-015-0816-y},
	pages = {211--252},
	number = {3},
	journaltitle = {International Journal of Computer Vision},
	shortjournal = {Int J Comput Vis},
	author = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and Berg, Alexander C. and Fei-Fei, Li},
	urldate = {2024-12-03},
	date = {2015-12},
	langid = {english},
	note = {25411 citations (Crossref) [2024-12-03]},
}

@inproceedings{martin_database_2001,
	location = {Vancouver, {BC}, Canada},
	title = {A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics},
	volume = {2},
	isbn = {978-0-7695-1143-6},
	url = {http://ieeexplore.ieee.org/document/937655/},
	doi = {10.1109/ICCV.2001.937655},
	eventtitle = {Eighth {IEEE} International Conference on Computer Vision},
	pages = {416--423},
	booktitle = {Proceedings Eighth {IEEE} International Conference on Computer Vision. {ICCV} 2001},
	publisher = {{IEEE} Comput. Soc},
	author = {Martin, D. and Fowlkes, C. and Tal, D. and Malik, J.},
	urldate = {2024-12-03},
	date = {2001},
	note = {4045 citations (Crossref) [2024-12-03]},
}

@online{adaloglou_intuitive_2020,
	title = {Intuitive Explanation of Skip Connections in Deep Learning},
	url = {https://theaisummer.com/skip-connections/},
	abstract = {What are skip connections, why we need them and how they are applied to architectures such as {ResNet}, {DenseNet} and {UNet}.},
	titleaddon = {{AI} Summer},
	author = {Adaloglou, Nikolas},
	urldate = {2024-12-03},
	date = {2020-03-23},
	langid = {english},
}

@article{yang_denoising_2021,
	title = {A denoising method for ship radiated noise based on Spearman variational mode decomposition, spatial-dependence recurrence sample entropy, improved wavelet threshold denoising, and Savitzky-Golay filter},
	volume = {60},
	issn = {11100168},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1110016821000594},
	doi = {10.1016/j.aej.2021.01.055},
	pages = {3379--3400},
	number = {3},
	journaltitle = {Alexandria Engineering Journal},
	shortjournal = {Alexandria Engineering Journal},
	author = {Yang, Hong and Cheng, Yuanxun and Li, Guohui},
	urldate = {2024-11-27},
	date = {2021-06},
	langid = {english},
	note = {85 citations (Crossref) [2024-11-27]},
}

@article{yang_dual_2023,
	title = {Dual feature extraction system for ship-radiated noise and its application extension},
	volume = {285},
	issn = {00298018},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0029801823017365},
	doi = {10.1016/j.oceaneng.2023.115352},
	pages = {115352},
	journaltitle = {Ocean Engineering},
	shortjournal = {Ocean Engineering},
	author = {Yang, Hong and Yang, Xiaodie and Li, Guohui},
	urldate = {2024-11-27},
	date = {2023-10},
	langid = {english},
	note = {7 citations (Crossref) [2024-11-27]},
}

@article{li_ultrasound_2024,
	title = {Ultrasound signal processing based on joint {GWO}-{VMD} wavelet threshold functions},
	volume = {226},
	issn = {02632241},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0263224124000277},
	doi = {10.1016/j.measurement.2024.114143},
	pages = {114143},
	journaltitle = {Measurement},
	shortjournal = {Measurement},
	author = {Li, Hu and Li, Songsong and Sun, Jiao and Huang, Benchi and Zhang, Jiaqi and Gao, Mingyang},
	urldate = {2024-11-27},
	date = {2024-02},
	langid = {english},
	note = {8 citations (Crossref) [2024-11-27]},
}

@article{li_noise_2024,
	title = {Noise reduction method for ship radiated noise signal based on modified uniform phase empirical mode decomposition},
	volume = {227},
	issn = {02632241},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0263224124000770},
	doi = {10.1016/j.measurement.2024.114193},
	pages = {114193},
	journaltitle = {Measurement},
	shortjournal = {Measurement},
	author = {Li, Guohui and Bu, Wenjia and Yang, Hong},
	urldate = {2024-11-27},
	date = {2024-03},
	langid = {english},
	note = {14 citations (Crossref) [2024-11-27]},
}

@article{li_new_2024,
	title = {A new underwater acoustic signal denoising method based on modified uniform phase empirical mode decomposition, hierarchical amplitude-aware permutation entropy, and optimized improved wavelet threshold denoising},
	volume = {293},
	issn = {00298018},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0029801823030135},
	doi = {10.1016/j.oceaneng.2023.116629},
	pages = {116629},
	journaltitle = {Ocean Engineering},
	shortjournal = {Ocean Engineering},
	author = {Li, Guohui and Han, Yaoyu and Yang, Hong},
	urldate = {2024-11-27},
	date = {2024-02},
	langid = {english},
	note = {12 citations (Crossref) [2024-11-27]},
}

@article{khan_new_2015,
	title = {New Wavelet Thresholding Algorithm in Dropping Ambient Noise from Underwater Acoustic Signals},
	volume = {07},
	rights = {http://creativecommons.org/licenses/by/4.0/},
	issn = {1942-0730, 1942-0749},
	url = {http://www.scirp.org/journal/doi.aspx?DOI=10.4236/jemaa.2015.73006},
	doi = {10.4236/jemaa.2015.73006},
	pages = {53--60},
	number = {3},
	journaltitle = {Journal of Electromagnetic Analysis and Applications},
	shortjournal = {{JEMAA}},
	author = {Khan, Mohammad Monirujjaman and Ashique, Ratil Hasnat and Liya, Badrun Naher and Sajjad, Md. Mohsin and Rahman, Md. Anisur and Amin, M. T. Hasan},
	urldate = {2024-11-27},
	date = {2015},
	note = {6 citations (Crossref) [2024-11-27]},
}

@article{ma_svmd_2023,
	title = {{SVMD} coupled with dual-threshold criteria of correlation coefficient: A self-adaptive denoising method for ship-radiated noise signal},
	volume = {281},
	issn = {00298018},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S002980182301315X},
	doi = {10.1016/j.oceaneng.2023.114931},
	shorttitle = {{SVMD} coupled with dual-threshold criteria of correlation coefficient},
	pages = {114931},
	journaltitle = {Ocean Engineering},
	shortjournal = {Ocean Engineering},
	author = {Ma, Haomiao and Xu, Yingfeng and Wang, Jianye and Song, Mengmeng and Zhang, Shenglun},
	urldate = {2024-10-10},
	date = {2023-08},
	langid = {english},
	note = {11 citations (Semantic Scholar/{DOI}) [2024-10-15]
12 citations (Crossref) [2024-10-14]},
}

@article{li_denoising_2019,
	title = {A Denoising Method of Ship Radiated Noise Signal Based on Modified {CEEMDAN}, Dispersion Entropy, and Interval Thresholding},
	volume = {8},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2079-9292},
	url = {https://www.mdpi.com/2079-9292/8/6/597},
	doi = {10.3390/electronics8060597},
	abstract = {Due to the non-linear and non-stationary characteristics of ship radiated noise ({SR}-N) signal, the traditional linear and frequency-domain denoising methods cannot be used for such signals. In this paper, an {SR}-N signal denoising method based on modified complete ensemble empirical mode decomposition ({EMD}) with adaptive noise ({CEEMDAN}), dispersion entropy ({DE}), and interval thresholding is proposed. The proposed denoising method has the following advantages: (1) as an improved version of {CEEMDAN}, modified {CEEMDAN} ({MCEEMDAN}) combines the advantages of {EMD} and {CEEMDAN}, and it is more reliable than {CEEMDAN} and has less consuming time; (2) as a fast complexity measurement technology, {DE} can effectively identify the type of intrinsic mode function ({IMF}); and (3) interval thresholding is used for {SR}-N signal denoising, which avoids loss of amplitude information compared with traditional denoising methods. Firstly, the original signal is decomposed into a series of {IMFs} using {MCEEMDAN}. According to the {DE} value of {IMF}, the modes are divided into three types: noise {IMF}, noise-dominated {IMF} and pure {IMF}. After noise {IMFs} are removed, the noise-dominated {IMFs} are denoised using interval thresholding. Finally, the pure {IMF} and the processed noise-dominated {IMFs} are reconstructed to obtain the final denoised signal. The denoising experiments with the Chen’s chaotic system show that the proposed method has a higher signal-to-noise ratio ({SNR}) than the other three methods. Applying the proposed method to denoise the real {SR}-N signal, the topological structure of chaotic attractor can be recovered clearly. It is proved that the proposed method can effectively suppress the high-frequency noise of {SR}-N signal.},
	pages = {597},
	number = {6},
	journaltitle = {Electronics},
	shortjournal = {Electronics},
	author = {Li, Guohui and Yang, Zhichao and Yang, Hong},
	urldate = {2024-09-24},
	date = {2019-05-28},
	langid = {english},
	note = {28 citations (Semantic Scholar/{DOI}) [2024-10-15]
25 citations (Crossref) [2024-10-14]},
}

@article{li_new_2024-1,
	title = {A new underwater acoustic signal denoising method based on modified uniform phase empirical mode decomposition, hierarchical amplitude-aware permutation entropy, and optimized improved wavelet threshold denoising},
	volume = {293},
	issn = {00298018},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0029801823030135},
	doi = {10.1016/j.oceaneng.2023.116629},
	pages = {116629},
	journaltitle = {Ocean Engineering},
	shortjournal = {Ocean Engineering},
	author = {Li, Guohui and Han, Yaoyu and Yang, Hong},
	urldate = {2024-09-24},
	date = {2024-02},
	langid = {english},
	note = {16 citations (Semantic Scholar/{DOI}) [2024-10-15]
12 citations (Crossref) [2024-10-14]},
}

@misc{zhang_unleashing_2024,
	title = {Unleashing the Power of Self-Supervised Image Denoising: A Comprehensive Review},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/2308.00247},
	doi = {10.48550/ARXIV.2308.00247},
	shorttitle = {Unleashing the Power of Self-Supervised Image Denoising},
	abstract = {The advent of deep learning has brought a revolutionary transformation to image denoising techniques. However, the persistent challenge of acquiring noise-clean pairs for supervised methods in real-world scenarios remains formidable, necessitating the exploration of more practical self-supervised image denoising. This paper focuses on self-supervised image denoising methods that offer effective solutions to address this challenge. Our comprehensive review thoroughly analyzes the latest advancements in self-supervised image denoising approaches, categorizing them into three distinct classes: General methods, Blind Spot Network ({BSN})-based methods, and Transformer-based methods. For each class, we provide a concise theoretical analysis along with their practical applications. To assess the effectiveness of these methods, we present both quantitative and qualitative experimental results on various datasets, utilizing classical algorithms as benchmarks. Additionally, we critically discuss the current limitations of these methods and propose promising directions for future research. By offering a detailed overview of recent developments in self-supervised image denoising, this review serves as an invaluable resource for researchers and practitioners in the field, facilitating a deeper understanding of this emerging domain and inspiring further advancements.},
	publisher = {{arXiv}},
	author = {Zhang, Dan and Zhou, Fangfang and Albu, Felix and Wei, Yuanzhou and Yang, Xiao and Gu, Yuan and Li, Qiang},
	urldate = {2024-11-26},
	date = {2024-03-25},
	note = {Version Number: 4},
	keywords = {Computer Vision and Pattern Recognition (cs.{CV}), {FOS}: Computer and information sciences, {FOS}: Electrical engineering, electronic engineering, information engineering, Image and Video Processing (eess.{IV})},
}

@misc{hock_n2v2_2022,
	title = {N2V2 -- Fixing Noise2Void Checkerboard Artifacts with Modified Sampling Strategies and a Tweaked Network Architecture},
	rights = {Creative Commons Attribution Non Commercial Share Alike 4.0 International},
	url = {https://arxiv.org/abs/2211.08512},
	doi = {10.48550/ARXIV.2211.08512},
	abstract = {In recent years, neural network based image denoising approaches have revolutionized the analysis of biomedical microscopy data. Self-supervised methods, such as Noise2Void (N2V), are applicable to virtually all noisy datasets, even without dedicated training data being available. Arguably, this facilitated the fast and widespread adoption of N2V throughout the life sciences. Unfortunately, the blind-spot training underlying N2V can lead to rather visible checkerboard artifacts, thereby reducing the quality of final predictions considerably. In this work, we present two modifications to the vanilla N2V setup that both help to reduce the unwanted artifacts considerably. Firstly, we propose a modified network architecture, i.e., using {BlurPool} instead of {MaxPool} layers throughout the used U-Net, rolling back the residual U-Net to a non-residual U-Net, and eliminating the skip connections at the uppermost U-Net level. Additionally, we propose new replacement strategies to determine the pixel intensity values that fill in the elected blind-spot pixels. We validate our modifications on a range of microscopy and natural image data. Based on added synthetic noise from multiple noise types and at varying amplitudes, we show that both proposed modifications push the current state-of-the-art for fully self-supervised image denoising.},
	publisher = {{arXiv}},
	author = {Höck, Eva and Buchholz, Tim-Oliver and Brachmann, Anselm and Jug, Florian and Freytag, Alexander},
	urldate = {2024-11-26},
	date = {2022-11-21},
	note = {Version Number: 2},
	keywords = {Computer Vision and Pattern Recognition (cs.{CV}), {FOS}: Computer and information sciences, Machine Learning (cs.{LG})},
}

@article{krull_probabilistic_2019,
	title = {Probabilistic Noise2Void: Unsupervised Content-Aware Denoising},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/1906.00651},
	doi = {10.48550/ARXIV.1906.00651},
	shorttitle = {Probabilistic Noise2Void},
	abstract = {Today, Convolutional Neural Networks ({CNNs}) are the leading method for image denoising. They are traditionally trained on pairs of images, which are often hard to obtain for practical applications. This motivates self-supervised training methods such as Noise2Void{\textasciitilde}(N2V) that operate on single noisy images. Self-supervised methods are, unfortunately, not competitive with models trained on image pairs. Here, we present 'Probabilistic Noise2Void' ({PN}2V), a method to train {CNNs} to predict per-pixel intensity distributions. Combining these with a suitable description of the noise, we obtain a complete probabilistic model for the noisy observations and true signal in every pixel. We evaluate {PN}2V on publicly available microscopy datasets, under a broad range of noise regimes, and achieve competitive results with respect to supervised state-of-the-art methods.},
	author = {Krull, Alexander and Vicar, Tomas and Jug, Florian},
	urldate = {2024-11-26},
	date = {2019-06-04},
	note = {Publisher: {arXiv}
Version Number: 2},
	keywords = {Computer Vision and Pattern Recognition (cs.{CV}), {FOS}: Computer and information sciences, {FOS}: Electrical engineering, electronic engineering, information engineering, Image and Video Processing (eess.{IV})},
}

@misc{alamdari_improving_2020,
	title = {Improving Deep Speech Denoising by Noisy2Noisy Signal Mapping},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/1904.12069},
	doi = {10.48550/ARXIV.1904.12069},
	abstract = {Existing deep learning-based speech denoising approaches require clean speech signals to be available for training. This paper presents a deep learning-based approach to improve speech denoising in real-world audio environments by not requiring the availability of clean speech signals in a self-supervised manner. A fully convolutional neural network is trained by using two noisy realizations of the same speech signal, one used as the input and the other as the output of the network. Extensive experimentations are conducted to show the superiority of the developed deep speech denoising approach over the conventional supervised deep speech denoising approach based on four commonly used performance metrics and also based on actual field-testing outcomes.},
	publisher = {{arXiv}},
	author = {Alamdari, Nasim and Azarang, Arian and Kehtarnavaz, Nasser},
	urldate = {2024-09-24},
	date = {2020-02-21},
	note = {37 citations (Semantic Scholar/{arXiv}) [2024-10-15]
Version Number: 2},
}

@misc{lehtinen_noise2noise_2018,
	title = {Noise2Noise: Learning Image Restoration without Clean Data},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/1803.04189},
	doi = {10.48550/ARXIV.1803.04189},
	shorttitle = {Noise2Noise},
	abstract = {We apply basic statistical reasoning to signal reconstruction by machine learning -- learning to map corrupted observations to clean signals -- with a simple and powerful conclusion: it is possible to learn to restore images by only looking at corrupted examples, at performance at and sometimes exceeding training using clean data, without explicit image priors or likelihood models of the corruption. In practice, we show that a single model learns photographic noise removal, denoising synthetic Monte Carlo images, and reconstruction of undersampled {MRI} scans -- all corrupted by different processes -- based on noisy data only.},
	publisher = {{arXiv}},
	author = {Lehtinen, Jaakko and Munkberg, Jacob and Hasselgren, Jon and Laine, Samuli and Karras, Tero and Aittala, Miika and Aila, Timo},
	urldate = {2024-09-24},
	date = {2018-10-29},
	note = {1387 citations (Semantic Scholar/{arXiv}) [2024-10-15]
Version Number: 3},
}

@misc{laine_high-quality_2019,
	title = {High-Quality Self-Supervised Deep Image Denoising},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/1901.10277},
	doi = {10.48550/ARXIV.1901.10277},
	abstract = {We describe a novel method for training high-quality image denoising models based on unorganized collections of corrupted images. The training does not need access to clean reference images, or explicit pairs of corrupted images, and can thus be applied in situations where such data is unacceptably expensive or impossible to acquire. We build on a recent technique that removes the need for reference data by employing networks with a "blind spot" in the receptive field, and significantly improve two key aspects: image quality and training efficiency. Our result quality is on par with state-of-the-art neural network denoisers in the case of i.i.d. additive Gaussian noise, and not far behind with Poisson and impulse noise. We also successfully handle cases where parameters of the noise model are variable and/or unknown in both training and evaluation data.},
	publisher = {{arXiv}},
	author = {Laine, Samuli and Karras, Tero and Lehtinen, Jaakko and Aila, Timo},
	urldate = {2024-11-26},
	date = {2019-10-28},
	note = {Version Number: 3},
	keywords = {Computer Vision and Pattern Recognition (cs.{CV}), {FOS}: Computer and information sciences, Machine Learning (cs.{LG}), Machine Learning (stat.{ML}), Neural and Evolutionary Computing (cs.{NE})},
}

@misc{krull_noise2void_2019,
	title = {Noise2Void - Learning Denoising from Single Noisy Images},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/1811.10980},
	doi = {10.48550/ARXIV.1811.10980},
	abstract = {The field of image denoising is currently dominated by discriminative deep learning methods that are trained on pairs of noisy input and clean target images. Recently it has been shown that such methods can also be trained without clean targets. Instead, independent pairs of noisy images can be used, in an approach known as Noise2Noise (N2N). Here, we introduce Noise2Void (N2V), a training scheme that takes this idea one step further. It does not require noisy image pairs, nor clean target images. Consequently, N2V allows us to train directly on the body of data to be denoised and can therefore be applied when other methods cannot. Especially interesting is the application to biomedical image data, where the acquisition of training targets, clean or noisy, is frequently not possible. We compare the performance of N2V to approaches that have either clean target images and/or noisy image pairs available. Intuitively, N2V cannot be expected to outperform methods that have more information available during training. Still, we observe that the denoising performance of Noise2Void drops in moderation and compares favorably to training-free denoising methods.},
	publisher = {{arXiv}},
	author = {Krull, Alexander and Buchholz, Tim-Oliver and Jug, Florian},
	urldate = {2024-11-26},
	date = {2019-04-05},
	note = {Version Number: 2},
	keywords = {Computer Vision and Pattern Recognition (cs.{CV}), {FOS}: Computer and information sciences},
}

@incollection{montavon_efficient_2012,
	location = {Berlin, Heidelberg},
	title = {Efficient {BackProp}},
	volume = {7700},
	rights = {http://www.springer.com/tdm},
	isbn = {978-3-642-35288-1},
	url = {http://link.springer.com/10.1007/978-3-642-35289-8_3},
	pages = {9--48},
	booktitle = {Neural Networks: Tricks of the Trade},
	publisher = {Springer Berlin Heidelberg},
	author = {{LeCun}, Yann A. and Bottou, Léon and Orr, Genevieve B. and Müller, Klaus-Robert},
	editor = {Montavon, Grégoire and Orr, Geneviève B. and Müller, Klaus-Robert},
	urldate = {2024-11-18},
	date = {2012},
	langid = {english},
	doi = {10.1007/978-3-642-35289-8_3},
	note = {Series Title: Lecture Notes in Computer Science},
}

@misc{primus_frequency-wise_2023,
	title = {On Frequency-Wise Normalizations for Better Recording Device Generalization in Audio Spectrogram Transformers},
	url = {http://arxiv.org/abs/2306.11764},
	abstract = {Varying conditions between the data seen at training and at application time remain a major challenge for machine learning. We study this problem in the context of Acoustic Scene Classification ({ASC}) with mismatching recording devices. Previous works successfully employed frequency-wise normalization of inputs and hidden layer activations in convolutional neural networks to reduce the recording device discrepancy. The main objective of this work was to adopt frequency-wise normalization for Audio Spectrogram Transformers ({ASTs}), which have recently become the dominant model architecture in {ASC}. To this end, we first investigate how recording device characteristics are encoded in the hidden layer activations of {ASTs}. We find that recording device information is initially encoded in the frequency dimension; however, after the first self-attention block, it is largely transformed into the token dimension. Based on this observation, we conjecture that suppressing recording device characteristics in the input spectrogram is the most effective. We propose a frequency-centering operation for spectrograms that improves the {ASC} performance on unseen recording devices on average by up to 18.2 percentage points.},
	number = {{arXiv}:2306.11764},
	publisher = {{arXiv}},
	author = {Primus, Paul and Widmer, Gerhard},
	urldate = {2024-11-16},
	date = {2023-06-20},
	eprinttype = {arxiv},
	eprint = {2306.11764},
	keywords = {Computer Science - Machine Learning, Computer Science - Sound, Electrical Engineering and Systems Science - Audio and Speech Processing},
}

@online{gunes_answer_2020,
	title = {Answer to ``Should I normalize all data prior feeding the neural network models?''},
	url = {https://stats.stackexchange.com/a/458604},
	shorttitle = {Answer to "Should I normalize all data prior feeding the neural network models?},
	titleaddon = {Cross Validated},
	author = {gunes},
	urldate = {2024-11-16},
	date = {2020-04-05},
}

@misc{wu_group_2018,
	title = {Group Normalization},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/1803.08494},
	doi = {10.48550/ARXIV.1803.08494},
	abstract = {Batch Normalization ({BN}) is a milestone technique in the development of deep learning, enabling various networks to train. However, normalizing along the batch dimension introduces problems --- {BN}'s error increases rapidly when the batch size becomes smaller, caused by inaccurate batch statistics estimation. This limits {BN}'s usage for training larger models and transferring features to computer vision tasks including detection, segmentation, and video, which require small batches constrained by memory consumption. In this paper, we present Group Normalization ({GN}) as a simple alternative to {BN}. {GN} divides the channels into groups and computes within each group the mean and variance for normalization. {GN}'s computation is independent of batch sizes, and its accuracy is stable in a wide range of batch sizes. On {ResNet}-50 trained in {ImageNet}, {GN} has 10.6\% lower error than its {BN} counterpart when using a batch size of 2; when using typical batch sizes, {GN} is comparably good with {BN} and outperforms other normalization variants. Moreover, {GN} can be naturally transferred from pre-training to fine-tuning. {GN} can outperform its {BN}-based counterparts for object detection and segmentation in {COCO}, and for video classification in Kinetics, showing that {GN} can effectively replace the powerful {BN} in a variety of tasks. {GN} can be easily implemented by a few lines of code in modern libraries.},
	publisher = {{arXiv}},
	author = {Wu, Yuxin and He, Kaiming},
	urldate = {2024-11-18},
	date = {2018},
	note = {Version Number: 3},
	keywords = {Computer Vision and Pattern Recognition (cs.{CV}), {FOS}: Computer and information sciences, Machine Learning (cs.{LG})},
}

@online{chris_kroenke_normalizing_2022,
	title = {Normalizing spectrograms for Deep Learning},
	url = {https://enzokro.dev/blog/posts/2022-08-20-spec-norms/},
	titleaddon = {Chaski},
	author = {{Chris Kroenke}},
	urldate = {2024-11-16},
	date = {2022-08-20},
	langid = {english},
}

@online{koh_l1_tf_2008,
	title = {l1\_tf: Software for l1 Trend Filtering},
	url = {https://web.stanford.edu/~boyd/l1_tf/},
	author = {Koh, Kwangmoo and Kim, Seung-Jean and Boyd, Stephen},
	urldate = {2024-11-16},
	date = {2008-05-15},
}

@article{hodrick_postwar_1997,
	title = {Postwar U.S. Business Cycles: An Empirical Investigation},
	volume = {29},
	issn = {00222879},
	url = {https://www.jstor.org/stable/2953682?origin=crossref},
	doi = {10.2307/2953682},
	shorttitle = {Postwar U.S. Business Cycles},
	pages = {1},
	number = {1},
	journaltitle = {Journal of Money, Credit and Banking},
	shortjournal = {Journal of Money, Credit and Banking},
	author = {Hodrick, Robert J. and Prescott, Edward C.},
	urldate = {2024-11-16},
	date = {1997-02},
	note = {3779 citations (Crossref) [2024-11-17]},
}

@inproceedings{glorot_understanding_2010,
	title = {Understanding the difficulty of training deep feedforward neural networks},
	url = {https://proceedings.mlr.press/v9/glorot10a.html},
	abstract = {Whereas before 2006 it appears that deep multi-layer neural networks were not successfully trained, since then several algorithms have been shown to successfully train them, with experimental results showing the superiority of deeper vs less deep architectures. All these experimental results were obtained with new initialization or training mechanisms. Our objective here is to understand better why standard gradient descent from random initialization is doing so poorly with deep neural networks, to better understand these recent relative successes and help design better algorithms in the future.  We first observe the influence of the non-linear activations functions. We find that the logistic sigmoid activation is unsuited for deep networks with random initialization because of its mean value, which can drive especially the top hidden layer into saturation. Surprisingly, we find that saturated units can move out of saturation by themselves, albeit slowly, and explaining the plateaus sometimes seen when training neural networks. We find that a new non-linearity that saturates less can often be beneficial. Finally, we study how activations and gradients vary across layers and during training, with the idea that training may be more difficult when the singular values of the Jacobian associated with each layer are far from 1.  Based on these considerations, we propose a new initialization scheme that brings substantially faster convergence.},
	eventtitle = {Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics},
	pages = {249--256},
	booktitle = {Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics},
	publisher = {{JMLR} Workshop and Conference Proceedings},
	author = {Glorot, Xavier and Bengio, Yoshua},
	urldate = {2024-11-16},
	date = {2010-03-31},
	langid = {english},
	note = {{ISSN}: 1938-7228},
}

@thesis{pons_deep_2019,
	location = {Barcelona},
	title = {Deep neural networks for music and audio tagging},
	institution = {Universitat Pompeu Fabra},
	type = {Doctorate},
	author = {Pons, Jordi},
	date = {2019},
}

@misc{choi_comparison_2017,
	title = {A Comparison of Audio Signal Preprocessing Methods for Deep Neural Networks on Music Tagging},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/1709.01922},
	doi = {10.48550/ARXIV.1709.01922},
	abstract = {In this paper, we empirically investigate the effect of audio preprocessing on music tagging with deep neural networks. We perform comprehensive experiments involving audio preprocessing using different time-frequency representations, logarithmic magnitude compression, frequency weighting, and scaling. We show that many commonly used input preprocessing techniques are redundant except magnitude compression.},
	publisher = {{arXiv}},
	author = {Choi, Keunwoo and Fazekas, György and Cho, Kyunghyun and Sandler, Mark},
	urldate = {2024-11-16},
	date = {2017},
	note = {Version Number: 3},
	keywords = {Computer Vision and Pattern Recognition (cs.{CV}), {FOS}: Computer and information sciences, Information Retrieval (cs.{IR}), Machine Learning (cs.{LG}), Sound (cs.{SD})},
}

@article{ruffini_deep_2019,
	title = {Deep Learning With {EEG} Spectrograms in Rapid Eye Movement Behavior Disorder},
	volume = {10},
	issn = {1664-2295},
	url = {https://www.frontiersin.org/article/10.3389/fneur.2019.00806/full},
	doi = {10.3389/fneur.2019.00806},
	pages = {806},
	journaltitle = {Frontiers in Neurology},
	shortjournal = {Front. Neurol.},
	author = {Ruffini, Giulio and Ibañez, David and Castellano, Marta and Dubreuil-Vall, Laura and Soria-Frisch, Aureli and Postuma, Ron and Gagnon, Jean-François and Montplaisir, Jacques},
	urldate = {2024-11-16},
	date = {2019-07-30},
	note = {75 citations (Crossref) [2024-11-16]},
}

@inproceedings{simic_normalization_2023,
	location = {Belgrade, Serbia},
	title = {Normalization of audio signals for the needs of machine learning},
	rights = {https://doi.org/10.15223/policy-029},
	isbn = {9798350303131},
	url = {https://ieeexplore.ieee.org/document/10372705/},
	doi = {10.1109/TELFOR59449.2023.10372705},
	eventtitle = {2023 31st Telecommunications Forum ({TELFOR})},
	pages = {1--4},
	booktitle = {2023 31st Telecommunications Forum ({TELFOR})},
	publisher = {{IEEE}},
	author = {Simic, Nebojsa and Gavrovska, Ana},
	urldate = {2024-11-16},
	date = {2023-11-21},
	note = {0 citations (Crossref) [2024-11-16]},
}

@misc{ng_sparse_2010,
	title = {Sparse autoencoder},
	url = {https://web.stanford.edu/class/cs294a/sparseAutoencoder_2011new.pdf},
	publisher = {Stanford {CS}294a},
	author = {Ng, Andrew},
	urldate = {2024-10-22},
	date = {2010-01-04},
}

@article{erhan_why_2010,
	title = {Why Does Unsupervised Pre-training Help Deep Learning?},
	volume = {11},
	issn = {1532-4435},
	abstract = {Much recent research has been devoted to learning algorithms for deep architectures such as Deep Belief Networks and stacks of auto-encoder variants, with impressive results obtained in several areas, mostly on vision and language data sets. The best results obtained on supervised learning tasks involve an unsupervised learning component, usually in an unsupervised pre-training phase. Even though these new algorithms have enabled training deep models, many questions remain as to the nature of this difficult learning problem. The main question investigated here is the following: how does unsupervised pre-training work? Answering this questions is important if learning in deep architectures is to be further improved. We propose several explanatory hypotheses and test them through extensive simulations. We empirically show the influence of pre-training with respect to architecture depth, model capacity, and number of training examples. The experiments confirm and clarify the advantage of unsupervised pre-training. The results suggest that unsupervised pre-training guides the learning towards basins of attraction of minima that support better generalization from the training data set; the evidence from these results supports a regularization explanation for the effect of pre-training.},
	pages = {625--660},
	journaltitle = {J. Mach. Learn. Res.},
	author = {Erhan, Dumitru and Bengio, Yoshua and Courville, Aaron and Manzagol, Pierre-Antoine and Vincent, Pascal and Bengio, Samy},
	date = {2010-03-01},
}

@inproceedings{ma_underwater_2023,
	location = {{ZHENGZHOU}, China},
	title = {An Underwater Acoustic Signal Denoising Algorithm Based on U-Net},
	rights = {https://doi.org/10.15223/policy-029},
	isbn = {9798350316728},
	url = {https://ieeexplore.ieee.org/document/10400249/},
	doi = {10.1109/ICSPCC59353.2023.10400249},
	eventtitle = {2023 {IEEE} International Conference on Signal Processing, Communications and Computing ({ICSPCC})},
	pages = {1--6},
	booktitle = {2023 {IEEE} International Conference on Signal Processing, Communications and Computing ({ICSPCC})},
	publisher = {{IEEE}},
	author = {Ma, Ting and Yan, Shefeng and Wang, Wei},
	urldate = {2024-11-04},
	date = {2023-11-14},
	note = {0 citations (Crossref) [2024-11-05]},
}

@inproceedings{zhou_self-noise_2023,
	location = {Tokyo, Japan},
	title = {Self-Noise Suppression for {AUV} without Clean Data: a Noise2Noise Approach},
	rights = {https://doi.org/10.15223/policy-029},
	isbn = {9798350331752},
	url = {https://ieeexplore.ieee.org/document/10103424/},
	doi = {10.1109/UT49729.2023.10103424},
	shorttitle = {Self-Noise Suppression for {AUV} without Clean Data},
	eventtitle = {2023 {IEEE} Underwater Technology ({UT})},
	pages = {1--5},
	booktitle = {2023 {IEEE} Underwater Technology ({UT})},
	publisher = {{IEEE}},
	author = {Zhou, Weiyang and Li, Jianglong},
	urldate = {2024-11-04},
	date = {2023-03-06},
	note = {1 citations (Crossref) [2024-11-04]},
}

@inproceedings{hongUnderwaterAcousticTarget2021a,
	location = {Chengdu, China},
	title = {Underwater Acoustic Target Recognition with {ResNet}18 on {ShipsEar} Dataset},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	isbn = {978-1-72817-673-4},
	url = {https://ieeexplore.ieee.org/document/9451099/},
	doi = {10.1109/ICET51757.2021.9451099},
	eventtitle = {2021 {IEEE} 4th International Conference on Electronics Technology ({ICET})},
	pages = {1240--1244},
	booktitle = {2021 {IEEE} 4th International Conference on Electronics Technology ({ICET})},
	publisher = {{IEEE}},
	author = {Hong, Feng and Liu, Chengwei and Guo, Lijuan and Chen, Feng and Feng, Haihong},
	urldate = {2024-08-06},
	date = {2021-05-07},
	note = {16 citations (Semantic Scholar/{DOI}) [2024-10-15]
18 citations (Crossref) [2024-10-14]},
}

@software{iqbal_plotneuralnet_2024,
	title = {{PlotNeuralNet}},
	rights = {{MIT}},
	url = {https://github.com/HarisIqbal88/PlotNeuralNet},
	abstract = {Latex code for making neural networks diagrams},
	author = {Iqbal, Haris},
	urldate = {2024-10-29},
	date = {2024-10-29},
	note = {original-date: 2018-07-24T16:51:34Z},
	keywords = {deep-neural-networks, latex},
}

@article{vankdothu_brain_2022,
	title = {A Brain Tumor Identification and Classification Using Deep Learning based on {CNN}-{LSTM} Method},
	volume = {101},
	issn = {00457906},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0045790622002361},
	doi = {10.1016/j.compeleceng.2022.107960},
	pages = {107960},
	journaltitle = {Computers and Electrical Engineering},
	shortjournal = {Computers and Electrical Engineering},
	author = {Vankdothu, Ramdas and Hameed, Mohd Abdul and Fatima, Husnah},
	urldate = {2024-10-27},
	date = {2022-07},
	langid = {english},
	note = {90 citations (Crossref) [2024-10-27]},
}

@article{lu_cnn-lstm-based_2020,
	title = {A {CNN}-{LSTM}-Based Model to Forecast Stock Prices},
	volume = {2020},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1099-0526, 1076-2787},
	url = {https://www.hindawi.com/journals/complexity/2020/6622927/},
	doi = {10.1155/2020/6622927},
	abstract = {Stock price data have the characteristics of time series. At the same time, based on machine learning long short-term memory ({LSTM}) which has the advantages of analyzing relationships among time series data through its memory function, we propose a forecasting method of stock price based on {CNN}-{LSTM}. In the meanwhile, we use {MLP}, {CNN}, {RNN}, {LSTM}, {CNN}-{RNN}, and other forecasting models to predict the stock price one by one. Moreover, the forecasting results of these models are analyzed and compared. The data utilized in this research concern the daily stock prices from July 1, 1991, to August 31, 2020, including 7127 trading days. In terms of historical data, we choose eight features, including opening price, highest price, lowest price, closing price, volume, turnover, ups and downs, and change. Firstly, we adopt {CNN} to efficiently extract features from the data, which are the items of the previous 10 days. And then, we adopt {LSTM} to predict the stock price with the extracted feature data. According to the experimental results, the {CNN}-{LSTM} can provide a reliable stock price forecasting with the highest prediction accuracy. This forecasting method not only provides a new research idea for stock price forecasting but also provides practical experience for scholars to study financial time series data.},
	pages = {1--10},
	journaltitle = {Complexity},
	shortjournal = {Complexity},
	author = {Lu, Wenjie and Li, Jiazheng and Li, Yifan and Sun, Aijun and Wang, Jingyang},
	editor = {Hassanien, Abd E. I.-Baset},
	urldate = {2024-10-27},
	date = {2020-11-23},
	langid = {english},
	note = {206 citations (Crossref) [2024-10-27]},
}

@inproceedings{wang_dimensional_2016,
	location = {Berlin, Germany},
	title = {Dimensional Sentiment Analysis Using a Regional {CNN}-{LSTM} Model},
	url = {http://aclweb.org/anthology/P16-2037},
	doi = {10.18653/v1/P16-2037},
	eventtitle = {Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
	pages = {225--230},
	booktitle = {Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
	publisher = {Association for Computational Linguistics},
	author = {Wang, Jin and Yu, Liang-Chih and Lai, K. Robert and Zhang, Xuejie},
	urldate = {2024-10-27},
	date = {2016},
	langid = {english},
	note = {311 citations (Crossref) [2024-10-27]},
}

@article{kim_predicting_2019,
	title = {Predicting residential energy consumption using {CNN}-{LSTM} neural networks},
	volume = {182},
	issn = {03605442},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0360544219311223},
	doi = {10.1016/j.energy.2019.05.230},
	pages = {72--81},
	journaltitle = {Energy},
	shortjournal = {Energy},
	author = {Kim, Tae-Young and Cho, Sung-Bae},
	urldate = {2024-10-27},
	date = {2019-09},
	langid = {english},
	note = {952 citations (Crossref) [2024-10-27]},
}

@misc{kingma_adam_2014,
	title = {Adam: A Method for Stochastic Optimization},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/1412.6980},
	doi = {10.48550/ARXIV.1412.6980},
	shorttitle = {Adam},
	abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss {AdaMax}, a variant of Adam based on the infinity norm.},
	publisher = {{arXiv}},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	urldate = {2024-10-27},
	date = {2014},
	note = {Version Number: 9},
}

@article{islam_combined_2020,
	title = {A combined deep {CNN}-{LSTM} network for the detection of novel coronavirus ({COVID}-19) using X-ray images},
	volume = {20},
	issn = {23529148},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2352914820305621},
	doi = {10.1016/j.imu.2020.100412},
	pages = {100412},
	journaltitle = {Informatics in Medicine Unlocked},
	shortjournal = {Informatics in Medicine Unlocked},
	author = {Islam, Md. Zabirul and Islam, Md. Milon and Asraf, Amanullah},
	urldate = {2024-10-27},
	date = {2020},
	langid = {english},
	note = {465 citations (Crossref) [2024-10-27]},
}

@article{umer_fake_2020,
	title = {Fake News Stance Detection Using Deep Learning Architecture ({CNN}-{LSTM})},
	volume = {8},
	rights = {https://creativecommons.org/licenses/by/4.0/legalcode},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/9178321/},
	doi = {10.1109/ACCESS.2020.3019735},
	pages = {156695--156706},
	journaltitle = {{IEEE} Access},
	shortjournal = {{IEEE} Access},
	author = {Umer, Muhammad and Imtiaz, Zainab and Ullah, Saleem and Mehmood, Arif and Choi, Gyu Sang and On, Byung-Won},
	urldate = {2024-10-27},
	date = {2020},
	note = {172 citations (Crossref) [2024-10-27]},
}

@software{zhupengsen_zhupengsenmethod-for-splitting--deepship-dataset_2024,
	title = {{ZhuPengsen}/Method-for-Splitting-the-{DeepShip}-Dataset},
	url = {https://github.com/ZhuPengsen/Method-for-Splitting-the-DeepShip-Dataset},
	abstract = {Method for Splitting the {DeepShip} Dataset},
	author = {{ZhuPengsen}},
	urldate = {2024-10-26},
	date = {2024-10-25},
	note = {original-date: 2022-07-23T12:13:14Z},
}

@article{lin_underwater_2024,
	title = {An Underwater Acoustic Target Recognition Method Based on Iterative Short-Time Fourier Transform},
	volume = {24},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {1530-437X, 1558-1748, 2379-9153},
	url = {https://ieeexplore.ieee.org/document/10599169/},
	doi = {10.1109/JSEN.2024.3424500},
	pages = {26199--26210},
	number = {16},
	journaltitle = {{IEEE} Sensors Journal},
	shortjournal = {{IEEE} Sensors J.},
	author = {Lin, Boqiang and Gao, Lina and Zhu, Pengsen and Zhang, Yonggang and Huang, Yulong},
	urldate = {2024-10-26},
	date = {2024-08-15},
	note = {0 citations (Crossref) [2024-10-26]},
}

@article{zhu_sfc-sup_2023,
	title = {{SFC}-Sup: Robust Two-Stage Underwater Acoustic Target Recognition Method Based on Supervised Contrastive Learning},
	volume = {61},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {0196-2892, 1558-0644},
	url = {https://ieeexplore.ieee.org/document/10305190/},
	doi = {10.1109/TGRS.2023.3329653},
	shorttitle = {{SFC}-Sup},
	pages = {1--23},
	journaltitle = {{IEEE} Transactions on Geoscience and Remote Sensing},
	shortjournal = {{IEEE} Trans. Geosci. Remote Sensing},
	author = {Zhu, Pengsen and Zhang, Yonggang and Huang, Yulong and Lin, Boqiang and Zhu, Minwen and Zhao, Kunlong and Zhou, Fuheng},
	urldate = {2024-10-26},
	date = {2023},
	note = {2 citations (Crossref) [2024-10-26]},
}

@article{zhu_underwater_2023,
	title = {Underwater acoustic target recognition based on spectrum component analysis of ship radiated noise},
	volume = {211},
	issn = {0003682X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0003682X2300350X},
	doi = {10.1016/j.apacoust.2023.109552},
	pages = {109552},
	journaltitle = {Applied Acoustics},
	shortjournal = {Applied Acoustics},
	author = {Zhu, Pengsen and Zhang, Yonggang and Huang, Yulong and Zhao, Chengxuan and Zhao, Kunlong and Zhou, Fuheng},
	urldate = {2024-10-26},
	date = {2023-08},
	langid = {english},
	note = {15 citations (Crossref) [2024-10-26]},
}

@article{zeng_spectrogram_2019,
	title = {Spectrogram based multi-task audio classification},
	volume = {78},
	issn = {1380-7501, 1573-7721},
	url = {http://link.springer.com/10.1007/s11042-017-5539-3},
	doi = {10.1007/s11042-017-5539-3},
	pages = {3705--3722},
	number = {3},
	journaltitle = {Multimedia Tools and Applications},
	shortjournal = {Multimed Tools Appl},
	author = {Zeng, Yuni and Mao, Hua and Peng, Dezhong and Yi, Zhang},
	urldate = {2024-10-26},
	date = {2019-02},
	langid = {english},
	note = {117 citations (Crossref) [2024-10-26]},
}

@article{chi_classifying_2022,
	title = {Classifying Autism From Crowdsourced Semistructured Speech Recordings: Machine Learning Model Comparison Study},
	volume = {5},
	rights = {Unless stated otherwise, all articles are open-access distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/2.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work ("first published in the Journal of Medical Internet Research...") is properly cited with original {URL} and bibliographic citation information. The complete bibliographic information, a link to the original publication on http://www.jmir.org/, as well as this copyright and license information must be included.},
	url = {https://pediatrics.jmir.org/2022/2/e35406},
	doi = {10.2196/35406},
	shorttitle = {Classifying Autism From Crowdsourced Semistructured Speech Recordings},
	abstract = {Background: Autism spectrum disorder ({ASD}) is a neurodevelopmental disorder that results in altered behavior, social development, and communication patterns. In recent years, autism prevalence has tripled, with 1 in 44 children now affected. Given that traditional diagnosis is a lengthy, labor-intensive process that requires the work of trained physicians, significant attention has been given to developing systems that automatically detect autism. We work toward this goal by analyzing audio data, as prosody abnormalities are a signal of autism, with affected children displaying speech idiosyncrasies such as echolalia, monotonous intonation, atypical pitch, and irregular linguistic stress patterns.
Objective: We aimed to test the ability for machine learning approaches to aid in detection of autism in self-recorded speech audio captured from children with {ASD} and neurotypical ({NT}) children in their home environments.
Methods: We considered three methods to detect autism in child speech: (1) random forests trained on extracted audio features (including Mel-frequency cepstral coefficients); (2) convolutional neural networks trained on spectrograms; and (3) fine-tuned wav2vec 2.0—a state-of-the-art transformer-based speech recognition model. We trained our classifiers on our novel data set of cellphone-recorded child speech audio curated from the Guess What? mobile game, an app designed to crowdsource videos of children with {ASD} and {NT} children in a natural home environment.
Results: The random forest classifier achieved 70\% accuracy, the fine-tuned wav2vec 2.0 model achieved 77\% accuracy, and the convolutional neural network achieved 79\% accuracy when classifying children’s audio as either {ASD} or {NT}. We used 5-fold cross-validation to evaluate model performance.
Conclusions: Our models were able to predict autism status when trained on a varied selection of home audio clips with inconsistent recording qualities, which may be more representative of real-world conditions. The results demonstrate that machine learning methods offer promise in detecting autism automatically from speech without specialized equipment.},
	pages = {e35406},
	number = {2},
	journaltitle = {{JMIR} Pediatrics and Parenting},
	author = {Chi, Nathan A. and Washington, Peter and Kline, Aaron and Husic, Arman and Hou, Cathy and He, Chloe and Dunlap, Kaitlyn and Wall, Dennis P.},
	urldate = {2024-10-26},
	date = {2022-04-14},
	note = {26 citations (Crossref) [2024-10-26]
Company: {JMIR} Pediatrics and Parenting
Distributor: {JMIR} Pediatrics and Parenting
Institution: {JMIR} Pediatrics and Parenting
Label: {JMIR} Pediatrics and Parenting
Publisher: {JMIR} Publications Inc., Toronto, Canada},
}

@inproceedings{basili_classification_2004,
	title = {Classification of musical genre: a machine learning approach.},
	shorttitle = {Classification of musical genre},
	abstract = {In this paper, we investigate the impact of machine learn- ing algorithms in the development of automatic music clas- sification models aiming to capture genres distinctions. The study of genres as bodies of musical items aggregated according to subjective and local criteria requires corre- sponding inductive models of such a notion. This process can be thus modeled as an example-driven learning task. We investigated the impact of different musical features on the inductive accuracy by first creating a medium-sized collection of examples for widely recognized genres and then evaluating the performances of different learning al- gorithms. In this work, features are derived from the {MIDI} transcriptions of the song collection.},
	author = {Basili, Roberto and Serafini, Alfredo and Stellato, Armando},
	date = {2004-01-01},
}

@article{luoUnderwaterAcousticTarget2021a,
	title = {An Underwater Acoustic Target Recognition Method Based on Spectrograms with Different Resolutions},
	volume = {9},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2077-1312},
	url = {https://www.mdpi.com/2077-1312/9/11/1246},
	doi = {10.3390/jmse9111246},
	abstract = {This paper focuses on the automatic target recognition ({ATR}) method based on ship-radiated noise and proposes an underwater acoustic target recognition ({UATR}) method based on {ResNet}. In the proposed method, a multi-window spectral analysis ({MWSA}) method is used to solve the difficulty that the traditional time–frequency (T–F) analysis method has in extracting multiple signal characteristics simultaneously. {MWSA} generates spectrograms with different T–F resolutions through multiple window processing to provide input for the classifier. Because of the insufficient number of ship-radiated noise samples, a conditional deep convolutional generative adversarial network ({cDCGAN}) model was designed for high-quality data augmentation. Experimental results on real ship-radiated noise show that the proposed {UATR} method has good classification performance.},
	pages = {1246},
	number = {11},
	journaltitle = {Journal of Marine Science and Engineering},
	shortjournal = {{JMSE}},
	author = {Luo, Xinwei and Zhang, Minghong and Liu, Ting and Huang, Ming and Xu, Xiaogang},
	urldate = {2024-08-13},
	date = {2021-11-10},
	langid = {english},
	note = {22 citations (Semantic Scholar/{DOI}) [2024-10-15]
25 citations (Crossref) [2024-10-14]},
}

@misc{badrinarayanan_segnet_2015,
	title = {{SegNet}: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/1511.00561},
	doi = {10.48550/ARXIV.1511.00561},
	shorttitle = {{SegNet}},
	abstract = {We present a novel and practical deep fully convolutional neural network architecture for semantic pixel-wise segmentation termed {SegNet}. This core trainable segmentation engine consists of an encoder network, a corresponding decoder network followed by a pixel-wise classification layer. The architecture of the encoder network is topologically identical to the 13 convolutional layers in the {VGG}16 network. The role of the decoder network is to map the low resolution encoder feature maps to full input resolution feature maps for pixel-wise classification. The novelty of {SegNet} lies is in the manner in which the decoder upsamples its lower resolution input feature map(s). Specifically, the decoder uses pooling indices computed in the max-pooling step of the corresponding encoder to perform non-linear upsampling. This eliminates the need for learning to upsample. The upsampled maps are sparse and are then convolved with trainable filters to produce dense feature maps. We compare our proposed architecture with the widely adopted {FCN} and also with the well known {DeepLab}-{LargeFOV}, {DeconvNet} architectures. This comparison reveals the memory versus accuracy trade-off involved in achieving good segmentation performance. {SegNet} was primarily motivated by scene understanding applications. Hence, it is designed to be efficient both in terms of memory and computational time during inference. It is also significantly smaller in the number of trainable parameters than other competing architectures. We also performed a controlled benchmark of {SegNet} and other architectures on both road scenes and {SUN} {RGB}-D indoor scene segmentation tasks. We show that {SegNet} provides good performance with competitive inference time and more efficient inference memory-wise as compared to other architectures. We also provide a Caffe implementation of {SegNet} and a web demo at http://mi.eng.cam.ac.uk/projects/segnet/.},
	publisher = {{arXiv}},
	author = {Badrinarayanan, Vijay and Kendall, Alex and Cipolla, Roberto},
	urldate = {2024-10-22},
	date = {2015},
	note = {Version Number: 3},
}

@misc{ioffe_batch_2015,
	title = {Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/1502.03167},
	doi = {10.48550/ARXIV.1502.03167},
	shorttitle = {Batch Normalization},
	abstract = {Training Deep Neural Networks is complicated by the fact that the distribution of each layer's inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, in some cases eliminating the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on {ImageNet} classification: reaching 4.9\% top-5 validation error (and 4.8\% test error), exceeding the accuracy of human raters.},
	publisher = {{arXiv}},
	author = {Ioffe, Sergey and Szegedy, Christian},
	urldate = {2024-10-22},
	date = {2015},
	note = {Version Number: 3},
}

@article{lampert_detection_2013,
	title = {On the detection of tracks in spectrogram images},
	volume = {46},
	issn = {00313203},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0031320312004712},
	doi = {10.1016/j.patcog.2012.11.009},
	pages = {1396--1408},
	number = {5},
	journaltitle = {Pattern Recognition},
	shortjournal = {Pattern Recognition},
	author = {Lampert, Thomas A. and O'Keefe, Simon E.M.},
	urldate = {2024-10-21},
	date = {2013-05},
	langid = {english},
	note = {18 citations (Crossref) [2024-10-21]},
}

@online{dinneen_reginald_2020,
	title = {Reginald Fessenden and the Invention of Sonar},
	url = {https://www.sciencehistory.org/stories/magazine/reginald-fessenden-and-the-invention-of-sonar/},
	abstract = {How a radio pioneer transformed life at sea.},
	titleaddon = {Science History Institute},
	author = {Dinneen, James},
	urldate = {2024-09-11},
	date = {2020-05-19},
	langid = {american},
}

@article{park_specaugment_2019,
	title = {{SpecAugment}: A Simple Data Augmentation Method for Automatic Speech Recognition},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/1904.08779},
	doi = {10.48550/ARXIV.1904.08779},
	shorttitle = {{SpecAugment}},
	abstract = {We present {SpecAugment}, a simple data augmentation method for speech recognition. {SpecAugment} is applied directly to the feature inputs of a neural network (i.e., filter bank coefficients). The augmentation policy consists of warping the features, masking blocks of frequency channels, and masking blocks of time steps. We apply {SpecAugment} on Listen, Attend and Spell networks for end-to-end speech recognition tasks. We achieve state-of-the-art performance on the {LibriSpeech} 960h and Swichboard 300h tasks, outperforming all prior work. On {LibriSpeech}, we achieve 6.8\% {WER} on test-other without the use of a language model, and 5.8\% {WER} with shallow fusion with a language model. This compares to the previous state-of-the-art hybrid system of 7.5\% {WER}. For Switchboard, we achieve 7.2\%/14.6\% on the Switchboard/{CallHome} portion of the Hub5'00 test set without the use of a language model, and 6.8\%/14.1\% with shallow fusion, which compares to the previous state-of-the-art hybrid system at 8.3\%/17.3\% {WER}.},
	author = {Park, Daniel S. and Chan, William and Zhang, Yu and Chiu, Chung-Cheng and Zoph, Barret and Cubuk, Ekin D. and Le, Quoc V.},
	urldate = {2024-10-21},
	date = {2019},
	note = {Publisher: {arXiv}
Version Number: 3},
}

@incollection{kacprzyk_new_2010,
	location = {Berlin, Heidelberg},
	title = {A New Metaheuristic Bat-Inspired Algorithm},
	volume = {284},
	isbn = {978-3-642-12537-9},
	url = {http://link.springer.com/10.1007/978-3-642-12538-6_6},
	pages = {65--74},
	booktitle = {Nature Inspired Cooperative Strategies for Optimization ({NICSO} 2010)},
	publisher = {Springer Berlin Heidelberg},
	author = {Yang, Xin-She},
	editor = {González, Juan R. and Pelta, David Alejandro and Cruz, Carlos and Terrazas, Germán and Krasnogor, Natalio},
	editorb = {Kacprzyk, Janusz},
	editorbtype = {redactor},
	urldate = {2024-10-20},
	date = {2010},
	doi = {10.1007/978-3-642-12538-6_6},
	note = {Series Title: Studies in Computational Intelligence},
}

@article{cortes_support-vector_1995,
	title = {Support-vector networks},
	volume = {20},
	rights = {http://www.springer.com/tdm},
	issn = {0885-6125, 1573-0565},
	url = {http://link.springer.com/10.1007/BF00994018},
	doi = {10.1007/BF00994018},
	pages = {273--297},
	number = {3},
	journaltitle = {Machine Learning},
	shortjournal = {Mach Learn},
	author = {Cortes, Corinna and Vapnik, Vladimir},
	urldate = {2024-10-18},
	date = {1995-09},
	langid = {english},
	note = {30515 citations (Crossref) [2024-10-18]},
}

@online{pramoditha_concept_2021,
	title = {The Concept of Artificial Neurons (Perceptrons) in Neural Networks},
	url = {https://towardsdatascience.com/the-concept-of-artificial-neurons-perceptrons-in-neural-networks-fab22249cbfc},
	abstract = {Neural Networks and Deep Learning Course: Part 1},
	titleaddon = {Medium},
	author = {Pramoditha, Rukshan},
	urldate = {2024-10-18},
	date = {2021-12-29},
	langid = {english},
}

@book{goodfellow_deep_2016,
	location = {Cambridge, Massachusetts},
	title = {Deep learning},
	isbn = {978-0-262-03561-3},
	series = {Adaptive computation and machine learning},
	pagetotal = {1},
	publisher = {The {MIT} Press},
	author = {Goodfellow, Ian and Courville, Aaron and Bengio, Yoshua},
	date = {2016},
}

@book{rayleigh_theory_2011,
	location = {Cambridge},
	edition = {1st edition},
	title = {The Theory of Sound},
	isbn = {978-1-108-03220-9},
	abstract = {John William Strutt, third Baron Rayleigh (1842–1919), was an English physicist best known as the co-discoverer of the element argon. These highly influential volumes, first published between 1877 and 1878, contain Rayleigh's classic account of acoustics, which provided the foundations of modern acoustic theory.},
	pagetotal = {344},
	publisher = {Cambridge University Press},
	author = {Rayleigh, John William Strutt Baron},
	date = {2011-06-02},
}

@book{helmholtz_sensations_1954,
	location = {New York},
	edition = {2nd ed. edition},
	title = {On the Sensations of Tone},
	isbn = {978-0-486-60753-5},
	abstract = {On the Sensations of Tone is one of the world's greatest scientific classics. It bridges the gap between the natural sciences and music theory and, nearly a century after its first publication, it is still a standard text for the study of physiological acoustics -- the scientific basis of musical theory. It is also a treasury of knowledge for musicians and students of music and a major work in the realm of aesthetics, making important contributions to physics, anatomy, and physiology in its establishment of the physical theory of music. Difficult scientific concepts are explained simply and easily for the general reader.The first two parts of this book deal with the physics and physiology of music. Part I explains the sensation of sound in general, vibrations, sympathetic resonances, and other phenomena. Part {II} cover combinational tones and beats, and develops Helmholtz's famous theory explaining why harmonious chords are in the ratios of small whole numbers (a problem unsolved since Pythagoras).Part {III} contains the author's theory on the aesthetic relationship of musical tones. After a survey of the different principles of musical styles in history (tonal systems of Pythagoras, the Church, the Chinese, Arabs, Persians, and others), he makes a detailed study of our own tonal system (keys, discords, progression of parts).Important points in this 576-page work are profusely illustrated with graphs, diagrams, tables, and musical examples. 33 appendices discuss pitch, acoustics, and music, and include a very valuable table and study of the history of pitch in Europe from the fourteenth to the nineteenth centuries.},
	pagetotal = {608},
	publisher = {Dover Publications},
	author = {Helmholtz, Hermann},
	date = {1954-06-01},
}

@book{newton_principia_2013,
	title = {The Principia: Mathematical Principles of Natural Philosophy},
	isbn = {978-1-4905-9215-2},
	shorttitle = {The Principia},
	abstract = {Newton's Principia by Sir Isaac Newton is presented here in a high quality paperback edition. This publication was produced from a professional scan of an original edition of the book, which can include imperfections from the original book or through the scanning process, and has been created from an edition which we consider to be of the best possible quality available. This popular classic work by Sir Isaac Newton is in the English language. Newton's Principia is highly recommended for those who enjoy the works of Sir Isaac Newton, and for those discovering the works of Sir Isaac Newton for the first time.},
	pagetotal = {464},
	publisher = {Createspace Independent Publishing Platform},
	author = {Newton, Sir Isaac},
	date = {2013-07-05},
}

@book{mersenne_harmonie_1957,
	edition = {Softcover reprint of the original 1st ed. 1957 edition},
	title = {Harmonie Universelle: The Books on Instruments},
	isbn = {978-94-017-5781-2},
	shorttitle = {Harmonie Universelle},
	pagetotal = {608},
	publisher = {Springer},
	author = {Mersenne, Marin and Chapman, Roger E.},
	date = {1957-01-01},
}

@book{abraham_underwater_2019,
	location = {Cham},
	title = {Underwater Acoustic Signal Processing: Modeling, Detection, and Estimation},
	isbn = {978-3-319-92981-1},
	series = {Modern Acoustics and Signal Processing Ser},
	shorttitle = {Underwater Acoustic Signal Processing},
	abstract = {Intro -- Foreword -- Preface -- Acknowledgements -- Contents -- Acronyms and Abbreviations -- Notation Conventions, Function, and Transform Definitions -- Mathematical Notation Convention -- Function Notations and Definitions -- Transform Notations and Definitions -- Part I Sonar and Underwater Acoustics -- 1 Introduction to Underwater Acoustic Signal Processing -- 1.1 Overview of Underwater Acoustic Signal Processing -- 1.1.1 Sonar Systems -- 1.1.2 Common Applications -- 1.1.3 Signal Processing in Underwater Acoustics -- 1.1.4 Development Process for Novel Applications -- 1.1.5 Example Signals of Interest -- 1.1.6 Examples of Signal and Information Processing -- 1.1.6.1 Detection -- 1.1.6.2 Localization -- 1.1.6.3 Tracking -- 1.1.6.4 Classification -- 1.2 Intended Use and Organization of This Book -- References -- 2 Sonar Systems and the Sonar Equation -- 2.1 Introduction -- 2.2 Remote Sensing with Sonar Systems -- 2.2.1 Components of a Sonar System -- 2.2.2 Monostatic, Bistatic, and Distributed Sonar Systems -- 2.2.3 Localization: Estimating the Position of a Sound or Scattering Source -- 2.2.3.1 Active vs. Passive Localization -- 2.2.3.2 Array Design and Angle Estimation -- 2.2.3.3 Localization with Distributed and Moving Sonar Systems -- 2.2.3.4 Localization and the Effects of Propagation -- 2.2.4 Bistatic Active Sonar -- 2.2.4.1 Active Sonar Resolution Cell -- 2.2.5 Doppler Scale and Shift -- 2.2.5.1 Doppler Effect via Waveform and Platform Trajectories -- 2.2.6 Doppler Sensitive and Insensitive Waveforms -- 2.3 The Sonar Equation -- 2.3.1 Decibel Notation -- 2.3.2 The Basic Passive Sonar Equation -- 2.3.2.1 Example: Passive Submarine Radiated Noise Detection -- 2.3.3 The Basic Active Sonar Equation -- 2.3.3.1 Example: Reverberation- and Noise-Limited Active Sonar Detection -- 2.3.4 Summary of Sonar Equation Terms},
	pagetotal = {1},
	publisher = {Springer International Publishing {AG}},
	author = {Abraham, Douglas A.},
	date = {2019},
}

@inproceedings{wang_research_2020,
	location = {Dalian, China},
	title = {Research on Feature Extraction and Recognition Method of Underwater Acoustic Target Based on Deep Convolutional Network},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	isbn = {978-1-72816-521-9},
	url = {https://ieeexplore.ieee.org/document/9213504/},
	doi = {10.1109/AEECA49918.2020.9213504},
	eventtitle = {2020 {IEEE} International Conference on Advances in Electrical Engineering and Computer Applications ({AEECA})},
	pages = {863--868},
	booktitle = {2020 {IEEE} International Conference on Advances in Electrical Engineering and Computer Applications ({AEECA})},
	publisher = {{IEEE}},
	author = {Wang, Peibing and Peng, Yuan},
	urldate = {2024-06-24},
	date = {2020-08},
	note = {7 citations (Semantic Scholar/{DOI}) [2024-10-15]
12 citations (Crossref) [2024-10-14]},
}

@article{zhang_underwater_2018,
	title = {Underwater Source Localization Using {TDOA} and {FDOA} Measurements With Unknown Propagation Speed and Sensor Parameter Errors},
	volume = {6},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{OAPA}.html},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/8402219/},
	doi = {10.1109/ACCESS.2018.2852636},
	pages = {36645--36661},
	journaltitle = {{IEEE} Access},
	shortjournal = {{IEEE} Access},
	author = {Zhang, Bingbing and Hu, Yongchang and Wang, Hongyi and Zhuang, Zhaowen},
	urldate = {2024-10-17},
	date = {2018},
	note = {37 citations (Crossref) [2024-10-17]},
}

@article{wang_underwater_2018,
	title = {Underwater acoustic source localization using generalized regression neural network},
	volume = {143},
	issn = {0001-4966, 1520-8524},
	url = {https://pubs.aip.org/jasa/article/143/4/2321/818743/Underwater-acoustic-source-localization-using},
	doi = {10.1121/1.5032311},
	abstract = {In this paper, machine learning is introduced to source localization in underwater ocean waveguides. Source localization is regarded as a supervised learning regression problem and is solved by generalized regression neural network ({GRNN}). As a feed-forward network, {GRNN} is built using training data with fixed structure and configuration. The normalized sample covariance matrix ({SCM}) formed over a number of snapshots, and the corresponding source position are used as the input and output for {GRNN}. The source position can be estimated directly from the normalized {SCM} with {GRNN}; the proposed approach is thus in theory data driven. In addition, there is only one parameter, the spread factor, to be learned for {GRNN}. The optimal spread factor is determined using cross-validation. The regression method of {GRNN} is compared with the classification method of feed-forward neural network ({FNN}), as well as the classical method of matched field processing ({MFP}) for vertical array data from the {SWellEx}-96 experiment. The results show that {GRNN} achieves a satisfactory localization performance that outperforms both {FNN} and {MFP}. The proposed approach provides an alternative way for underwater source localization, especially in the absence of a priori environmental information or an appropriate propagation model.},
	pages = {2321--2331},
	number = {4},
	journaltitle = {The Journal of the Acoustical Society of America},
	author = {Wang, Yun and Peng, Hua},
	urldate = {2024-10-17},
	date = {2018-04-01},
	langid = {english},
	note = {83 citations (Crossref) [2024-10-17]},
}

@article{su_review_2020,
	title = {A Review of Underwater Localization Techniques, Algorithms, and Challenges},
	volume = {2020},
	rights = {http://creativecommons.org/licenses/by/4.0/},
	issn = {1687-725X, 1687-7268},
	url = {https://www.hindawi.com/journals/js/2020/6403161/},
	doi = {10.1155/2020/6403161},
	abstract = {Recently, there has been increasing interest in the field of underwater wireless sensor networks ({UWSNs}), which is a basic source for the exploration of the ocean environment. A range of military and civilian applications is anticipated to assist {UWSN}. The {UWSN} is being developed by the extensive wireless sensor network ({WSN}) applications and wireless technologies. Therefore, in this paper, a review has been presented which unveils the existing challenges in the underwater environment. In this review, firstly, an introduction to {UWSN} is presented. After that, underwater localizations and the basics are presented. Secondly, the paper focuses on the architecture of {UWSN} and technologies used for underwater acoustic sensor network ({UASN}) localization. Various localization techniques are discussed in the paper classified by centralized and distributed localizations. They are further classified into estimated and prediction-based localizations. Also, various underwater localization algorithms are discussed, which are grouped by the algorithms based on range and range-free schemes. Finally, the paper focuses on the challenges existing in underwater localizations, underwater acoustic communications with conclusions.},
	pages = {1--24},
	journaltitle = {Journal of Sensors},
	shortjournal = {Journal of Sensors},
	author = {Su, Xin and Ullah, Inam and Liu, Xiaofeng and Choi, Dongmin},
	urldate = {2024-10-17},
	date = {2020-01-13},
	langid = {english},
	note = {112 citations (Crossref) [2024-10-17]},
}

@article{cauchy_wind_2018,
	title = {Wind Speed Measured from Underwater Gliders Using Passive Acoustics},
	volume = {35},
	issn = {0739-0572, 1520-0426},
	url = {https://journals.ametsoc.org/view/journals/atot/35/12/jtech-d-17-0209.1.xml},
	doi = {10.1175/JTECH-D-17-0209.1},
	abstract = {Wind speed measurements are needed to understand ocean–atmosphere coupling processes and their effects on climate. Satellite observations provide sufficient spatial and temporal coverage but are lacking adequate calibration, while ship- and mooring-based observations are spatially limited and have technical shortcomings. However, wind-generated underwater noise can be used to measure wind speed, a method known as Weather Observations Through Ambient Noise ({WOTAN}). Here, we adapt the {WOTAN} technique for application to ocean gliders, enabling calibrated wind speed measurements to be combined with contemporaneous oceanographic profiles over extended spatial and temporal scales. We demonstrate the methodology in three glider surveys in the Mediterranean Sea during winter 2012/13. Wind speeds ranged from 2 to 21.5 ms-1, and the relationship to underwater ambient noise measured from the glider was quantified. A two-regime linear model is proposed, which validates a previous linear model for light winds (below 12 ms-1) identifies a regime change in the noise generation mechanism at higher wind speeds. This proposed model improves on previous work by extending the validated model range to strong winds of up to 21.5 ms-1. 
The acquisition, data processing, and calibration steps are described. Future applications for glider-based wind speed observations and the development of a global wind speed estimation model are discussed.},
	pages = {2305--2321},
	number = {12},
	journaltitle = {Journal of Atmospheric and Oceanic Technology},
	author = {Cauchy, Pierre and Heywood, Karen J. and Merchant, Nathan D. and Queste, Bastien Y. and Testor, Pierre},
	urldate = {2024-10-17},
	date = {2018-12},
	note = {19 citations (Crossref) [2024-10-17]},
}

@article{ozanich_feedforward_2020,
	title = {A feedforward neural network for direction-of-arrival estimation},
	volume = {147},
	issn = {0001-4966, 1520-8524},
	url = {https://pubs.aip.org/jasa/article/147/3/2035/997284/A-feedforward-neural-network-for-direction-of},
	doi = {10.1121/10.0000944},
	abstract = {This paper examines the relationship between conventional beamforming and linear supervised learning, then develops a nonlinear deep feed-forward neural network ({FNN}) for direction-of-arrival ({DOA}) estimation. First, conventional beamforming is reformulated as a real-valued, linear inverse problem in the weight space, which is compared to a support vector machine and a linear {FNN} model. In the linear formulation, {DOA} is quickly and accurately estimated for a realistic array calibration example. Then, a nonlinear {FNN} is developed for two-source {DOA} and for K-source {DOA}, where K is unknown. Two training methodologies are used: exhaustive training for controlled accuracy and random training for flexibility. The number of {FNN} model hidden layers, hidden nodes, and activation functions are selected using a hyperparameter search. In plane wave simulations, the 2-source {FNN} resolved incoherent sources with 1° resolution using a single snapshot, similar to Sparse Bayesian Learning ({SBL}). With multiple snapshots, K-source {FNN} achieved resolution and accuracy similar to Multiple Signal Classification and {SBL} for an unknown number of sources. The practicality of the deep {FNN} model is demonstrated on Swellex96 experimental data for multiple source {DOA} on a horizontal acoustic array.},
	pages = {2035--2048},
	number = {3},
	journaltitle = {The Journal of the Acoustical Society of America},
	author = {Ozanich, Emma and Gerstoft, Peter and Niu, Haiqiang},
	urldate = {2024-10-17},
	date = {2020-03-01},
	langid = {english},
	note = {95 citations (Crossref) [2024-10-17]},
}

@article{liu_doa_2021,
	title = {{DOA} estimation based on {CNN} for underwater acoustic array},
	volume = {172},
	issn = {0003682X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0003682X20306988},
	doi = {10.1016/j.apacoust.2020.107594},
	pages = {107594},
	journaltitle = {Applied Acoustics},
	shortjournal = {Applied Acoustics},
	author = {Liu, Yuji and Chen, Huixiu and Wang, Biao},
	urldate = {2024-10-17},
	date = {2021-01},
	langid = {english},
	note = {45 citations (Crossref) [2024-10-17]},
}

@article{li_deep_2022,
	title = {Deep learning-based {DOA} estimation using {CRNN} for underwater acoustic arrays},
	volume = {9},
	issn = {2296-7745},
	url = {https://www.frontiersin.org/articles/10.3389/fmars.2022.1027830/full},
	doi = {10.3389/fmars.2022.1027830},
	abstract = {In the marine environment, estimating the direction of arrival ({DOA}) is challenging because of the multipath signals and low signal-to-noise ratio ({SNR}). In this paper, we propose a convolutional recurrent neural network ({CRNN})-based method for underwater {DOA} estimation using an acoustic array. The proposed {CRNN} takes the phase component of the short-time Fourier transform of the array signals as the input feature. The convolutional part of the {CRNN} extracts high-level features, while the recurrent component captures the temporal dependencies of the features. Moreover, we introduce a residual connection to further improve the performance of {DOA} estimation. We train the {CRNN} with multipath signals generated by the {BELLHOP} model and a uniform line array. Experimental results show that the proposed {CRNN} yields high-accuracy {DOA} estimation at different {SNR} levels, significantly outperforming existing methods. The proposed {CRNN} also exhibits a relatively short processing time for {DOA} estimation, extending its applicability.},
	pages = {1027830},
	journaltitle = {Frontiers in Marine Science},
	shortjournal = {Front. Mar. Sci.},
	author = {Li, Xiaoqiang and Chen, Jianfeng and Bai, Jisheng and Ayub, Muhammad Saad and Zhang, Dongzhe and Wang, Mou and Yan, Qingli},
	urldate = {2024-10-17},
	date = {2022-11-10},
	note = {2 citations (Crossref) [2024-10-17]},
}

@article{cao_deep_2021,
	title = {Deep transfer learning for underwater direction of arrival using one vector sensor},
	volume = {149},
	issn = {0001-4966, 1520-8524},
	url = {https://pubs.aip.org/jasa/article/149/3/1699/973657/Deep-transfer-learning-for-underwater-direction-of},
	doi = {10.1121/10.0003645},
	abstract = {A deep transfer learning ({DTL}) method is proposed for the direction of arrival ({DOA}) estimation using a single-vector sensor. The method involves training of a convolutional neural network ({CNN}) with synthetic data in source domain and then adapting the source domain to target domain with available at-sea data. The {CNN} is fed with the cross-spectrum of acoustical pressure and particle velocity during the training process to learn {DOAs} of a moving surface ship. For domain adaptation, first convolutional layers of the pre-trained {CNN} are copied to a target {CNN}, and the remaining layers of the target {CNN} are randomly initialized and trained on at-sea data. Numerical tests and real data results suggest that the {DTL} yields more reliable {DOA} estimates than a conventional {CNN}, especially with interfering sources.},
	pages = {1699--1711},
	number = {3},
	journaltitle = {The Journal of the Acoustical Society of America},
	author = {Cao, Huaigang and Wang, Wenbo and Su, Lin and Ni, Haiyan and Gerstoft, Peter and Ren, Qunyan and Ma, Li},
	urldate = {2024-10-17},
	date = {2021-03-01},
	langid = {english},
	note = {41 citations (Crossref) [2024-10-17]},
}

@online{knowlton_what_nodate,
	title = {What are common underwater sounds?},
	url = {https://dosits.org/science/sounds-in-the-sea/what-are-common-underwater-sounds/},
	abstract = {The ocean is filled with sound. Underwater sound is generated by a variety of natural sources, such as breaking waves, rain, and marine life. It is also generated by a variety of man-made sources, such as},
	titleaddon = {Discovery of Sound in the Sea},
	author = {Knowlton, Chris},
	urldate = {2024-09-11},
	langid = {american},
}

@online{morin_history_nodate,
	title = {History of the {SOFAR} Channel},
	url = {https://dosits.org/science/movement/sofar-channel/history-of-the-sofar-channel/},
	abstract = {In the spring of 1944, ocean scientists, Maurice Ewing and J. Worzel, departed Woods Hole, Massachusetts, aboard the research vessel R/V Saluda to test a theory that predicted that low-frequency sound should be able to travel long distances in the deep ocean. A deep receiving hydrophone was hung from R/V Saluda. A second ship dropped},
	titleaddon = {Discovery of Sound in the Sea},
	author = {Morin, Holly},
	urldate = {2024-09-11},
	langid = {american},
}

@misc{brown_language_2020,
	title = {Language Models are Few-Shot Learners},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/2005.14165},
	doi = {10.48550/ARXIV.2005.14165},
	abstract = {Recent work has demonstrated substantial gains on many {NLP} tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something which current {NLP} systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches. Specifically, we train {GPT}-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, {GPT}-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. {GPT}-3 achieves strong performance on many {NLP} datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where {GPT}-3's few-shot learning still struggles, as well as some datasets where {GPT}-3 faces methodological issues related to training on large web corpora. Finally, we find that {GPT}-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans. We discuss broader societal impacts of this finding and of {GPT}-3 in general.},
	publisher = {{arXiv}},
	author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and {McCandlish}, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
	urldate = {2024-10-16},
	date = {2020},
	note = {Version Number: 4},
}

@misc{devlin_bert_2018,
	title = {{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/1810.04805},
	doi = {10.48550/ARXIV.1810.04805},
	shorttitle = {{BERT}},
	abstract = {We introduce a new language representation model called {BERT}, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, {BERT} is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained {BERT} model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. {BERT} is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the {GLUE} score to 80.5\% (7.7\% point absolute improvement), {MultiNLI} accuracy to 86.7\% (4.6\% absolute improvement), {SQuAD} v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and {SQuAD} v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
	publisher = {{arXiv}},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	urldate = {2024-10-16},
	date = {2018},
	note = {Version Number: 2},
}

@misc{vaswani_attention_2017,
	title = {Attention Is All You Need},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/1706.03762},
	doi = {10.48550/ARXIV.1706.03762},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 {BLEU} on the {WMT} 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 {BLEU}. On the {WMT} 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art {BLEU} score of 41.8 after training for 3.5 days on eight {GPUs}, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
	publisher = {{arXiv}},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	urldate = {2024-10-16},
	date = {2017},
	note = {Version Number: 7},
}

@book{minsky_perceptrons_1972,
	location = {Cambridge/Mass.},
	edition = {2. print. with corr},
	title = {Perceptrons: an introduction to computational geometry},
	isbn = {978-0-262-13043-1},
	shorttitle = {Perceptrons},
	pagetotal = {258},
	publisher = {The {MIT} Press},
	author = {Minsky, Marvin and Papert, Seymour A.},
	date = {1972},
}

@article{lecun_deep_2015,
	title = {Deep learning},
	volume = {521},
	issn = {0028-0836, 1476-4687},
	url = {https://www.nature.com/articles/nature14539},
	doi = {10.1038/nature14539},
	pages = {436--444},
	number = {7553},
	journaltitle = {Nature},
	shortjournal = {Nature},
	author = {{LeCun}, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	urldate = {2024-10-16},
	date = {2015-05-28},
	langid = {english},
	note = {54464 citations (Crossref) [2024-10-16]},
}

@article{lecun_gradient-based_1998,
	title = {Gradient-based learning applied to document recognition},
	volume = {86},
	url = {https://ieeexplore.ieee.org/abstract/document/726791/},
	pages = {2278--2324},
	number = {11},
	journaltitle = {Proceedings of the {IEEE}},
	author = {{LeCun}, Yann and Bottou, Léon and Bengio, Yoshua and Haffner, Patrick},
	urldate = {2024-10-16},
	date = {1998},
	note = {Publisher: Ieee},
}

@article{lecun_convolutional_1995,
	title = {Convolutional networks for images, speech, and time series},
	volume = {3361},
	url = {https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=e26cc4a1c717653f323715d751c8dea7461aa105},
	pages = {1995},
	number = {10},
	journaltitle = {The handbook of brain theory and neural networks},
	author = {{LeCun}, Yann and Bengio, Yoshua},
	urldate = {2024-10-16},
	date = {1995},
	note = {Publisher: Citeseer},
}

@article{lecun_backpropagation_1989,
	title = {Backpropagation applied to handwritten zip code recognition},
	volume = {1},
	url = {https://ieeexplore.ieee.org/abstract/document/6795724/},
	pages = {541--551},
	number = {4},
	journaltitle = {Neural computation},
	author = {{LeCun}, Yann and Boser, Bernhard and Denker, John S. and Henderson, Donnie and Howard, Richard E. and Hubbard, Wayne and Jackel, Lawrence D.},
	urldate = {2024-10-16},
	date = {1989},
	note = {Publisher: {MIT} Press},
}

@misc{he_deep_2015,
	title = {Deep Residual Learning for Image Recognition},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/1512.03385},
	doi = {10.48550/ARXIV.1512.03385},
	abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the {ImageNet} dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than {VGG} nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the {ImageNet} test set. This result won the 1st place on the {ILSVRC} 2015 classification task. We also present analysis on {CIFAR}-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the {COCO} object detection dataset. Deep residual nets are foundations of our submissions to {ILSVRC} \&amp; {COCO} 2015 competitions, where we also won the 1st places on the tasks of {ImageNet} detection, {ImageNet} localization, {COCO} detection, and {COCO} segmentation.},
	publisher = {{arXiv}},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	urldate = {2024-10-16},
	date = {2015},
	note = {Version Number: 1},
}

@misc{simonyan_very_2014,
	title = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/1409.1556},
	doi = {10.48550/ARXIV.1409.1556},
	abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our {ImageNet} Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing {ConvNet} models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
	publisher = {{arXiv}},
	author = {Simonyan, Karen and Zisserman, Andrew},
	urldate = {2024-10-16},
	date = {2014},
	note = {Version Number: 6},
}

@inproceedings{krizhevsky_imagenet_2012,
	title = {{ImageNet} Classification with Deep Convolutional Neural Networks},
	volume = {25},
	url = {https://papers.nips.cc/paper_files/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html},
	abstract = {We trained a large, deep convolutional neural network to classify the 1.3 million high-resolution images in the {LSVRC}-2010 {ImageNet} training set into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 39.7{\textbackslash}\% and 18.9{\textbackslash}\% which is considerably better than the previous state-of-the-art results. The neural network, which has 60 million parameters and 500,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and two globally connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient {GPU} implementation of convolutional nets. To reduce overfitting in the globally connected layers we employed a new regularization method that proved to be very effective.},
	booktitle = {Advances in Neural Information Processing Systems},
	publisher = {Curran Associates, Inc.},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	urldate = {2024-10-16},
	date = {2012},
}

@inproceedings{raina_large-scale_2009,
	location = {Montreal Quebec Canada},
	title = {Large-scale deep unsupervised learning using graphics processors},
	isbn = {978-1-60558-516-1},
	url = {https://dl.acm.org/doi/10.1145/1553374.1553486},
	doi = {10.1145/1553374.1553486},
	eventtitle = {{ICML} '09: The 26th Annual International Conference on Machine Learning held in conjunction with the 2007 International Conference on Inductive Logic Programming},
	pages = {873--880},
	booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
	publisher = {{ACM}},
	author = {Raina, Rajat and Madhavan, Anand and Ng, Andrew Y.},
	urldate = {2024-10-16},
	date = {2009-06-14},
	langid = {english},
	note = {369 citations (Crossref) [2024-10-16]},
}

@misc{lin_microsoft_2014,
	title = {Microsoft {COCO}: Common Objects in Context},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/1405.0312},
	doi = {10.48550/ARXIV.1405.0312},
	shorttitle = {Microsoft {COCO}},
	abstract = {We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to {PASCAL}, {ImageNet}, and {SUN}. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model.},
	publisher = {{arXiv}},
	author = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Bourdev, Lubomir and Girshick, Ross and Hays, James and Perona, Pietro and Ramanan, Deva and Zitnick, C. Lawrence and Dollár, Piotr},
	urldate = {2024-10-16},
	date = {2014},
	note = {Version Number: 3},
}

@inproceedings{deng_imagenet_2009,
	location = {Miami, {FL}},
	title = {{ImageNet}: A large-scale hierarchical image database},
	isbn = {978-1-4244-3992-8},
	url = {https://ieeexplore.ieee.org/document/5206848/},
	doi = {10.1109/CVPR.2009.5206848},
	shorttitle = {{ImageNet}},
	eventtitle = {2009 {IEEE} Computer Society Conference on Computer Vision and Pattern Recognition Workshops ({CVPR} Workshops)},
	pages = {248--255},
	booktitle = {2009 {IEEE} Conference on Computer Vision and Pattern Recognition},
	publisher = {{IEEE}},
	author = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and {Kai Li} and {Li Fei-Fei}},
	urldate = {2024-10-16},
	date = {2009-06},
	note = {33252 citations (Crossref) [2024-10-16]},
}

@article{rumelhart_learning_1986,
	title = {Learning representations by back-propagating errors},
	volume = {323},
	rights = {http://www.springer.com/tdm},
	issn = {0028-0836, 1476-4687},
	url = {https://www.nature.com/articles/323533a0},
	doi = {10.1038/323533a0},
	pages = {533--536},
	number = {6088},
	journaltitle = {Nature},
	shortjournal = {Nature},
	author = {Rumelhart, David E. and Hinton, Geoffrey E. and Williams, Ronald J.},
	urldate = {2024-10-16},
	date = {1986-10},
	langid = {english},
	note = {17985 citations (Crossref) [2024-10-16]},
}

@article{mcculloch_logical_1943,
	title = {A logical calculus of the ideas immanent in nervous activity},
	volume = {5},
	rights = {http://www.springer.com/tdm},
	issn = {0007-4985, 1522-9602},
	url = {http://link.springer.com/10.1007/BF02478259},
	doi = {10.1007/BF02478259},
	pages = {115--133},
	number = {4},
	journaltitle = {The Bulletin of Mathematical Biophysics},
	shortjournal = {Bulletin of Mathematical Biophysics},
	author = {{McCulloch}, Warren S. and Pitts, Walter},
	urldate = {2024-10-15},
	date = {1943-12},
	langid = {english},
	note = {11093 citations (Crossref) [2024-10-15]},
}

@article{rosenblatt_perceptron_1958,
	title = {The perceptron: A probabilistic model for information storage and organization in the brain.},
	volume = {65},
	issn = {1939-1471, 0033-295X},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/h0042519},
	doi = {10.1037/h0042519},
	shorttitle = {The perceptron},
	pages = {386--408},
	number = {6},
	journaltitle = {Psychological Review},
	shortjournal = {Psychological Review},
	author = {Rosenblatt, F.},
	urldate = {2024-10-15},
	date = {1958},
	langid = {english},
	note = {6272 citations (Crossref) [2024-10-15]},
}

@article{turing_computing_1950,
	title = {Computing Machinery and Intelligence},
	volume = {{LIX}},
	issn = {1460-2113, 0026-4423},
	url = {https://academic.oup.com/mind/article/LIX/236/433/986238},
	doi = {10.1093/mind/LIX.236.433},
	pages = {433--460},
	number = {236},
	journaltitle = {Mind},
	author = {Turing, A. M.},
	urldate = {2024-10-15},
	date = {1950-10-01},
	langid = {english},
	note = {6304 citations (Crossref) [2024-10-15]},
}

@article{franz_splashes_1959,
	title = {Splashes as Sources of Sound in Liquids},
	volume = {31},
	issn = {0001-4966, 1520-8524},
	url = {https://pubs.aip.org/jasa/article/31/8/1080/718696/Splashes-as-Sources-of-Sound-in-Liquids},
	doi = {10.1121/1.1907831},
	abstract = {The mechanisms of sound production by the splashes made by the gas-to-liquid entry of objects are discussed. The sound from the splash is considered to be associated with acoustic multipoles of all orders, the main ones being simple sources, dipoles, and quadrupoles. The orders of the multipoles that predominate during the various phases of the splash are estimated from the flow and boundary conditions. The sounds radiated into the water by the low-velocity vertical entry of single water droplets, sprays of water droplets, and various other objects, such as spheres, cones, and wedges, have been measured and found to have the characteristics of acoustic dipoles. The extensive experimental data on the spectrum of the underwater sound from the splashes of droplets and sprays and the scaling laws for dipoles are used to estimate the spectrum levels of the underwater sound from the splashing of rain on the surface of a sea in terms of the rate of rainfall.},
	pages = {1080--1096},
	number = {8},
	journaltitle = {The Journal of the Acoustical Society of America},
	author = {Franz, G. J.},
	urldate = {2024-09-11},
	date = {1959-08-01},
	langid = {english},
	note = {206 citations (Semantic Scholar/{DOI}) [2024-10-15]
141 citations (Crossref) [2024-10-14]},
}

@article{wenz_review_1972,
	title = {Review of Underwater Acoustics Research: Noise},
	volume = {51},
	issn = {0001-4966, 1520-8524},
	url = {https://pubs.aip.org/jasa/article/51/3B/1010/620512/Review-of-Underwater-Acoustics-Research-Noise},
	doi = {10.1121/1.1912921},
	shorttitle = {Review of Underwater Acoustics Research},
	abstract = {The purposes, problems, and progress of radiated noise, self-noise, and ambient noise research are reviewed. Purposes are related primarily to national defense, but applications to fishery and to the utilization of other natural resources are also noted. Basic problems, most of which were recognized 20 years or more ago, involve ascertainment of properties of the noise, identification of noise sources and mechanisms of noise generation, and the discovery and definition of noise dependencies on environmental factors. Many radiated and self-noise sources and mechanisms have been identified. Major problems are those of noise measurement, noise reduction, and prevention. In the field of ambient noise, most measurements have been of sound-pressure level. Some of the noise sources and environmental factors have been identified, and a capability for qualitative and gross prediction has been achieved. Recommended are further investigations of the variation of ambient noise with receiver depth, directionality of the noise field, statistics of both noise level and instantaneous noise values, additional work at frequencies below 10 Hz, and additional geographic coverage, making full use of current knowledge to fashion models for experimental guidance. Challenging problems exist in procedures and instrumentation for noise studies.},
	pages = {1010--1024},
	number = {3},
	journaltitle = {The Journal of the Acoustical Society of America},
	author = {Wenz, Gordon M.},
	urldate = {2024-09-09},
	date = {1972-03-01},
	langid = {english},
	note = {87 citations (Semantic Scholar/{DOI}) [2024-10-15]
71 citations (Crossref) [2024-10-14]},
}

@article{ritzmann_snapping_1973,
	title = {Snapping Behavior of the Shrimp \textit{Alpheus californiensis}},
	volume = {181},
	issn = {0036-8075, 1095-9203},
	url = {https://www.science.org/doi/10.1126/science.181.4098.459},
	doi = {10.1126/science.181.4098.459},
	abstract = {A pair of very smooth disks, located on the claw of the snapping shrimp
              Alpheus californiensis
              , are temporarily held together by cohesive forces of water. This allows the closer muscle of the claw to generate a large amount of tension before these cohesive forces are overcome, and results in a rapid closing movement.},
	pages = {459--460},
	number = {4098},
	journaltitle = {Science},
	shortjournal = {Science},
	author = {Ritzmann, Roy},
	urldate = {2024-09-11},
	date = {1973-08-03},
	langid = {english},
	note = {41 citations (Semantic Scholar/{DOI}) [2024-10-15]
35 citations (Crossref) [2024-10-14]},
}

@article{altes_detection_1980,
	title = {Detection, estimation, and classification with spectrograms},
	volume = {67},
	issn = {0001-4966, 1520-8524},
	url = {https://pubs.aip.org/jasa/article/67/4/1232/691645/Detection-estimation-and-classification-with},
	doi = {10.1121/1.384165},
	abstract = {A locally optimum detector correlates the data spectrogram with a reference spectrogram in order to detect (i) a known signal with unknown delay and Doppler parameters, (ii) a random signal with known covariance function, or (iii) the output of a random, time-varying channel with known scattering function. Spectrogram correlation can also be used for maximum likelihood parameter estimation, e.g., estimation of delay or center frequency of a signal. To estimate an analog input signal from its spectrogram, a modified deconvolution operation can be used together with a predictive noise canceler. If no noise is added to the spectrogram, the mean-square error of this signal estimate is independent of the window function that is used to construct the spectrogram. When estimates of specific signal parameters are obtained directly from the spectrogram, these estimates have mean-square errors that depend upon both signal and window waveforms. Spectrogram correlation can be used for classification as well as for estimation and detection. Parameter estimators and detectors are, in fact, specialized kinds of classifiers.},
	pages = {1232--1246},
	number = {4},
	journaltitle = {The Journal of the Acoustical Society of America},
	author = {Altes, Richard A.},
	urldate = {2024-09-11},
	date = {1980-04-01},
	langid = {english},
	note = {257 citations (Semantic Scholar/{DOI}) [2024-10-15]
192 citations (Crossref) [2024-10-14]},
}

@article{gorman_analysis_1988,
	title = {Analysis of hidden units in a layered network trained to classify sonar targets},
	volume = {1},
	rights = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {08936080},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0893608088900238},
	doi = {10.1016/0893-6080(88)90023-8},
	pages = {75--89},
	number = {1},
	journaltitle = {Neural Networks},
	shortjournal = {Neural Networks},
	author = {Gorman, R.Paul and Sejnowski, Terrence J.},
	urldate = {2024-09-11},
	date = {1988-01},
	langid = {english},
	note = {1213 citations (Semantic Scholar/{DOI}) [2024-10-15]
770 citations (Crossref) [2024-10-14]},
}

@article{medwin_bubble_1989,
	title = {Bubble sources of the Knudsen sea noise spectra},
	volume = {86},
	issn = {0001-4966, 1520-8524},
	url = {https://pubs.aip.org/jasa/article/86/3/1124/784761/Bubble-sources-of-the-Knudsen-sea-noise},
	doi = {10.1121/1.398104},
	abstract = {Single coherent bubble contributions to the incoherent underwater noise of spilling breakers have been studied in an anechoic laboratory facility. The waves are generated by a plunger, they propagate 17 m along a 1.2×1.2-m water waveguide, and ‘‘spill’’ and create bubbles at the surface of a 3×3×3-m anechoic cube of water. Several species of bubbles have been identified. In general, they act as transient dipoles of duration from 2 to several milliseconds, with peak axial source strength of the order of tenths of pascals, at 1 m. The noise is emitted when the bubble is within hundreds of micrometers or a few millimeters of the surface. Bubbles were observed in the 2 decades of frequency from 500 to 50 000 Hz. The average of the individual bubble events yielded a spectrum that slopes at about 5 {dB}/oct from 1 to 20 {kHz}, the same as the Knudsen wind noise spectra at sea. The magnitude of the laboratory breaker noise during continual wave-breaking events was approximately 80 {dB} re: 1 μ Pa2/Hz at 1 {kHz}, which is essentially the same as observed during the continual bubble production that occurs with very high winds at sea. The reasons for this agreement are discussed.},
	pages = {1124--1130},
	number = {3},
	journaltitle = {The Journal of the Acoustical Society of America},
	author = {Medwin, Herman and Beaky, Matthew M.},
	urldate = {2024-09-11},
	date = {1989-09-01},
	langid = {english},
	note = {150 citations (Semantic Scholar/{DOI}) [2024-10-15]
98 citations (Crossref) [2024-10-14]},
}

@article{boashash_methodology_1990,
	title = {A methodology for detection and classification of some underwater acoustic signals using time-frequency analysis techniques},
	volume = {38},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {00963518},
	url = {http://ieeexplore.ieee.org/document/103085/},
	doi = {10.1109/29.103085},
	pages = {1829--1841},
	number = {11},
	journaltitle = {{IEEE} Transactions on Acoustics, Speech, and Signal Processing},
	shortjournal = {{IEEE} Trans. Acoust., Speech, Signal Processing},
	author = {Boashash, B. and O'Shea, P.},
	urldate = {2024-09-11},
	date = {1990-11},
	note = {150 citations (Semantic Scholar/{DOI}) [2024-10-15]
114 citations (Crossref) [2024-10-14]},
}

@inproceedings{abel_image_1992,
	location = {San Francisco, {CA}, {USA}},
	title = {An image processing approach to frequency tracking (application to sonar data)},
	isbn = {978-0-7803-0532-8},
	url = {http://ieeexplore.ieee.org/document/225995/},
	doi = {10.1109/ICASSP.1992.225995},
	eventtitle = {[Proceedings] {ICASSP}-92: 1992 {IEEE} International Conference on Acoustics, Speech, and Signal Processing},
	pages = {561--564 vol.2},
	booktitle = {[Proceedings] {ICASSP}-92: 1992 {IEEE} International Conference on Acoustics, Speech, and Signal Processing},
	publisher = {{IEEE}},
	author = {Abel, J.S. and Lee, H.J. and Lowell, A.P.},
	urldate = {2024-08-13},
	date = {1992},
	note = {22 citations (Semantic Scholar/{DOI}) [2024-10-15]
14 citations (Crossref) [2024-10-14]},
}

@article{chin-hsing_classification_1998,
	title = {Classification of underwater signals using wavelet transforms and neural networks},
	volume = {27},
	rights = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {08957177},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0895717797002598},
	doi = {10.1016/S0895-7177(97)00259-8},
	pages = {47--60},
	number = {2},
	journaltitle = {Mathematical and Computer Modelling},
	shortjournal = {Mathematical and Computer Modelling},
	author = {Chin-Hsing, Chen and Jiann-Der, Lee and Ming-Chi, Lin},
	urldate = {2024-09-10},
	date = {1998-01},
	langid = {english},
	note = {56 citations (Semantic Scholar/{DOI}) [2024-10-15]
53 citations (Crossref) [2024-10-14]},
}

@article{vaccaro_past_1998,
	title = {The past, present, and the future of underwater acoustic signal processing},
	volume = {15},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {10535888},
	url = {http://ieeexplore.ieee.org/document/689583/},
	doi = {10.1109/79.689583},
	pages = {21--51},
	number = {4},
	journaltitle = {{IEEE} Signal Processing Magazine},
	shortjournal = {{IEEE} Signal Process. Mag.},
	author = {Vaccaro, R.J.},
	urldate = {2024-06-24},
	date = {1998-07},
	note = {108 citations (Semantic Scholar/{DOI}) [2024-10-15]
85 citations (Crossref) [2024-10-14]},
	keywords = {Review},
}

@article{arveson_radiated_2000,
	title = {Radiated noise characteristics of a modern cargo ship},
	volume = {107},
	issn = {0001-4966, 1520-8524},
	url = {https://pubs.aip.org/jasa/article/107/1/118/550528/Radiated-noise-characteristics-of-a-modern-cargo},
	doi = {10.1121/1.428344},
	abstract = {Extensive measurements were made of the radiated noise of M/V {OVERSEAS} {HARRIETTE}, a bulk cargo ship (length 173 m, displacement 25 515 tons) powered by a direct-drive low-speed diesel engine—a design representative of many modern merchant ships. The radiated noise data show high-level tonal frequencies from the ship’s service diesel generator, main engine firing rate, and blade rate harmonics due to propeller cavitation. Radiated noise directionality measurements indicate that the radiation is generally dipole in form at lower frequencies, as expected. There are some departures from this pattern that may indicate hull interactions. Blade rate source level (174 {dB} re 1 μPa/m at 9 Hz, 16 knots) agrees reasonably well with a model of fundamental blade rate radiation previously reported by Gray and Greeley, but agreement for blade rate harmonics is not as good. Noise from merchant ships elevates the natural ambient by 20–30 {dB} in many areas; the effects of this noise on the biological environment have not been widely investigated.},
	pages = {118--129},
	number = {1},
	journaltitle = {The Journal of the Acoustical Society of America},
	author = {Arveson, Paul T. and Vendittis, David J.},
	urldate = {2024-09-09},
	date = {2000-01-01},
	langid = {english},
	note = {358 citations (Semantic Scholar/{DOI}) [2024-10-15]
262 citations (Crossref) [2024-10-14]},
}

@inproceedings{ward_sonar_2000,
	location = {Halifax, {NS}, Canada},
	title = {Sonar signal detection and classification using artificial neural networks},
	volume = {2},
	isbn = {978-0-7803-5957-4},
	url = {http://ieeexplore.ieee.org/document/849558/},
	doi = {10.1109/CCECE.2000.849558},
	eventtitle = {2000 Canadian Conference on Electrical and Computer Engineering Conference Proceedings. Navigating to a New Era},
	pages = {717--721},
	booktitle = {2000 Canadian Conference on Electrical and Computer Engineering. Conference Proceedings. Navigating to a New Era},
	publisher = {{IEEE}},
	author = {Ward, M.K. and Stevenson, M.},
	urldate = {2024-06-24},
	date = {2000},
	note = {20 citations (Semantic Scholar/{DOI}) [2024-10-15]
7 citations (Crossref) [2024-10-14]},
}

@article{lohse_snapping_2001,
	title = {Snapping shrimp make flashing bubbles},
	volume = {413},
	rights = {http://www.springer.com/tdm},
	issn = {0028-0836, 1476-4687},
	url = {https://www.nature.com/articles/35097152},
	doi = {10.1038/35097152},
	pages = {477--478},
	number = {6855},
	journaltitle = {Nature},
	shortjournal = {Nature},
	author = {Lohse, Detlef and Schmitz, Barbara and Versluis, Michel},
	urldate = {2024-09-11},
	date = {2001-10},
	langid = {english},
	note = {100 citations (Semantic Scholar/{DOI}) [2024-10-15]
87 citations (Crossref) [2024-10-14]},
}

@article{andrew_ocean_2002,
	title = {Ocean ambient sound: Comparing the 1960s with the 1990s for a receiver off the California coast},
	volume = {3},
	issn = {1529-7853},
	url = {https://pubs.aip.org/asa/arlo/article/3/2/65-70/123823},
	doi = {10.1121/1.1461915},
	shorttitle = {Ocean ambient sound},
	pages = {65--70},
	number = {2},
	journaltitle = {Acoustics Research Letters Online},
	shortjournal = {Acoustics Research Letters Online},
	author = {Andrew, Rex K. and Howe, Bruce M. and Mercer, James A. and Dzieciuch, Matthew A.},
	urldate = {2024-09-11},
	date = {2002-04},
	langid = {english},
	note = {421 citations (Semantic Scholar/{DOI}) [2024-10-15]
293 citations (Crossref) [2024-10-14]},
}

@article{erbe_underwater_2002,
	title = {Underwater noise of whale‐watching boats and potential effects on killer whales based on an acoustic impact model},
	volume = {18},
	issn = {0824-0469, 1748-7692},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/j.1748-7692.2002.tb01045.x},
	doi = {10.1111/j.1748-7692.2002.tb01045.x},
	abstract = {Underwater noise of whale‐watching boats was recorded in the popular killer whale‐watching region of southern British Columbia and northwestern Washington State. A software sound propagation and impact assessment model was applied to estimate zones around whale‐watching boats where boat noise was audible to killer whales, where it interfered with their communication, where it caused behavioral avoidance, and where it possibly caused hearing loss. Boat source levels ranged from 145 to 169 {dB} re 1 μPa @ 1 m, increasing with speed. The noise of fast boats was modeled to be audible to killer whales over 16 km, to mask killer whale calls over 14 km, to elicit a behavioral response over 200 m, and to cause a temporary threshold shift ({TTS}) in hearing of 5 {dB} after 30–50 min within 450 m. For boats cruising at slow speeds, the predicted ranges were 1 km for audibility and masking, 50 m for behavioral responses, and 20 m for {TTS}. Superposed noise levels of a number of boats circulating around or following the whales were close to the critical level assumed to cause a permanent hearing loss over prolonged exposure. These data should be useful in developing whale‐watching regulations. This study also gave lower estimates of killer whale call source levels of 105–124 {dB} re 1 μPa.},
	pages = {394--418},
	number = {2},
	journaltitle = {Marine Mammal Science},
	shortjournal = {Marine Mammal Science},
	author = {Erbe, Christine},
	urldate = {2024-09-11},
	date = {2002-04},
	langid = {english},
	note = {305 citations (Semantic Scholar/{DOI}) [2024-10-15]
178 citations (Crossref) [2024-10-14]},
}

@article{tucker_classification_2005,
	title = {Classification of Transient Sonar Sounds Using Perceptually Motivated Features},
	volume = {30},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {0364-9059},
	url = {http://ieeexplore.ieee.org/document/1593805/},
	doi = {10.1109/JOE.2005.850910},
	pages = {588--600},
	number = {3},
	journaltitle = {{IEEE} Journal of Oceanic Engineering},
	shortjournal = {{IEEE} J. Oceanic Eng.},
	author = {Tucker, S. and Brown, G.J.},
	urldate = {2024-10-10},
	date = {2005-07},
	langid = {english},
	note = {56 citations (Semantic Scholar/{DOI}) [2024-10-15]
39 citations (Crossref) [2024-10-14]},
}

@article{bailey_simultaneous_2006,
	title = {Simultaneous localization and mapping ({SLAM}): part {II}},
	volume = {13},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {1070-9932},
	url = {http://ieeexplore.ieee.org/document/1678144/},
	doi = {10.1109/MRA.2006.1678144},
	shorttitle = {Simultaneous localization and mapping ({SLAM})},
	pages = {108--117},
	number = {3},
	journaltitle = {{IEEE} Robotics \& Automation Magazine},
	shortjournal = {{IEEE} Robot. Automat. Mag.},
	author = {Bailey, T. and Durrant-Whyte, H.},
	urldate = {2024-06-20},
	date = {2006-09},
	note = {2363 citations (Semantic Scholar/{DOI}) [2024-10-15]
1749 citations (Crossref) [2024-10-14]},
	keywords = {Initial reading list},
}

@article{hinton_fast_2006,
	title = {A Fast Learning Algorithm for Deep Belief Nets},
	volume = {18},
	issn = {0899-7667, 1530-888X},
	url = {https://direct.mit.edu/neco/article/18/7/1527-1554/7065},
	doi = {10.1162/neco.2006.18.7.1527},
	abstract = {We show how to use “complementary priors” to eliminate the explaining-away effects that make inference difficult in densely connected belief nets that have many hidden layers. Using complementary priors, we derive a fast, greedy algorithm that can learn deep, directed belief networks one layer at a time, provided the top two layers form an undirected associative memory. The fast, greedy algorithm is used to initialize a slower learning procedure that fine-tunes the weights using a contrastive version of the wake-sleep algorithm. After fine-tuning, a network with three hidden layers forms a very good generative model of the joint distribution of handwritten digit images and their labels. This generative model gives better digit classification than the best discriminative learning algorithms. The low-dimensional manifolds on which the digits lie are modeled by long ravines in the free-energy landscape of the top-level associative memory, and it is easy to explore these ravines by using the directed connections to display what the associative memory has in mind.},
	pages = {1527--1554},
	number = {7},
	journaltitle = {Neural Computation},
	shortjournal = {Neural Computation},
	author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee-Whye},
	urldate = {2024-08-14},
	date = {2006-07},
	langid = {english},
	note = {9999 citations (Semantic Scholar/{DOI}) [2024-10-15]
11562 citations (Crossref) [2024-10-14]},
	keywords = {{DBN}},
}

@article{dahl_underwater_2007,
	title = {Underwater Ambient Noise},
	volume = {3},
	issn = {1557-0215},
	url = {https://acousticstoday.org/issues/2007AT/Jan2007/#?page=24},
	doi = {10.1121/1.2961145},
	pages = {23},
	number = {1},
	journaltitle = {Acoustics Today},
	shortjournal = {Acou. Today},
	author = {Dahl, Peter H. and Miller, James H. and Cato, Douglas H. and Andrew, Rex K.},
	urldate = {2024-09-11},
	date = {2007},
	langid = {english},
	note = {322 citations (Semantic Scholar/{DOI}) [2024-10-15]
84 citations (Crossref) [2024-10-14]},
}

@article{darrigol_acoustic_2007,
	title = {The acoustic origins of harmonic analysis},
	volume = {61},
	issn = {0003-9519, 1432-0657},
	url = {https://link.springer.com/10.1007/s00407-007-0003-9},
	doi = {10.1007/s00407-007-0003-9},
	pages = {343--424},
	number = {4},
	journaltitle = {Archive for History of Exact Sciences},
	shortjournal = {Arch. Hist. Exact Sci.},
	author = {Darrigol, Olivier},
	urldate = {2024-09-11},
	date = {2007-07},
	langid = {english},
	note = {13 citations (Semantic Scholar/{DOI}) [2024-10-15]
10 citations (Crossref) [2024-10-14]},
}

@inproceedings{taegyun_lim_classification_2007,
	location = {Sharjah, United Arab Emirates},
	title = {Classification of underwater transient signals using {MFCC} feature vector},
	url = {http://ieeexplore.ieee.org/document/4555521/},
	doi = {10.1109/ISSPA.2007.4555521},
	eventtitle = {2007 9th International Symposium on Signal Processing and Its Applications ({ISSPA})},
	pages = {1--4},
	booktitle = {2007 9th International Symposium on Signal Processing and Its Applications},
	publisher = {{IEEE}},
	author = {{Taegyun Lim} and {Keunsung Bae} and {Chansik Hwang} and {Hyeonguk Lee}},
	urldate = {2024-10-09},
	date = {2007-02},
	note = {25 citations (Semantic Scholar/{DOI}) [2024-10-15]
5 citations (Crossref) [2024-10-14]},
}

@article{wysocki_diversity_2007,
	title = {Diversity in ambient noise in European freshwater habitats: Noise levels, spectral profiles, and impact on fishes},
	volume = {121},
	issn = {0001-4966, 1520-8524},
	url = {https://pubs.aip.org/jasa/article/121/5/2559/538519/Diversity-in-ambient-noise-in-European-freshwater},
	doi = {10.1121/1.2713661},
	shorttitle = {Diversity in ambient noise in European freshwater habitats},
	abstract = {The detectability of acoustic signals depends on the hearing abilities of receivers and the prevailing ambient noise in a given habitat. Ambient noise is inherent in all terrestrial and aquatic habitats and has the potential to severely mask relevant acoustic signals. In order to assess the detectability of sounds to fishes, the linear equivalent sound pressure levels ({LLeq}) of twelve European freshwater habitats were measured and spectra of the ambient noise recordings analyzed. Stagnant habitats such as lakes and backwaters are quiet, with noise levels below 100dB re 1{μPa} ({LLeq}) under no-wind conditions. Typically, most environmental noise is concentrated in the lower frequency range below 500Hz. Noise levels in fast-flowing waters were typically above 110dB and peaked at 135dB (Danube River in a free-flowing area). Contrary to stagnant habitats, high amounts of sound energy were present in the high frequency range above 1kHz, leaving a low-energy “noise window” below 1kHz. Comparisons between the habitat noise types presented here and prior data on auditory masking indicate that fishes with enhanced hearing abilities are only moderately masked in stagnant, quiet habitats, whereas they would be considerably masked in fast-flowing habitats.},
	pages = {2559--2566},
	number = {5},
	journaltitle = {The Journal of the Acoustical Society of America},
	author = {Wysocki, Lidia Eva and Amoser, Sonja and Ladich, Friedrich},
	urldate = {2024-09-11},
	date = {2007-05-01},
	langid = {english},
	note = {92 citations (Semantic Scholar/{DOI}) [2024-10-15]
74 citations (Crossref) [2024-10-14]},
}

@article{leroy_new_2008,
	title = {A new equation for the accurate calculation of sound speed in all oceans},
	volume = {124},
	issn = {0001-4966, 1520-8524},
	url = {https://pubs.aip.org/jasa/article/124/5/2774/910920/A-new-equation-for-the-accurate-calculation-of},
	doi = {10.1121/1.2988296},
	abstract = {A new equation is proposed for the calculation of sound speed in seawater as a function of temperature, salinity, depth, and latitude in all oceans and open seas, including the Baltic and the Black Sea. The proposed equation agrees to better than ±0.2m∕s with two reference complex equations, each fitting the best available data corresponding to existing waters of different salinities. The only exceptions are isolated hot brine spots that may be found at the bottom of some seas. The equation is of polynomial form, with 14 terms and coefficients of between one and three significant figures. This is a substantial reduction in complexity compared to the more complex equations using pressure that need to be calculated according to depth and location. The equation uses the 1990 universal temperature scale (an elementary transformation is given for data based on the 1968 temperature scale). It is hoped that the equation will be useful to those who need to calculate sound speed in applications of marine acoustics.},
	pages = {2774--2782},
	number = {5},
	journaltitle = {The Journal of the Acoustical Society of America},
	author = {Leroy, Claude C. and Robinson, Stephen P. and Goldsmith, Mike J.},
	urldate = {2024-09-12},
	date = {2008-11-01},
	langid = {english},
	note = {89 citations (Semantic Scholar/{DOI}) [2024-10-15]
74 citations (Crossref) [2024-10-14]},
}

@inproceedings{guo_underwater_2009,
	location = {St. Louis, {MO}, {USA}},
	title = {Underwater transient and non transient signals classification using predictive neural networks},
	isbn = {978-1-4244-3803-7},
	url = {http://ieeexplore.ieee.org/document/5354031/},
	doi = {10.1109/IROS.2009.5354031},
	eventtitle = {2009 {IEEE}/{RSJ} International Conference on Intelligent Robots and Systems ({IROS} 2009)},
	pages = {2283--2288},
	booktitle = {2009 {IEEE}/{RSJ} International Conference on Intelligent Robots and Systems},
	publisher = {{IEEE}},
	author = {Guo, Yan and Gas, Bruno},
	urldate = {2024-10-09},
	date = {2009-10},
	note = {4 citations (Semantic Scholar/{DOI}) [2024-10-15]
3 citations (Crossref) [2024-10-14]},
}

@article{kim_ell_1_2009,
	title = {\${\textbackslash}ell\_1\$ Trend Filtering},
	volume = {51},
	issn = {0036-1445, 1095-7200},
	url = {http://epubs.siam.org/doi/10.1137/070690274},
	doi = {10.1137/070690274},
	pages = {339--360},
	number = {2},
	journaltitle = {{SIAM} Review},
	shortjournal = {{SIAM} Rev.},
	author = {Kim, Seung-Jean and Koh, Kwangmoo and Boyd, Stephen and Gorinevsky, Dimitry},
	urldate = {2024-07-17},
	date = {2009-05},
	langid = {english},
	note = {569 citations (Semantic Scholar/{DOI}) [2024-10-15]
450 citations (Crossref) [2024-10-14]},
}

@article{lampert_survey_2010,
	title = {A survey of spectrogram track detection algorithms},
	volume = {71},
	rights = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {0003682X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0003682X09001959},
	doi = {10.1016/j.apacoust.2009.08.007},
	pages = {87--100},
	number = {2},
	journaltitle = {Applied Acoustics},
	shortjournal = {Applied Acoustics},
	author = {Lampert, Thomas A. and O’Keefe, Simon E.M.},
	urldate = {2024-08-13},
	date = {2010-02},
	langid = {english},
	note = {81 citations (Semantic Scholar/{DOI}) [2024-10-15]
55 citations (Crossref) [2024-10-14]},
}

@article{slabbekoorn_noisy_2010,
	title = {A noisy spring: the impact of globally rising underwater sound levels on fish},
	volume = {25},
	rights = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {01695347},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0169534710000832},
	doi = {10.1016/j.tree.2010.04.005},
	shorttitle = {A noisy spring},
	pages = {419--427},
	number = {7},
	journaltitle = {Trends in Ecology \& Evolution},
	shortjournal = {Trends in Ecology \& Evolution},
	author = {Slabbekoorn, Hans and Bouton, Niels and Van Opzeeland, Ilse and Coers, Aukje and Ten Cate, Carel and Popper, Arthur N.},
	urldate = {2024-09-11},
	date = {2010-07},
	langid = {english},
	note = {821 citations (Semantic Scholar/{DOI}) [2024-10-15]
690 citations (Crossref) [2024-10-14]},
}

@inproceedings{chen_detection_2011,
	location = {Hangzhou, China},
	title = {Detection of Underwater Acoustic Signal from Ship Noise Based on {WPT} Method},
	isbn = {978-1-4577-1798-7},
	url = {http://ieeexplore.ieee.org/document/6093547/},
	doi = {10.1109/IWCFTA.2011.27},
	eventtitle = {2011 Fourth International Workshop on Chaos-Fractals Theories and Applications ({IWCFTA})},
	pages = {324--327},
	booktitle = {2011 Fourth International Workshop on Chaos-Fractals Theories and Applications},
	publisher = {{IEEE}},
	author = {Chen, Sheng and Zhang, {HongHua}},
	urldate = {2024-10-09},
	date = {2011-10},
	note = {4 citations (Semantic Scholar/{DOI}) [2024-10-15]
1 citations (Crossref) [2024-10-14]},
}

@article{chung_demon_2011,
	title = {{DEMON} Acoustic Ship Signature Measurements in an Urban Harbor},
	volume = {2011},
	issn = {1687-6261, 1687-627X},
	url = {https://onlinelibrary.wiley.com/doi/10.1155/2011/952798},
	doi = {10.1155/2011/952798},
	abstract = {Detection, classification, and tracking of small vessels are important tasks for improving port security and the security of coastal and offshore operations. Hydroacoustic sensors can be applied for the detection of noise generated by vessels, and this noise can be used for vessel detection, classification, and tracking. This paper presents recent improvements aimed at the measurement and separation of ship {DEMON} (Detection of Envelope Modulation on Noise) {DEMON} acoustic signatures in busy harbor conditions. Ship signature measurements were conducted in the Hudson River and {NY} Harbor. The {DEMON} spectra demonstrated much better temporal stability compared with the full ship spectra and were measured at distances up to 7 km. The combination of cross‐correlation and methods allowed separation of the acoustic signatures of ships in busy urban environments.},
	pages = {952798},
	number = {1},
	journaltitle = {Advances in Acoustics and Vibration},
	shortjournal = {Advances in Acoustics and Vibration},
	author = {Chung, Kil Woo and Sutin, Alexander and Sedunov, Alexander and Bruno, Michael},
	editor = {Azad, Abul},
	urldate = {2024-09-09},
	date = {2011-01},
	langid = {english},
	note = {80 citations (Semantic Scholar/{DOI}) [2024-10-15]
51 citations (Crossref) [2024-10-14]},
}

@inproceedings{asja_fischer_introduction_2012,
	location = {Buenos Aires, Argentina},
	title = {An Introduction to Restricted Boltzmann Machines},
	doi = {10.1007/978-3-642-33275-3_2},
	abstract = {Restricted Boltzmann machines ({RBMs}) are probabilistic graphical models that can be interpreted as stochastic neural networks. The increase in computational power and the development of faster learning algorithms have made them applicable to relevant machine learning problems. They attracted much attention recently after being proposed as building blocks of multi-layer learning systems called deep belief networks. This tutorial introduces {RBMs} as undirected graphical models. The basic concepts of graphical models are introduced first, however, basic knowledge in statistics is presumed. Different learning algorithms for {RBMs} are discussed. As most of them are based on Markov chain Monte Carlo ({MCMC}) methods, an introduction to Markov chains and the required {MCMC} techniques is provided.},
	eventtitle = {Progress in Pattern Recognition, Image Analysis, Computer Vision, and Applications},
	pages = {14--36},
	booktitle = {Lecture Notes in Computer Science},
	publisher = {Springer},
	author = {{Asja Fischer} and Fischer, Asja and {Christian Igel} and Igel, Christian},
	date = {2012-09-03},
	doi = {10.1007/978-3-642-33275-3_2},
	note = {570 citations (Semantic Scholar/{DOI}) [2024-10-15]
297 citations (Crossref) [2024-10-14]
{MAG} {ID}: 2202505358},
	keywords = {{RBM}},
}

@misc{hinton_improving_2012,
	title = {Improving neural networks by preventing co-adaptation of feature detectors},
	url = {http://arxiv.org/abs/1207.0580},
	doi = {10.48550/arXiv.1207.0580},
	abstract = {When a large feedforward neural network is trained on a small training set, it typically performs poorly on held-out test data. This "overfitting" is greatly reduced by randomly omitting half of the feature detectors on each training case. This prevents complex co-adaptations in which a feature detector is only helpful in the context of several other specific feature detectors. Instead, each neuron learns to detect a feature that is generally helpful for producing the correct answer given the combinatorially large variety of internal contexts in which it must operate. Random "dropout" gives big improvements on many benchmark tasks and sets new records for speech and object recognition.},
	number = {{arXiv}:1207.0580},
	publisher = {{arXiv}},
	author = {Hinton, Geoffrey E. and Srivastava, Nitish and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan R.},
	urldate = {2024-09-16},
	date = {2012-07-03},
	eprinttype = {arxiv},
	eprint = {1207.0580 [cs]},
	note = {7420 citations (Semantic Scholar/{arXiv}) [2024-10-15]},
}

@article{mckenna_underwater_2012,
	title = {Underwater radiated noise from modern commercial ships},
	volume = {131},
	issn = {0001-4966, 1520-8524},
	url = {https://pubs.aip.org/jasa/article/131/1/92/822905/Underwater-radiated-noise-from-modern-commercial},
	doi = {10.1121/1.3664100},
	abstract = {Underwater radiated noise measurements for seven types of modern commercial ships during normal operating conditions are presented. Calibrated acoustic data (\&lt;1000 Hz) from an autonomous seafloor-mounted acoustic recorder were combined with ship passage information from the Automatic Identification System. This approach allowed for detailed measurements (i.e., source level, sound exposure level, and transmission range) on ships of opportunity. A key result was different acoustic levels and spectral shapes observed from different ship-types. A 54 {kGT} container ship had the highest broadband source level at 188 {dB} re 1{μPa}@1m; a 26 {kGT} chemical tanker had the lowest at 177 {dB} re 1{μPa}@1m. Bulk carriers had higher source levels near 100 Hz, while container ship and tanker noise was predominantly below 40 Hz. Simple models to predict source levels of modern merchant ships as a group from particular ship characteristics (e.g., length, gross tonnage, and speed) were not possible given individual ship-type differences. Furthermore, ship noise was observed to radiate asymmetrically. Stern aspect noise levels are 5 to 10 {dB} higher than bow aspect noise levels. Collectively, these results emphasize the importance of including modern ship-types in quantifying shipping noise for predictive models of global, regional, and local marine environments.},
	pages = {92--103},
	number = {1},
	journaltitle = {The Journal of the Acoustical Society of America},
	author = {{McKenna}, Megan F. and Ross, Donald and Wiggins, Sean M. and Hildebrand, John A.},
	urldate = {2024-09-09},
	date = {2012-01-01},
	langid = {english},
	note = {394 citations (Semantic Scholar/{DOI}) [2024-10-15]
319 citations (Crossref) [2024-10-14]},
}

@article{bengio_representation_2013,
	title = {Representation Learning: A Review and New Perspectives},
	volume = {35},
	doi = {10.1109/tpami.2013.50},
	abstract = {The success of machine learning algorithms generally depends on data representation, and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data. Although specific domain knowledge can be used to help design representations, learning with generic priors can also be used, and the quest for {AI} is motivating the design of more powerful representation-learning algorithms implementing such priors. This paper reviews recent work in the area of unsupervised feature learning and deep learning, covering advances in probabilistic models, autoencoders, manifold learning, and deep networks. This motivates longer term unanswered questions about the appropriate objectives for learning good representations, for computing representations (i.e., inference), and the geometrical connections between representation learning, density estimation, and manifold learning.},
	pages = {1798--1828},
	number = {8},
	journaltitle = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence},
	author = {Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
	date = {2013-08-01},
	doi = {10.1109/tpami.2013.50},
	note = {9997 citations (Semantic Scholar/{DOI}) [2024-10-15]
8018 citations (Crossref) [2024-10-14]
{MAG} {ID}: 2163922914},
}

@misc{girshick_rich_2013,
	title = {Rich feature hierarchies for accurate object detection and semantic segmentation},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/1311.2524},
	doi = {10.48550/ARXIV.1311.2524},
	abstract = {Object detection performance, as measured on the canonical {PASCAL} {VOC} dataset, has plateaued in the last few years. The best-performing methods are complex ensemble systems that typically combine multiple low-level image features with high-level context. In this paper, we propose a simple and scalable detection algorithm that improves mean average precision ({mAP}) by more than 30\% relative to the previous best result on {VOC} 2012---achieving a {mAP} of 53.3\%. Our approach combines two key insights: (1) one can apply high-capacity convolutional neural networks ({CNNs}) to bottom-up region proposals in order to localize and segment objects and (2) when labeled training data is scarce, supervised pre-training for an auxiliary task, followed by domain-specific fine-tuning, yields a significant performance boost. Since we combine region proposals with {CNNs}, we call our method R-{CNN}: Regions with {CNN} features. We also compare R-{CNN} to {OverFeat}, a recently proposed sliding-window detector based on a similar {CNN} architecture. We find that R-{CNN} outperforms {OverFeat} by a large margin on the 200-class {ILSVRC}2013 detection dataset. Source code for the complete system is available at http://www.cs.berkeley.edu/{\textasciitilde}rbg/rcnn.},
	publisher = {{arXiv}},
	author = {Girshick, Ross and Donahue, Jeff and Darrell, Trevor and Malik, Jitendra},
	urldate = {2024-09-23},
	date = {2013},
	note = {9999 citations (Semantic Scholar/{arXiv}) [2024-10-15]
Version Number: 5},
}

@inproceedings{kamal_deep_2013,
	location = {Kochi, India},
	title = {Deep learning architectures for underwater target recognition},
	isbn = {978-93-80095-45-5},
	url = {http://ieeexplore.ieee.org/document/6701911/},
	doi = {10.1109/SYMPOL.2013.6701911},
	eventtitle = {2013 International Symposium on Ocean Electronics ({SYMPOL})},
	pages = {48--54},
	booktitle = {2013 Ocean Electronics ({SYMPOL})},
	publisher = {{IEEE}},
	author = {Kamal, Suraj and Mohammed, Shameer K. and Pillai, P. R. Saseendran and Supriya, M. H.},
	urldate = {2024-08-14},
	date = {2013-10},
	note = {52 citations (Semantic Scholar/{DOI}) [2024-10-15]
42 citations (Crossref) [2024-10-14]},
}

@article{roth_underwater_2013,
	title = {Underwater radiated noise levels of a research icebreaker in the central Arctic Ocean},
	volume = {133},
	issn = {0001-4966, 1520-8524},
	url = {https://pubs.aip.org/jasa/article/133/4/1971/916031/Underwater-radiated-noise-levels-of-a-research},
	doi = {10.1121/1.4790356},
	abstract = {U.S. Coast Guard Cutter Healy's underwater radiated noise signature was characterized in the central Arctic Ocean during different types of ice-breaking operations. Propulsion modes included transit in variable ice cover, breaking heavy ice with backing-and-ramming maneuvers, and dynamic positioning with the bow thruster in operation. Compared to open-water transit, Healy's noise signature increased approximately 10 {dB} between 20 Hz and 2 {kHz} when breaking ice. The highest noise levels resulted while the ship was engaged in backing-and-ramming maneuvers, owing to cavitation when operating the propellers astern or in opposing directions. In frequency bands centered near 10, 50, and 100 Hz, source levels reached 190–200 {dB} re: 1 μPa at 1 m (full octave band) during ice-breaking operations.},
	pages = {1971--1980},
	number = {4},
	journaltitle = {The Journal of the Acoustical Society of America},
	author = {Roth, Ethan H and Schmidt, Val and Hildebrand, John A. and Wiggins, Sean M.},
	urldate = {2024-09-09},
	date = {2013-04-01},
	langid = {english},
	note = {26 citations (Semantic Scholar/{DOI}) [2024-10-15]
17 citations (Crossref) [2024-10-14]},
}

@misc{zeiler_visualizing_2013,
	title = {Visualizing and Understanding Convolutional Networks},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/1311.2901},
	doi = {10.48550/ARXIV.1311.2901},
	abstract = {Large Convolutional Network models have recently demonstrated impressive classification performance on the {ImageNet} benchmark. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we address both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. We also perform an ablation study to discover the performance contribution from different model layers. This enables us to find model architectures that outperform Krizhevsky {\textbackslash}etal on the {ImageNet} classification benchmark. We show our {ImageNet} model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.},
	publisher = {{arXiv}},
	author = {Zeiler, Matthew D and Fergus, Rob},
	urldate = {2024-09-23},
	date = {2013},
	note = {9999 citations (Semantic Scholar/{arXiv}) [2024-10-15]
Version Number: 3},
}

@article{fischer_training_2014,
	title = {Training restricted Boltzmann machines: An introduction},
	volume = {47},
	issn = {00313203},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0031320313002495},
	doi = {10.1016/j.patcog.2013.05.025},
	shorttitle = {Training restricted Boltzmann machines},
	pages = {25--39},
	number = {1},
	journaltitle = {Pattern Recognition},
	shortjournal = {Pattern Recognition},
	author = {Fischer, Asja and Igel, Christian},
	urldate = {2024-06-20},
	date = {2014-01},
	langid = {english},
	note = {463 citations (Semantic Scholar/{DOI}) [2024-10-15]
343 citations (Crossref) [2024-10-14]},
	keywords = {Initial reading list, {RBM}},
}

@inproceedings{li_method_2014,
	location = {Hangzhou, Zhejiang, China},
	title = {A method based on wavelet packets-fractal and {SVM} for underwater acoustic signals recognition},
	isbn = {978-1-4799-2186-7 978-1-4799-2188-1 978-1-4799-2187-4},
	url = {http://ieeexplore.ieee.org/document/7015379/},
	doi = {10.1109/ICOSP.2014.7015379},
	eventtitle = {2014 12th International Conference on Signal Processing ({ICSP} 2014)},
	pages = {2169--2173},
	booktitle = {2014 12th International Conference on Signal Processing ({ICSP})},
	publisher = {{IEEE}},
	author = {Li, Haitao and Cheng, Yusheng and Dai, Weiguo and Li, Zhizhong},
	urldate = {2024-10-09},
	date = {2014-10},
	note = {11 citations (Semantic Scholar/{DOI}) [2024-10-15]
8 citations (Crossref) [2024-10-14]},
}

@misc{makhzani_k-sparse_2014,
	title = {k-Sparse Autoencoders},
	url = {http://arxiv.org/abs/1312.5663},
	doi = {10.48550/arXiv.1312.5663},
	abstract = {Recently, it has been observed that when representations are learnt in a way that encourages sparsity, improved performance is obtained on classification tasks. These methods involve combinations of activation functions, sampling steps and different kinds of penalties. To investigate the effectiveness of sparsity by itself, we propose the k-sparse autoencoder, which is an autoencoder with linear activation function, where in hidden layers only the k highest activities are kept. When applied to the {MNIST} and {NORB} datasets, we find that this method achieves better classification results than denoising autoencoders, networks trained with dropout, and {RBMs}. k-sparse autoencoders are simple to train and the encoding stage is very fast, making them well-suited to large problem sizes, where conventional sparse coding algorithms cannot be applied.},
	number = {{arXiv}:1312.5663},
	publisher = {{arXiv}},
	author = {Makhzani, Alireza and Frey, Brendan},
	urldate = {2024-09-16},
	date = {2014-03-22},
	eprinttype = {arxiv},
	eprint = {1312.5663 [cs]},
	note = {391 citations (Semantic Scholar/{arXiv}) [2024-10-15]},
}

@article{wang_robust_2014,
	title = {Robust underwater noise targets classification using auditory inspired time–frequency analysis},
	volume = {78},
	issn = {0003682X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0003682X13002624},
	doi = {10.1016/j.apacoust.2013.11.003},
	pages = {68--76},
	journaltitle = {Applied Acoustics},
	shortjournal = {Applied Acoustics},
	author = {Wang, Shuguang and Zeng, Xiangyang},
	urldate = {2024-10-10},
	date = {2014-04},
	langid = {english},
	note = {114 citations (Semantic Scholar/{DOI}) [2024-10-15]
112 citations (Crossref) [2024-10-14]},
}

@inproceedings{wu_robust_2014,
	location = {Taipei, Taiwan},
	title = {Robust underwater target recognition using auditory cepstral coefficients},
	isbn = {978-1-4799-3646-5 978-1-4799-3645-8},
	url = {http://ieeexplore.ieee.org/document/6964335/},
	doi = {10.1109/OCEANS-TAIPEI.2014.6964335},
	eventtitle = {{OCEANS} 2014 - {TAIPEI}},
	pages = {1--4},
	booktitle = {{OCEANS} 2014 - {TAIPEI}},
	publisher = {{IEEE}},
	author = {Wu, Yaozhen and Yang, Yixin and Tao, Can and Tian, Feng and Yang, Long},
	urldate = {2024-10-10},
	date = {2014-04},
	note = {3 citations (Semantic Scholar/{DOI}) [2024-10-15]
3 citations (Crossref) [2024-10-14]},
}

@inproceedings{zeng_underwater_2014,
	location = {Guilin, Guangxi, China},
	title = {Underwater sound classification based on Gammatone filter bank and Hilbert-Huang transform},
	isbn = {978-1-4799-5274-8 978-1-4799-5272-4},
	url = {http://ieeexplore.ieee.org/document/6986287/},
	doi = {10.1109/ICSPCC.2014.6986287},
	eventtitle = {2014 {IEEE} International Conference on Signal Processing, Communications and Computing ({ICSPCC})},
	pages = {707--710},
	booktitle = {2014 {IEEE} International Conference on Signal Processing, Communications and Computing ({ICSPCC})},
	publisher = {{IEEE}},
	author = {Zeng, Xiangyang and Wang, Shuguang},
	urldate = {2024-10-10},
	date = {2014-08},
	note = {12 citations (Semantic Scholar/{DOI}) [2024-10-15]
10 citations (Crossref) [2024-10-14]},
}

@misc{girshick_fast_2015,
	title = {Fast R-{CNN}},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/1504.08083},
	doi = {10.48550/ARXIV.1504.08083},
	abstract = {This paper proposes a Fast Region-based Convolutional Network method (Fast R-{CNN}) for object detection. Fast R-{CNN} builds on previous work to efficiently classify object proposals using deep convolutional networks. Compared to previous work, Fast R-{CNN} employs several innovations to improve training and testing speed while also increasing detection accuracy. Fast R-{CNN} trains the very deep {VGG}16 network 9x faster than R-{CNN}, is 213x faster at test-time, and achieves a higher {mAP} on {PASCAL} {VOC} 2012. Compared to {SPPnet}, Fast R-{CNN} trains {VGG}16 3x faster, tests 10x faster, and is more accurate. Fast R-{CNN} is implemented in Python and C++ (using Caffe) and is available under the open-source {MIT} License at https://github.com/rbgirshick/fast-rcnn.},
	publisher = {{arXiv}},
	author = {Girshick, Ross},
	urldate = {2024-09-23},
	date = {2015},
	note = {9999 citations (Semantic Scholar/{arXiv}) [2024-10-15]
Version Number: 2},
}

@misc{ronneberger_u-net_2015,
	title = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
	url = {http://arxiv.org/abs/1505.04597},
	shorttitle = {U-Net},
	abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the {ISBI} challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and {DIC}) we won the {ISBI} cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent {GPU}. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .},
	number = {{arXiv}:1505.04597},
	publisher = {{arXiv}},
	author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	urldate = {2024-09-23},
	date = {2015-05-18},
	eprinttype = {arxiv},
	eprint = {1505.04597 [cs]},
	note = {9999 citations (Semantic Scholar/{arXiv}) [2024-10-15]},
}

@inproceedings{sherin_b_m_selection_2015,
	location = {Chennai, India},
	title = {Selection and parameter optimization of {SVM} kernel function for underwater target classification},
	isbn = {978-1-4799-8300-1},
	url = {http://ieeexplore.ieee.org/document/7108260/},
	doi = {10.1109/UT.2015.7108260},
	abstract = {The identification and classification of noise sources in the ocean has become a key task of modern underwater acoustic signal processing and because of the ever changing and complicated oceanic environment, underwater target classification has become a demanding task. An underwater acoustic target classification system identifies the acoustic target from the characteristic acoustic signature. The characteristic acoustic signatures are patterned by feature recognition algorithms operating on data captured by hydrophone. In this paper, an {SVM} classifier works on the acoustic signatures of four different target types. The performance of the classifier depends on a variety of factors, of which {SVM} parameter tuning is very important. Several attempts have been made for automatic kernel selection and parameter optimization, including meta-heuristic algorithms such as genetic algorithms ({GA}) and particle swarm optimization ({PSO}). This paper attempts towards selection of {SVM} parameters, kernel and kernel parameter optimization using the {BAT} algorithm. The results indicate higher classification accuracy when compared to {PSO} based selection and optimization.},
	eventtitle = {2015 {IEEE} Underwater Technology ({UT})},
	pages = {1--5},
	booktitle = {2015 {IEEE} Underwater Technology ({UT})},
	publisher = {{IEEE}},
	author = {{Sherin B. M.} and {Supriya M. H.}},
	urldate = {2024-10-10},
	date = {2015-02},
	langid = {english},
	note = {32 citations (Semantic Scholar/{DOI}) [2024-10-15]
16 citations (Crossref) [2024-10-14]},
}

@inproceedings{cao_deep_2016,
	location = {Beijing, China},
	title = {Deep learning-based recognition of underwater target},
	isbn = {978-1-5090-4165-7},
	url = {http://ieeexplore.ieee.org/document/7868522/},
	doi = {10.1109/ICDSP.2016.7868522},
	eventtitle = {2016 {IEEE} International Conference on Digital Signal Processing ({DSP})},
	pages = {89--93},
	booktitle = {2016 {IEEE} International Conference on Digital Signal Processing ({DSP})},
	publisher = {{IEEE}},
	author = {Cao, Xu and Zhang, Xiaomin and Yu, Yang and Niu, Letian},
	urldate = {2024-08-14},
	date = {2016-10},
	note = {60 citations (Semantic Scholar/{DOI}) [2024-10-15]
45 citations (Crossref) [2024-10-14]},
}

@article{david_santos-dominguez_shipsear_2016,
	title = {{ShipsEar}: An underwater vessel noise database},
	volume = {113},
	doi = {10.1016/j.apacoust.2016.06.008},
	abstract = {Abstract   There is a manifest shortage of audio databases available to underwater acoustics researchers. With the aim of palliating this situation, {ShipsEar}, a database of underwater recordings of ship and boat sounds, has been made available to the research community at  http://atlanttic.uvigo.es/underwaternoise/ . The database is currently composed of 90 records representing sounds from 11 vessel types. It includes detailed information on technical aspects of the recordings and environmental and other conditions during acquisition. To demonstrate the usefulness of {ShipsEar}, a vessel classifier was developed, based on cepstral coefficients and Gaussian mixture models. It was tested on a subset of {ShipsEar} database in which the original 11 vessel types were merged into 4 vessel size classes. The system yielded an overall classification rate of 75.4\%, and 100\% accuracy in detecting vessel presence. {ShipsEar} is potentially useful for the development and testing of applications based on processing underwater vessel sound.},
	pages = {64--69},
	number = {113},
	journaltitle = {Applied Acoustics},
	author = {{David Santos-Domínguez} and {Soledad Torres-Guijarro} and {Antonio Cardenal-López} and Pena-Gimenez, Antonio},
	date = {2016-12-01},
	doi = {10.1016/j.apacoust.2016.06.008},
	note = {230 citations (Semantic Scholar/{DOI}) [2024-10-15]
221 citations (Crossref) [2024-10-14]
{MAG} {ID}: 2466903746},
}

@article{li_feature_2016,
	title = {Feature Extraction of Ship-Radiated Noise Based on Permutation Entropy of the Intrinsic Mode Function with the Highest Energy},
	volume = {18},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1099-4300},
	url = {https://www.mdpi.com/1099-4300/18/11/393},
	doi = {10.3390/e18110393},
	abstract = {In order to solve the problem of feature extraction of underwater acoustic signals in complex ocean environment, a new method for feature extraction from ship-radiated noise is presented based on empirical mode decomposition theory and permutation entropy. It analyzes the separability for permutation entropies of the intrinsic mode functions of three types of ship-radiated noise signals, and discusses the permutation entropy of the intrinsic mode function with the highest energy. In this study, ship-radiated noise signals measured from three types of ships are decomposed into a set of intrinsic mode functions with empirical mode decomposition method. Then, the permutation entropies of all intrinsic mode functions are calculated with appropriate parameters. The permutation entropies are obviously different in the intrinsic mode functions with the highest energy, thus, the permutation entropy of the intrinsic mode function with the highest energy is regarded as a new characteristic parameter to extract the feature of ship-radiated noise. After that, the characteristic parameters—namely, the energy difference between high and low frequency, permutation entropy, and multi-scale permutation entropy—are compared with the permutation entropy of the intrinsic mode function with the highest energy. It is discovered that the four characteristic parameters are at the same level for similar ships, however, there are differences in the parameters for different types of ships. The results demonstrate that the permutation entropy of the intrinsic mode function with the highest energy is better in separability as the characteristic parameter than the other three parameters by comparing their fluctuation ranges and the average values of the four characteristic parameters. Hence, the feature of ship-radiated noise can be extracted efficiently with the method.},
	pages = {393},
	number = {11},
	journaltitle = {Entropy},
	shortjournal = {Entropy},
	author = {Li, Yu-Xing and Li, Ya-An and Chen, Zhe and Chen, Xiao},
	urldate = {2024-10-09},
	date = {2016-11-11},
	langid = {english},
	note = {57 citations (Semantic Scholar/{DOI}) [2024-10-15]
31 citations (Crossref) [2024-10-14]},
}

@article{siddagangaiah_complexity-based_2016,
	title = {A Complexity-Based Approach for the Detection of Weak Signals in Ocean Ambient Noise},
	volume = {18},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1099-4300},
	url = {https://www.mdpi.com/1099-4300/18/3/101},
	doi = {10.3390/e18030101},
	abstract = {There are numerous studies showing that there is a constant increase in the ocean ambient noise level and the ever-growing demand for developing algorithms for detecting weak signals in ambient noise. In this study, we utilize dynamical and statistical complexity to detect the presence of weak ship noise embedded in ambient noise. The ambient noise and ship noise were recorded in the South China Sea. The multiscale entropy ({MSE}) method and the complexity-entropy causality plane (C-H plane) were used to quantify the dynamical and statistical complexity of the measured time series, respectively. We generated signals with varying signal-to-noise ratio ({SNR}) by varying the amplification of a ship signal. The simulation results indicate that the complexity is sensitive to change in the information in the ambient noise and the change in {SNR}, a finding that enables the detection of weak ship signals in strong background ambient noise. The simulation results also illustrate that complexity is better than the traditional spectrogram method, particularly effective for detecting low {SNR} signals in ambient noise. In addition, complexity-based {MSE} and C-H plane methods are simple, robust and do not assume any underlying dynamics in time series. Hence, complexity should be used in practical situations.},
	pages = {101},
	number = {3},
	journaltitle = {Entropy},
	shortjournal = {Entropy},
	author = {Siddagangaiah, Shashidhar and Li, Yaan and Guo, Xijing and Chen, Xiao and Zhang, Qunfei and Yang, Kunde and Yang, Yixin},
	urldate = {2024-10-10},
	date = {2016-03-18},
	langid = {english},
	note = {52 citations (Semantic Scholar/{DOI}) [2024-10-15]
52 citations (Crossref) [2024-10-14]},
}

@article{veirs_ship_2016,
	title = {Ship noise extends to frequencies used for echolocation by endangered killer whales},
	volume = {4},
	rights = {http://creativecommons.org/licenses/by/4.0/},
	issn = {2167-8359},
	url = {https://peerj.com/articles/1657},
	doi = {10.7717/peerj.1657},
	abstract = {Combining calibrated hydrophone measurements with vessel location data from the Automatic Identification System, we estimate underwater sound pressure levels for 1,582 unique ships that transited the core critical habitat of the endangered Southern Resident killer whales during 28 months between March, 2011, and October, 2013. Median received spectrum levels of noise from 2,809 isolated transits are elevated relative to median background levels not only at low frequencies (20–30 {dB} re 1 µPa
              2
              /Hz from 100 to 1,000 Hz), but also at high frequencies (5–13 {dB} from 10,000 to 96,000 Hz). Thus, noise received from ships at ranges less than 3 km extends to frequencies used by odontocetes. Broadband received levels (11.5–40,000 Hz) near the shoreline in Haro Strait ({WA}, {USA}) for the entire ship population were 110 ± 7 {dB} re 1 µPa on average. Assuming near-spherical spreading based on a transmission loss experiment we compute mean broadband source levels for the ship population of 173 ± 7 {dB} re 1 µPa 1 m without accounting for frequency-dependent absorption. Mean ship speed was 7.3 ± 2.0 m/s (14.1 ± 3.9 knots). Most ship classes show a linear relationship between source level and speed with a slope near +2 {dB} per m/s (+1 {dB}/knot). Spectrum, 1/12-octave, and 1/3-octave source levels for the whole population have median values that are comparable to previous measurements and models at most frequencies, but for select studies may be relatively low below 200 Hz and high above 20,000 Hz. Median source spectrum levels peak near 50 Hz for all 12 ship classes, have a maximum of 159 {dB} re 1 µPa
              2
              /Hz @ 1 m for container ships, and vary between classes. Below 200 Hz, the class-specific median spectrum levels bifurcate with large commercial ships grouping as higher power noise sources. Within all ship classes spectrum levels vary more at low frequencies than at high frequencies, and the degree of variability is almost halved for classes that have smaller speed standard deviations. This is the first study to present source spectra for populations of different ship classes operating in coastal habitats, including at higher frequencies used by killer whales for both communication and echolocation.},
	pages = {e1657},
	journaltitle = {{PeerJ}},
	author = {Veirs, Scott and Veirs, Val and Wood, Jason D.},
	urldate = {2024-10-10},
	date = {2016-02-02},
	langid = {english},
	note = {141 citations (Semantic Scholar/{DOI}) [2024-10-15]
109 citations (Crossref) [2024-10-14]},
}

@article{xu_stacked_2016,
	title = {Stacked Sparse Autoencoder ({SSAE}) for Nuclei Detection on Breast Cancer Histopathology Images},
	volume = {35},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {0278-0062, 1558-254X},
	url = {http://ieeexplore.ieee.org/document/7163353/},
	doi = {10.1109/TMI.2015.2458702},
	pages = {119--130},
	number = {1},
	journaltitle = {{IEEE} Transactions on Medical Imaging},
	shortjournal = {{IEEE} Trans. Med. Imaging},
	author = {Xu, Jun and Xiang, Lei and Liu, Qingshan and Gilmore, Hannah and Wu, Jianzhong and Tang, Jinghai and Madabhushi, Anant},
	urldate = {2024-09-03},
	date = {2016-01},
	note = {757 citations (Semantic Scholar/{DOI}) [2024-10-15]
661 citations (Crossref) [2024-10-14]},
}

@article{akeret_radio_2017,
	title = {Radio frequency interference mitigation using deep convolutional neural networks},
	volume = {18},
	issn = {22131337},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2213133716301056},
	doi = {10.1016/j.ascom.2017.01.002},
	pages = {35--39},
	journaltitle = {Astronomy and Computing},
	shortjournal = {Astronomy and Computing},
	author = {Akeret, J. and Chang, C. and Lucchi, A. and Refregier, A.},
	urldate = {2024-08-05},
	date = {2017-01},
	langid = {english},
	note = {143 citations (Semantic Scholar/{DOI}) [2024-10-15]
136 citations (Crossref) [2024-10-14]},
}

@article{akeret_hide_2017,
	title = {{HIDE} \& {SEEK}: End-to-end packages to simulate and process radio survey data},
	volume = {18},
	issn = {22131337},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2213133716300695},
	doi = {10.1016/j.ascom.2016.11.001},
	shorttitle = {{HIDE} \& {SEEK}},
	pages = {8--17},
	journaltitle = {Astronomy and Computing},
	shortjournal = {Astronomy and Computing},
	author = {Akeret, J. and Seehars, S. and Chang, C. and Monstein, C. and Amara, A. and Refregier, A.},
	urldate = {2024-08-05},
	date = {2017-01},
	langid = {english},
	note = {16 citations (Semantic Scholar/{DOI}) [2024-10-15]
21 citations (Crossref) [2024-10-14]},
}

@misc{he_mask_2017,
	title = {Mask R-{CNN}},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/1703.06870},
	doi = {10.48550/ARXIV.1703.06870},
	abstract = {We present a conceptually simple, flexible, and general framework for object instance segmentation. Our approach efficiently detects objects in an image while simultaneously generating a high-quality segmentation mask for each instance. The method, called Mask R-{CNN}, extends Faster R-{CNN} by adding a branch for predicting an object mask in parallel with the existing branch for bounding box recognition. Mask R-{CNN} is simple to train and adds only a small overhead to Faster R-{CNN}, running at 5 fps. Moreover, Mask R-{CNN} is easy to generalize to other tasks, e.g., allowing us to estimate human poses in the same framework. We show top results in all three tracks of the {COCO} suite of challenges, including instance segmentation, bounding-box object detection, and person keypoint detection. Without bells and whistles, Mask R-{CNN} outperforms all existing, single-model entries on every task, including the {COCO} 2016 challenge winners. We hope our simple and effective approach will serve as a solid baseline and help ease future research in instance-level recognition. Code has been made available at: https://github.com/facebookresearch/Detectron},
	publisher = {{arXiv}},
	author = {He, Kaiming and Gkioxari, Georgia and Dollár, Piotr and Girshick, Ross},
	urldate = {2024-09-23},
	date = {2017},
	note = {9999 citations (Semantic Scholar/{arXiv}) [2024-10-15]
Version Number: 3},
}

@misc{kendall_what_2017,
	title = {What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/1703.04977},
	doi = {10.48550/ARXIV.1703.04977},
	abstract = {There are two major types of uncertainty one can model. Aleatoric uncertainty captures noise inherent in the observations. On the other hand, epistemic uncertainty accounts for uncertainty in the model -- uncertainty which can be explained away given enough data. Traditionally it has been difficult to model epistemic uncertainty in computer vision, but with new Bayesian deep learning tools this is now possible. We study the benefits of modeling epistemic vs. aleatoric uncertainty in Bayesian deep learning models for vision tasks. For this we present a Bayesian deep learning framework combining input-dependent aleatoric uncertainty together with epistemic uncertainty. We study models under the framework with per-pixel semantic segmentation and depth regression tasks. Further, our explicit uncertainty formulation leads to new loss functions for these tasks, which can be interpreted as learned attenuation. This makes the loss more robust to noisy data, also giving new state-of-the-art results on segmentation and depth regression benchmarks.},
	publisher = {{arXiv}},
	author = {Kendall, Alex and Gal, Yarin},
	urldate = {2024-07-17},
	date = {2017},
	note = {4205 citations (Semantic Scholar/{arXiv}) [2024-10-15]
Version Number: 2},
}

@article{li_novel_2017,
	title = {A Novel Feature Extraction Method for Ship-Radiated Noise Based on Variational Mode Decomposition and Multi-Scale Permutation Entropy},
	volume = {19},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1099-4300},
	url = {https://www.mdpi.com/1099-4300/19/7/342},
	doi = {10.3390/e19070342},
	abstract = {In view of the problem that the features of ship-radiated noise are difficult to extract and inaccurate, a novel method based on variational mode decomposition ({VMD}), multi-scale permutation entropy ({MPE}) and a support vector machine ({SVM}) is proposed to extract the features of ship-radiated noise. In order to eliminate mode mixing and extract the complexity of the intrinsic mode function ({IMF}) accurately, {VMD} is employed to decompose the three types of ship-radiated noise instead of Empirical Mode Decomposition ({EMD}) and its extended methods. Considering the reason that the permutation entropy ({PE}) can quantify the complexity only in one scale, the {MPE} is used to extract features in different scales. In this study, three types of ship-radiated noise signals are decomposed into a set of band-limited {IMFs} by the {VMD} method, and the intensity of each {IMF} is calculated. Then, the {IMFs} with the highest energy are selected for the extraction of their {MPE}. By analyzing the separability of {MPE} at different scales, the optimal {MPE} of the {IMF} with the highest energy is regarded as the characteristic vector. Finally, the feature vectors are sent into the {SVM} classifier to classify and recognize different types of ships. The proposed method was applied in simulated signals and actual signals of ship-radiated noise. By comparing with the {PE} of the {IMF} with the highest energy by {EMD}, ensemble {EMD} ({EEMD}) and {VMD}, the results show that the proposed method can effectively extract the features of {MPE} and realize the classification and recognition for ships.},
	pages = {342},
	number = {7},
	journaltitle = {Entropy},
	shortjournal = {Entropy},
	author = {Li, Yuxing and Li, Yaan and Chen, Xiao and Yu, Jing},
	urldate = {2024-10-09},
	date = {2017-07-08},
	langid = {english},
	note = {68 citations (Semantic Scholar/{DOI}) [2024-10-15]
68 citations (Crossref) [2024-10-14]},
}

@inproceedings{lian_underwater_2017,
	location = {Chongqing, China},
	title = {Underwater acoustic target classification based on modified {GFCC} features},
	isbn = {978-1-4673-8979-2},
	url = {http://ieeexplore.ieee.org/document/8054017/},
	doi = {10.1109/IAEAC.2017.8054017},
	eventtitle = {2017 {IEEE} 2nd Advanced Information Technology, Electronic and Automation Control Conference ({IAEAC})},
	pages = {258--262},
	booktitle = {2017 {IEEE} 2nd Advanced Information Technology, Electronic and Automation Control Conference ({IAEAC})},
	publisher = {{IEEE}},
	author = {Lian, Zixu and Xu, Ke and Wan, Jianwei and Li, Gang},
	urldate = {2024-10-09},
	date = {2017-03},
	note = {18 citations (Semantic Scholar/{DOI}) [2024-10-15]
16 citations (Crossref) [2024-10-14]},
}

@article{yan_ship_2017,
	title = {Ship Radiated Noise Recognition Using Resonance-Based Sparse Signal Decomposition},
	volume = {2017},
	rights = {http://creativecommons.org/licenses/by/4.0/},
	issn = {1070-9622, 1875-9203},
	url = {https://www.hindawi.com/journals/sv/2017/6930605/},
	doi = {10.1155/2017/6930605},
	abstract = {Under the complex oceanic environment, robust and effective feature extraction is the key issue of ship radiated noise recognition. Since traditional feature extraction methods are susceptible to the inevitable environmental noise, the type of vessels, and the speed of ships, the recognition accuracy will degrade significantly. Hence, we propose a robust time-frequency analysis method which combines resonance-based sparse signal decomposition ({RSSD}) and Hilbert marginal spectrum ({HMS}) analysis. First, the observed signals are decomposed into high resonance component, low resonance component, and residual component by {RSSD}, which is a nonlinear signal analysis method based not on frequency or scale but on resonance. High resonance component is multiple simultaneous sustained oscillations, low resonance component is nonoscillatory transients, and residual component is white Gaussian noises. According to the low-frequency periodic oscillatory characteristic of ship radiated noise, high resonance component is the purified ship radiated noise. {RSSD} is suited to noise suppression for low-frequency oscillation signals. Second, {HMS} of high resonance component is extracted by Hilbert-Huang transform ({HHT}) as the feature vector. Finally, support vector machine ({SVM}) is adopted as a classifier. Real audio recordings are employed in the experiments under different signal-to-noise ratios ({SNRs}). The experimental results indicate that the proposed method has a better recognition performance than the traditional method under different {SNRs}.},
	pages = {1--9},
	journaltitle = {Shock and Vibration},
	shortjournal = {Shock and Vibration},
	author = {Yan, Jiaquan and Sun, Haixin and Cheng, En and Kuai, Xiaoyan and Zhang, Xiaoliang},
	urldate = {2024-10-10},
	date = {2017},
	langid = {english},
	note = {9 citations (Semantic Scholar/{DOI}) [2024-10-15]
4 citations (Crossref) [2024-10-14]},
}

@article{yang_performance_2017,
	title = {Performance Comparison of Two Types of Auditory Perceptual Features in Robust Underwater Target Classification},
	volume = {103},
	issn = {1610-1928},
	url = {http://www.ingentaconnect.com/content/10.3813/AAA.919033},
	doi = {10.3813/AAA.919033},
	pages = {56--66},
	number = {1},
	journaltitle = {Acta Acustica united with Acustica},
	shortjournal = {Acta Acustica united with Acustica},
	author = {Yang, Lixue and Chen, Kean},
	urldate = {2024-10-10},
	date = {2017-01-01},
	langid = {english},
	note = {4 citations (Semantic Scholar/{DOI}) [2024-10-15]
4 citations (Crossref) [2024-10-14]},
}

@inproceedings{yue_classification_2017,
	location = {Sanya, China},
	title = {The Classification of Underwater Acoustic Targets Based on Deep Learning Methods},
	isbn = {978-94-6252-360-9},
	url = {http://www.atlantis-press.com/php/paper-details.php?id=25881226},
	doi = {10.2991/caai-17.2017.118},
	eventtitle = {2017 2nd International Conference on Control, Automation and Artificial Intelligence ({CAAI} 2017)},
	booktitle = {Proceedings of the 2017 2nd International Conference on Control, Automation and Artificial Intelligence ({CAAI} 2017)},
	publisher = {Atlantis Press},
	author = {Yue, Hao and Zhang, Lilun and Wang, Dezhi and Wang, Yongxian and Lu, Zengquan},
	urldate = {2024-10-10},
	date = {2017},
	langid = {english},
	note = {40 citations (Semantic Scholar/{DOI}) [2024-10-15]
24 citations (Crossref) [2024-10-14]},
}

@article{chen_hierarchical_2018,
	title = {Hierarchical Cosine Similarity Entropy for Feature Extraction of Ship-Radiated Noise},
	volume = {20},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1099-4300},
	url = {https://www.mdpi.com/1099-4300/20/6/425},
	doi = {10.3390/e20060425},
	abstract = {The classification performance of passive sonar can be improved by extracting the features of ship-radiated noise. Traditional feature extraction methods neglect the nonlinear features in ship-radiated noise, such as entropy. The multiscale sample entropy ({MSE}) algorithm has been widely used for quantifying the entropy of a signal, but there are still some limitations. To remedy this, the hierarchical cosine similarity entropy ({HCSE}) is proposed in this paper. Firstly, the hierarchical decomposition is utilized to decompose a time series into some subsequences. Then, the sample entropy ({SE}) is modified by utilizing Shannon entropy rather than conditional entropy and employing angular distance instead of Chebyshev distance. Finally, the complexity of each subsequence is quantified by the modified {SE}. Simulation results show that the {HCSE} method overcomes some limitations in {MSE}. For example, undefined entropy is not likely to occur in {HCSE}, and it is more suitable for short time series. Compared with {MSE}, the experimental results illustrate that the classification accuracy of real ship-radiated noise is significantly improved from 75\% to 95.63\% by using {HCSE}. Consequently, the proposed {HCSE} can be applied in practical applications.},
	pages = {425},
	number = {6},
	journaltitle = {Entropy},
	shortjournal = {Entropy},
	author = {Chen, Zhe and Li, Yaan and Liang, Hongtao and Yu, Jing},
	urldate = {2024-10-09},
	date = {2018-06-01},
	langid = {english},
	note = {21 citations (Semantic Scholar/{DOI}) [2024-10-15]
22 citations (Crossref) [2024-10-14]},
}

@article{gu_recent_2018,
	title = {Recent advances in convolutional neural networks},
	volume = {77},
	issn = {00313203},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0031320317304120},
	doi = {10.1016/j.patcog.2017.10.013},
	pages = {354--377},
	journaltitle = {Pattern Recognition},
	shortjournal = {Pattern Recognition},
	author = {Gu, Jiuxiang and Wang, Zhenhua and Kuen, Jason and Ma, Lianyang and Shahroudy, Amir and Shuai, Bing and Liu, Ting and Wang, Xingxing and Wang, Gang and Cai, Jianfei and Chen, Tsuhan},
	urldate = {2024-09-23},
	date = {2018-05},
	langid = {english},
	note = {4492 citations (Semantic Scholar/{DOI}) [2024-10-15]
3819 citations (Crossref) [2024-10-14]},
}

@article{hu_deep_2018,
	title = {Deep Learning Methods for Underwater Target Feature Extraction and Recognition},
	volume = {2018},
	rights = {http://creativecommons.org/licenses/by/4.0/},
	issn = {1687-5265, 1687-5273},
	url = {https://www.hindawi.com/journals/cin/2018/1214301/},
	doi = {10.1155/2018/1214301},
	abstract = {The classification and recognition technology of underwater acoustic signal were always an important research content in the field of underwater acoustic signal processing. Currently, wavelet transform, Hilbert-Huang transform, and Mel frequency cepstral coefficients are used as a method of underwater acoustic signal feature extraction. In this paper, a method for feature extraction and identification of underwater noise data based on {CNN} and {ELM} is proposed. An automatic feature extraction method of underwater acoustic signals is proposed using depth convolution network. An underwater target recognition classifier is based on extreme learning machine. Although convolution neural networks can execute both feature extraction and classification, their function mainly relies on a full connection layer, which is trained by gradient descent-based; the generalization ability is limited and suboptimal, so an extreme learning machine ({ELM}) was used in classification stage. Firstly, {CNN} learns deep and robust features, followed by the removing of the fully connected layers. Then {ELM} fed with the {CNN} features is used as the classifier to conduct an excellent classification. Experiments on the actual data set of civil ships obtained 93.04\% recognition rate; compared to the traditional Mel frequency cepstral coefficients and Hilbert-Huang feature, recognition rate greatly improved.},
	pages = {1--10},
	journaltitle = {Computational Intelligence and Neuroscience},
	shortjournal = {Computational Intelligence and Neuroscience},
	author = {Hu, Gang and Wang, Kejun and Peng, Yuan and Qiu, Mengran and Shi, Jianfei and Liu, Liangliang},
	urldate = {2024-10-09},
	date = {2018},
	langid = {english},
	note = {100 citations (Semantic Scholar/{DOI}) [2024-10-15]
100 citations (Crossref) [2024-10-14]},
}

@article{ke_underwater_2018,
	title = {Underwater Acoustic Target Recognition Based on Supervised Feature-Separation Algorithm},
	volume = {18},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/18/12/4318},
	doi = {10.3390/s18124318},
	abstract = {For the purpose of improving the accuracy of underwater acoustic target recognition with only a small number of labeled data, we proposed a novel recognition method, including 4 steps: pre-processing, pre-training, fine-tuning and recognition. The 4 steps can be explained as follows: (1) Pre-processing with Resonance-based Sparsity Signal Decomposition ({RSSD}): {RSSD} was firstly utilized to extract high-resonance components from ship-radiated noise. The high-resonance components contain the major information for target recognition. (2) Pre-training with unsupervised feature-extraction: we proposed a one-dimensional convolution autoencoder-decoder model and then we pre-trained the model to extract features from the high-resonance components. (3) Fine-tuning with supervised feature-separation: a supervised feature-separation algorithm was proposed to fine-tune the model and separate the extracted features. (4) Recognition: classifiers were trained to recognize the separated features and complete the recognition mission. The unsupervised pre-training autoencoder-decoder can make good use of a large number of unlabeled data, so that only a small number of labeled data are required in the following supervised fine-tuning and recognition, which is quite effective when it is difficult to collect enough labeled data. The recognition experiments were all conducted on ship-radiated noise data recorded using a sensory hydrophone. By combining the 4 steps above, the proposed recognition method can achieve recognition accuracy of 93.28\%, which sufficiently surpasses other traditional state-of-art feature-extraction methods.},
	pages = {4318},
	number = {12},
	journaltitle = {Sensors},
	shortjournal = {Sensors},
	author = {Ke, Xiaoquan and Yuan, Fei and Cheng, En},
	urldate = {2024-10-09},
	date = {2018-12-07},
	langid = {english},
	note = {50 citations (Semantic Scholar/{DOI}) [2024-10-15]
45 citations (Crossref) [2024-10-14]},
}

@inproceedings{li_underwater_2018,
	location = {Charleston, {SC}},
	title = {Underwater target classification using deep learning},
	isbn = {978-1-5386-4814-8},
	url = {https://ieeexplore.ieee.org/document/8604906/},
	doi = {10.1109/OCEANS.2018.8604906},
	eventtitle = {{OCEANS} 2018 {MTS}/{IEEE} Charleston},
	pages = {1--5},
	booktitle = {{OCEANS} 2018 {MTS}/{IEEE} Charleston},
	publisher = {{IEEE}},
	author = {Li, Chen and Huang, Zhaoqiong and Xu, Ji and Yan, Yonghong},
	urldate = {2024-10-09},
	date = {2018-10},
	note = {12 citations (Semantic Scholar/{DOI}) [2024-10-15]
8 citations (Crossref) [2024-10-14]},
}

@inproceedings{li_classification_2018,
	location = {Kobe},
	title = {Classification of Underwater Acoustic Target Using Auditory Spectrum Feature and {SVDD} Ensemble},
	isbn = {978-1-5386-1654-3},
	url = {https://ieeexplore.ieee.org/document/8558795/},
	doi = {10.1109/OCEANSKOBE.2018.8558795},
	eventtitle = {2018 {OCEANS} - {MTS}/{IEEE} Kobe Techno-Ocean ({OTO})},
	pages = {1--4},
	booktitle = {2018 {OCEANS} - {MTS}/{IEEE} Kobe Techno-Oceans ({OTO})},
	publisher = {{IEEE}},
	author = {Li, Huangfu and Yue, Pan and Jiangqiao, Li},
	urldate = {2024-10-09},
	date = {2018-05},
	note = {2 citations (Semantic Scholar/{DOI}) [2024-10-15]
2 citations (Crossref) [2024-10-14]},
}

@inproceedings{li_feature_2018,
	location = {Islamabad},
	title = {Feature extraction of underwater acoustic signal using mode decomposition and measuring complexity},
	isbn = {978-1-5386-3564-3},
	url = {http://ieeexplore.ieee.org/document/8312307/},
	doi = {10.1109/IBCAST.2018.8312307},
	eventtitle = {2018 15th International Bhurban Conference on Applied Sciences and Technology ({IBCAST})},
	pages = {757--763},
	booktitle = {2018 15th International Bhurban Conference on Applied Sciences and Technology ({IBCAST})},
	publisher = {{IEEE}},
	author = {Li, Yaan and Li, Yuxing},
	urldate = {2024-10-09},
	date = {2018-01},
	note = {6 citations (Semantic Scholar/{DOI}) [2024-10-15]
2 citations (Crossref) [2024-10-14]},
}

@inproceedings{mello_novelty_2018,
	location = {Rio de Janeiro},
	title = {Novelty Detection in Passive Sonar Systems using Stacked {AutoEncoders}},
	isbn = {978-1-5090-6014-6},
	url = {https://ieeexplore.ieee.org/document/8489559/},
	doi = {10.1109/IJCNN.2018.8489559},
	eventtitle = {2018 International Joint Conference on Neural Networks ({IJCNN})},
	pages = {1--7},
	booktitle = {2018 International Joint Conference on Neural Networks ({IJCNN})},
	publisher = {{IEEE}},
	author = {Mello, Vinicius Dos Santos and Moura, Natanael Nunes De and Seixas, Jose Manoel De},
	urldate = {2024-10-09},
	date = {2018-07},
	note = {8 citations (Semantic Scholar/{DOI}) [2024-10-15]
4 citations (Crossref) [2024-10-14]},
}

@article{niu_application_2018,
	title = {Application of {SN}-{EMD} in Mode Feature Extraction of Ship Radiated Noise},
	volume = {2018},
	rights = {http://creativecommons.org/licenses/by/4.0/},
	issn = {1024-123X, 1563-5147},
	url = {https://www.hindawi.com/journals/mpe/2018/2184612/},
	doi = {10.1155/2018/2184612},
	abstract = {Due to the randomness of added noise, noise-assisted versions based on {EMD} (empirical mode decomposition) usually cause new “mode mixing” problem. In addition, these algorithms also have problems such as high time-consuming and large recovering error. For the reasons, a new method {SN}-{EMD} (Selective Noise-assisted {EMD}) is put forward in this paper. It determines whether to add noise as assistance by judging whether there is high frequency intermittent component contained in the signal or not. The new method was proved to have the optimal performance by comparing the performance parameters for evaluating the decomposition. In this paper, {SN}-{EMD} was used to decompose ship radiated noise. On account of the differences in the original information contained in each mode of radiated noise signals from different ship, we selected the first three modes for processing. Average instantaneous frequency, center frequency, energy density, and energy distribution ratio were extracted as mode feature of ship targets for classification and recognition. Spatial distribution of the feature quantities in three-dimensional space verified similarity of the same target and separability of different targets.},
	pages = {1--16},
	journaltitle = {Mathematical Problems in Engineering},
	shortjournal = {Mathematical Problems in Engineering},
	author = {Niu, Fang and Hui, Juan and Zhao, Anbang and Cheng, Yue and Chen, Yang},
	urldate = {2024-10-10},
	date = {2018-12-03},
	langid = {english},
	note = {14 citations (Semantic Scholar/{DOI}) [2024-10-15]
6 citations (Crossref) [2024-10-14]},
}

@article{patek_evolutionary_2018,
	title = {Evolutionary Biomechanics: The Pathway to Power in Snapping Shrimp},
	volume = {28},
	issn = {09609822},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0960982217316664},
	doi = {10.1016/j.cub.2017.12.033},
	shorttitle = {Evolutionary Biomechanics},
	pages = {R115--R117},
	number = {3},
	journaltitle = {Current Biology},
	shortjournal = {Current Biology},
	author = {Patek, S.N. and Longo, Sarah J.},
	urldate = {2024-09-11},
	date = {2018-02},
	langid = {english},
	note = {14 citations (Semantic Scholar/{DOI}) [2024-10-15]
13 citations (Crossref) [2024-10-14]},
}

@article{shen_auditory_2018,
	title = {Auditory Inspired Convolutional Neural Networks for Ship Type Classification with Raw Hydrophone Data},
	volume = {20},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1099-4300},
	url = {https://www.mdpi.com/1099-4300/20/12/990},
	doi = {10.3390/e20120990},
	abstract = {Detecting and classifying ships based on radiated noise provide practical guidelines for the reduction of underwater noise footprint of shipping. In this paper, the detection and classification are implemented by auditory inspired convolutional neural networks trained from raw underwater acoustic signal. The proposed model includes three parts. The first part is performed by a multi-scale 1D time convolutional layer initialized by auditory filter banks. Signals are decomposed into frequency components by convolution operation. In the second part, the decomposed signals are converted into frequency domain by permute layer and energy pooling layer to form frequency distribution in auditory cortex. Then, 2D frequency convolutional layers are applied to discover spectro-temporal patterns, as well as preserve locality and reduce spectral variations in ship noise. In the third part, the whole model is optimized with an objective function of classification to obtain appropriate auditory filters and feature representations that are correlative with ship categories. The optimization reflects the plasticity of auditory system. Experiments on five ship types and background noise show that the proposed approach achieved an overall classification accuracy of 79.2\%, which improved by 6\% compared to conventional approaches. Auditory filter banks were adaptive in shape to improve accuracy of classification.},
	pages = {990},
	number = {12},
	journaltitle = {Entropy},
	shortjournal = {Entropy},
	author = {Shen, Sheng and Yang, Honghui and Li, Junhao and Xu, Guanghui and Sheng, Meiping},
	urldate = {2024-10-10},
	date = {2018-12-19},
	langid = {english},
	note = {41 citations (Semantic Scholar/{DOI}) [2024-10-15]
40 citations (Crossref) [2024-10-14]},
}

@article{wang_improved_2018,
	title = {An Improved Deep Clustering Model for Underwater Acoustical Targets},
	volume = {48},
	issn = {1370-4621, 1573-773X},
	url = {http://link.springer.com/10.1007/s11063-017-9755-7},
	doi = {10.1007/s11063-017-9755-7},
	pages = {1633--1644},
	number = {3},
	journaltitle = {Neural Processing Letters},
	shortjournal = {Neural Process Lett},
	author = {Wang, Qiang and Wang, Lu and Zeng, Xiangyang and Zhao, Lifan},
	urldate = {2024-08-14},
	date = {2018-12},
	langid = {english},
	note = {9 citations (Semantic Scholar/{DOI}) [2024-10-15]
10 citations (Crossref) [2024-10-14]},
	keywords = {{DBN}},
}

@inproceedings{wei_method_2018,
	location = {Zhengzhou},
	title = {A Method of Underwater Acoustic Signal Classification Based on Deep Neural Network},
	isbn = {978-1-5386-5500-9},
	url = {https://ieeexplore.ieee.org/document/8612517/},
	doi = {10.1109/ICISCE.2018.00019},
	eventtitle = {2018 5th International Conference on Information Science and Control Engineering ({ICISCE})},
	pages = {46--50},
	booktitle = {2018 5th International Conference on Information Science and Control Engineering ({ICISCE})},
	publisher = {{IEEE}},
	author = {Wei, Zhengxian and Ju, Yang and Song, Min},
	urldate = {2024-06-24},
	date = {2018-07},
	note = {16 citations (Semantic Scholar/{DOI}) [2024-10-15]
14 citations (Crossref) [2024-10-14]},
}

@inproceedings{xie_dbm-based_2018,
	location = {Chengdu, China},
	title = {{DBM}-Based Underwater Acoustic Source Recognition},
	isbn = {978-1-5386-7864-0},
	url = {https://ieeexplore.ieee.org/document/8689186/},
	doi = {10.1109/ICCS.2018.8689186},
	eventtitle = {2018 {IEEE} International Conference on Communication Systems ({ICCS})},
	pages = {366--371},
	booktitle = {2018 {IEEE} International Conference on Communication Systems ({ICCS})},
	publisher = {{IEEE}},
	author = {Xie, Jiawu and Chen, Jie and Zhang, Jian},
	urldate = {2024-08-14},
	date = {2018-12},
	note = {3 citations (Semantic Scholar/{DOI}) [2024-10-15]
2 citations (Crossref) [2024-10-14]},
	keywords = {{DBN}},
}

@article{yang_competitive_2018,
	title = {Competitive Deep-Belief Networks for Underwater Acoustic Target Recognition},
	volume = {18},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/18/4/952},
	doi = {10.3390/s18040952},
	abstract = {Underwater acoustic target recognition based on ship-radiated noise belongs to the small-sample-size recognition problems. A competitive deep-belief network is proposed to learn features with more discriminative information from labeled and unlabeled samples. The proposed model consists of four stages: (1) A standard restricted Boltzmann machine is pretrained using a large number of unlabeled data to initialize its parameters; (2) the hidden units are grouped according to categories, which provides an initial clustering model for competitive learning; (3) competitive training and back-propagation algorithms are used to update the parameters to accomplish the task of clustering; (4) by applying layer-wise training and supervised fine-tuning, a deep neural network is built to obtain features. Experimental results show that the proposed method can achieve classification accuracy of 90.89\%, which is 8.95\% higher than the accuracy obtained by the compared methods. In addition, the highest accuracy of our method is obtained with fewer features than other methods.},
	pages = {952},
	number = {4},
	journaltitle = {Sensors},
	shortjournal = {Sensors},
	author = {Yang, Honghui and Shen, Sheng and Yao, Xiaohui and Sheng, Meiping and Wang, Chen},
	urldate = {2024-08-14},
	date = {2018-03-23},
	langid = {english},
	note = {77 citations (Semantic Scholar/{DOI}) [2024-10-15]
69 citations (Crossref) [2024-10-14]},
	keywords = {{DBN}},
}

@inproceedings{zhang_frequency_2018,
	location = {Beijing, China},
	title = {Frequency line extraction on low {SNR} lofargram using principal component analysis},
	isbn = {978-1-5386-4673-1},
	url = {https://ieeexplore.ieee.org/document/8652411/},
	doi = {10.1109/ICSP.2018.8652411},
	eventtitle = {2018 14th {IEEE} International Conference on Signal Processing ({ICSP})},
	pages = {455--459},
	booktitle = {2018 14th {IEEE} International Conference on Signal Processing ({ICSP})},
	publisher = {{IEEE}},
	author = {Zhang, Hairu and Li, Chao and Wang, Haibin and Wang, Jun and Yang, Fan},
	urldate = {2024-08-13},
	date = {2018-08},
	note = {5 citations (Semantic Scholar/{DOI}) [2024-10-15]
5 citations (Crossref) [2024-10-14]},
}

@article{bianco_machine_2019,
	title = {Machine learning in acoustics: Theory and applications},
	volume = {146},
	issn = {0001-4966, 1520-8524},
	url = {https://pubs.aip.org/jasa/article/146/5/3590/994832/Machine-learning-in-acoustics-Theory-and},
	doi = {10.1121/1.5133944},
	shorttitle = {Machine learning in acoustics},
	abstract = {Acoustic data provide scientific and engineering insights in fields ranging from biology and communications to ocean and Earth science. We survey the recent advances and transformative potential of machine learning ({ML}), including deep learning, in the field of acoustics. {ML} is a broad family of techniques, which are often based in statistics, for automatically detecting and utilizing patterns in data. Relative to conventional acoustics and signal processing, {ML} is data-driven. Given sufficient training data, {ML} can discover complex relationships between features and desired labels or actions, or between features themselves. With large volumes of training data, {ML} can discover models describing complex acoustic phenomena such as human speech and reverberation. {ML} in acoustics is rapidly developing with compelling results and significant future promise. We first introduce {ML}, then highlight {ML} developments in four acoustics research areas: source localization in speech processing, source localization in ocean acoustics, bioacoustics, and environmental sounds in everyday scenes.},
	pages = {3590--3628},
	number = {5},
	journaltitle = {The Journal of the Acoustical Society of America},
	author = {Bianco, Michael J. and Gerstoft, Peter and Traer, James and Ozanich, Emma and Roch, Marie A. and Gannot, Sharon and Deledalle, Charles-Alban},
	urldate = {2024-06-20},
	date = {2019-11-01},
	langid = {english},
	note = {313 citations (Semantic Scholar/{DOI}) [2024-10-15]
349 citations (Crossref) [2024-10-14]},
	keywords = {Initial reading list, Review},
}

@article{cao_convolutional_2019,
	title = {Convolutional Neural Network With Second-Order Pooling for Underwater Target Classification},
	volume = {19},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {1530-437X, 1558-1748, 2379-9153},
	url = {https://ieeexplore.ieee.org/document/8573835/},
	doi = {10.1109/JSEN.2018.2886368},
	pages = {3058--3066},
	number = {8},
	journaltitle = {{IEEE} Sensors Journal},
	shortjournal = {{IEEE} Sensors J.},
	author = {Cao, Xu and Togneri, Roberto and Zhang, Xiaomin and Yu, Yang},
	urldate = {2024-10-09},
	date = {2019-04-15},
	note = {48 citations (Semantic Scholar/{DOI}) [2024-10-15]
51 citations (Crossref) [2024-10-14]},
}

@article{cao_underwater_2019,
	title = {Underwater target classification at greater depths using deep neural network with joint multiple‐domain feature},
	volume = {13},
	rights = {http://onlinelibrary.wiley.com/{termsAndConditions}\#vor},
	issn = {1751-8792, 1751-8792},
	url = {https://onlinelibrary.wiley.com/doi/10.1049/iet-rsn.2018.5279},
	doi = {10.1049/iet-rsn.2018.5279},
	pages = {484--491},
	number = {3},
	journaltitle = {{IET} Radar, Sonar \& Navigation},
	shortjournal = {{IET} Radar, Sonar \&amp; Navigation},
	author = {Cao, Xu and Zhang, Xiaomin and Togneri, Roberto and Yu, Yang},
	urldate = {2024-08-14},
	date = {2019-03},
	langid = {english},
	note = {12 citations (Semantic Scholar/{DOI}) [2024-10-15]
12 citations (Crossref) [2024-10-14]},
}

@article{chenUnderwaterTargetRecognition2019a,
	title = {Underwater target recognition method based on convolution residual network},
	volume = {283},
	rights = {http://creativecommons.org/licenses/by/4.0/},
	issn = {2261-236X},
	url = {https://www.matec-conferences.org/10.1051/matecconf/201928304011},
	doi = {10.1051/matecconf/201928304011},
	abstract = {The underwater target radiated noises usually have characteristics of low signal to noise ratio, complex signal components and so on. Therefore the recognition is a difficult task and powerful recognition method must be applied to obtain good results. In this paper, a recognition method for underwater target radiated noise time-frequency image based on convolutional neural network with residual units is proposed. The principles and characteristics of the convolutional residual network are analyzed and three basic convolutional residual units are put forward. Then three convolutional residual network models with very deep structure are established based on basic convolutional residual units and some normal convolution layers. The number of the hidden layers is 50, 100 and 150 respectively and softmax algorithm is used as the top classifier. The wavelet transform is adopted to generate time-frequency images of the underwater target radiated noises with frequency band of 10{\textasciitilde}200Hz, thus ensuring the accuracy of local structure of the image, then the above three models can be used to recognize the images. The experimental data of two types of targets were processed. The results are as follows. As the number of training time increases, the training loss shows a convergence trend and the recognition accuracy of test data gradually increases to more than 90\%. In addition, the top-level output has obvious separability. The final recognition accuracies of the three convolutional residual networks are all over 93\% and higher than that of normal convolutional neural network with 5 layers. As the number of layers increases, the recognition accuracy of the convolutional residual network increases to a certain extent, illustrating the increase of layer number can improve the processing effect. The analysis results show that the convolution residual network can extract features with separability through deep structure and achieve effective underwater target recognition.},
	pages = {04011},
	journaltitle = {{MATEC} Web of Conferences},
	shortjournal = {{MATEC} Web Conf.},
	author = {Chen, Yuechao and Du, Shuanping and Quan, {HengHeng} and Zhou, Bin},
	editor = {Goussev, V. and Yin, J.},
	urldate = {2024-10-09},
	date = {2019},
	note = {2 citations (Semantic Scholar/{DOI}) [2024-10-15]
1 citations (Crossref) [2024-10-14]},
}

@inproceedings{chenUnderwaterTargetRecognition2019,
	location = {Chongqing, China},
	title = {Underwater Target Recognition Method Based on Convolution Autoencoder},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	isbn = {978-1-72812-345-5},
	url = {https://ieeexplore.ieee.org/document/9173362/},
	doi = {10.1109/ICSIDP47821.2019.9173362},
	eventtitle = {2019 {IEEE} International Conference on Signal, Information and Data Processing ({ICSIDP})},
	pages = {1--5},
	booktitle = {2019 {IEEE} International Conference on Signal, Information and Data Processing ({ICSIDP})},
	publisher = {{IEEE}},
	author = {Chen, Yuechao and Shang, Jintao},
	urldate = {2024-08-14},
	date = {2019-12},
	note = {2 citations (Semantic Scholar/{DOI}) [2024-10-15]
4 citations (Crossref) [2024-10-14]},
}

@article{chen_new_2019,
	title = {A New Feature Extraction Method for Ship-Radiated Noise Based on Improved {CEEMDAN}, Normalized Mutual Information and Multiscale Improved Permutation Entropy},
	volume = {21},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1099-4300},
	url = {https://www.mdpi.com/1099-4300/21/6/624},
	doi = {10.3390/e21060624},
	abstract = {Extracting useful features from ship-radiated noise can improve the performance of passive sonar. The entropy feature is an important supplement to existing technologies for ship classification. However, the existing entropy feature extraction methods for ship-radiated noise are less reliable under noisy conditions because they lack noise reduction procedures or are single-scale based. In order to simultaneously solve these problems, a new feature extraction method is proposed based on improved complementary ensemble empirical mode decomposition with adaptive noise ({ICEEMDAN}), normalized mutual information ({norMI}), and multiscale improved permutation entropy ({MIPE}). Firstly, the {ICEEMDAN} is utilized to obtain a group of intrinsic mode functions ({IMFs}) from ship-radiated noise. The noise reduction process is then conducted by identifying and eliminating the noise {IMFs}. Next, the {norMI} and {MIPE} of the signal-dominant {IMFs} are calculated, respectively; and the {norMI} is used to weigh the corresponding {MIPE} result. The multi-scale entropy feature is finally defined as the sum of the weighted {MIPE} results. Experimental results show that the recognition rate of the proposed method achieves 90.67\% and 83\%, respectively, under noise free and 5 {dB} conditions, which is much higher than existing entropy feature extraction algorithms. Hence, the proposed method is more reliable and suitable for feature extraction of ship-radiated noise in practice.},
	pages = {624},
	number = {6},
	journaltitle = {Entropy},
	shortjournal = {Entropy},
	author = {Chen, Zhe and Li, Yaan and Cao, Renjie and Ali, Wasiq and Yu, Jing and Liang, Hongtao},
	urldate = {2024-10-09},
	date = {2019-06-25},
	langid = {english},
	note = {24 citations (Semantic Scholar/{DOI}) [2024-10-15]
24 citations (Crossref) [2024-10-14]},
}

@article{chi_sound_2019,
	title = {Sound source ranging using a feed-forward neural network trained with fitting-based early stopping},
	volume = {146},
	issn = {0001-4966, 1520-8524},
	url = {https://pubs.aip.org/jasa/article/146/3/EL258/995939/Sound-source-ranging-using-a-feed-forward-neural},
	doi = {10.1121/1.5126115},
	abstract = {When a feed-forward neural network ({FNN}) is trained for acoustic source ranging in an ocean waveguide, it is difficult evaluating the {FNN} ranging accuracy of unlabeled test data. The label is the distance between source and receiver array. A fitting-based early stopping ({FEAST}) method is introduced to evaluate the {FNN} ranging error on test data where the distance to the source is unknown. Based on {FEAST}, when the evaluated ranging error is minimum on test data, training is stopped. This will improve the {FNN} ranging accuracy on the test data. The {FEAST} is demonstrated on simulated and experimental data.},
	pages = {EL258--EL264},
	number = {3},
	journaltitle = {The Journal of the Acoustical Society of America},
	author = {Chi, Jing and Li, Xiaolei and Wang, Haozhong and Gao, Dazhi and Gerstoft, Peter},
	urldate = {2024-10-09},
	date = {2019-09-01},
	langid = {english},
	note = {26 citations (Semantic Scholar/{DOI}) [2024-10-15]
41 citations (Crossref) [2024-10-14]},
}

@article{choi_acoustic_2019,
	title = {Acoustic Classification of Surface and Underwater Vessels in the Ocean Using Supervised Machine Learning},
	volume = {19},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/19/16/3492},
	doi = {10.3390/s19163492},
	abstract = {Four data-driven methods—random forest ({RF}), support vector machine ({SVM}), feed-forward neural network ({FNN}), and convolutional neural network ({CNN})—are applied to discriminate surface and underwater vessels in the ocean using low-frequency acoustic pressure data. Acoustic data are modeled considering a vertical line array by a Monte Carlo simulation using the underwater acoustic propagation model, {KRAKEN}, in the ocean environment of East Sea in Korea. The raw data are preprocessed and reorganized into the phone-space cross-spectral density matrix ({pCSDM}) and mode-space cross-spectral density matrix ({mCSDM}). Two additional matrices are generated using the absolute values of matrix elements in each {CSDM}. Each of these four matrices is used as input data for supervised machine learning. Binary classification is performed by using {RF}, {SVM}, {FNN}, and {CNN}, and the obtained results are compared. All machine-learning algorithms show an accuracy of {\textgreater}95\% for three types of input data—the {pCSDM}, {mCSDM}, and {mCSDM} with the absolute matrix elements. The {CNN} is the best in terms of low percent error. In particular, the result using the complex {pCSDM} is encouraging because these data-driven methods inherently do not require environmental information. This work demonstrates the potential of machine learning to discriminate between surface and underwater vessels in the ocean.},
	pages = {3492},
	number = {16},
	journaltitle = {Sensors},
	shortjournal = {Sensors},
	author = {Choi, Jongkwon and Choo, Youngmin and Lee, Keunhwa},
	urldate = {2024-10-09},
	date = {2019-08-09},
	langid = {english},
	note = {40 citations (Semantic Scholar/{DOI}) [2024-10-15]
40 citations (Crossref) [2024-10-14]},
}

@inproceedings{hashisho_underwater_2019,
	location = {Dubrovnik, Croatia},
	title = {Underwater Color Restoration Using U-Net Denoising Autoencoder},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	isbn = {978-1-72813-140-5},
	url = {https://ieeexplore.ieee.org/document/8868679/},
	doi = {10.1109/ISPA.2019.8868679},
	eventtitle = {2019 11th International Symposium on Image and Signal Processing and Analysis ({ISPA})},
	pages = {117--122},
	booktitle = {2019 11th International Symposium on Image and Signal Processing and Analysis ({ISPA})},
	publisher = {{IEEE}},
	author = {Hashisho, Yousif and Albadawi, Mohamad and Krause, Tom and Von Lukas, Uwe Freiherr},
	urldate = {2024-09-24},
	date = {2019-09},
	note = {27 citations (Semantic Scholar/{DOI}) [2024-10-15]
31 citations (Crossref) [2024-10-14]},
}

@article{li_comparative_2019,
	title = {A Comparative Study of Multiscale Sample Entropy and Hierarchical Entropy and Its Application in Feature Extraction for Ship-Radiated Noise},
	volume = {21},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1099-4300},
	url = {https://www.mdpi.com/1099-4300/21/8/793},
	doi = {10.3390/e21080793},
	abstract = {The presence of marine ambient noise makes it difficult to extract effective features from ship-radiated noise. Traditional feature extraction methods based on the Fourier transform or wavelets are limited in such a complex ocean environment. Recently, entropy-based methods have been proven to have many advantages compared with traditional methods. In this paper, we propose a novel feature extraction method for ship-radiated noise based on hierarchical entropy ({HE}). Compared with the traditional entropy, namely multiscale sample entropy ({MSE}), which only considers information carried in the lower frequency components, {HE} takes into account both lower and higher frequency components of signals. We illustrate the different properties of {HE} and {MSE} by testing them on simulation signals. The results show that {HE} has better performance than {MSE}, especially when the difference in signals is mainly focused on higher frequency components. Furthermore, experiments on real-world data of five types of ship-radiated noise are conducted. A probabilistic neural network is employed to evaluate the performance of the obtained features. Results show that {HE} has a higher classification accuracy for the five types of ship-radiated noise compared with {MSE}. This indicates that the {HE}-based feature extraction method could be used to identify ships in the field of underwater acoustic signal processing.},
	pages = {793},
	number = {8},
	journaltitle = {Entropy},
	shortjournal = {Entropy},
	author = {Li, Weijia and Shen, Xiaohong and Li, Yaan},
	urldate = {2024-10-09},
	date = {2019-08-14},
	langid = {english},
	note = {20 citations (Semantic Scholar/{DOI}) [2024-10-15]
20 citations (Crossref) [2024-10-14]},
}

@article{li_novel_2019,
	title = {A Novel Improved Feature Extraction Technique for Ship-Radiated Noise Based on {IITD} and {MDE}},
	volume = {21},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1099-4300},
	url = {https://www.mdpi.com/1099-4300/21/12/1215},
	doi = {10.3390/e21121215},
	abstract = {Ship-radiated noise signal has a lot of nonlinear, non-Gaussian, and nonstationary information characteristics, which can reflect the important signs of ship performance. This paper proposes a novel feature extraction technique for ship-radiated noise based on improved intrinsic time-scale decomposition ({IITD}) and multiscale dispersion entropy ({MDE}). The proposed feature extraction technique is named {IITD}-{MDE}. First, {IITD} is applied to decompose the ship-radiated noise signal into a series of intrinsic scale components ({ISCs}). Then, we select the {ISC} with the main information through the correlation analysis, and calculate the {MDE} value as feature vectors. Finally, the feature vectors are input into the support vector machine ({SVM}) for ship classification. The experimental results indicate that the recognition rate of the proposed technique reaches 86\% accuracy. Therefore, compared with the other feature extraction methods, the proposed method provides a new solution for classifying different types of ships effectively.},
	pages = {1215},
	number = {12},
	journaltitle = {Entropy},
	shortjournal = {Entropy},
	author = {Li, Zhaoxi and Li, Yaan and Zhang, Kai and Guo, Jianli},
	urldate = {2024-10-09},
	date = {2019-12-12},
	langid = {english},
	note = {25 citations (Semantic Scholar/{DOI}) [2024-10-15]
25 citations (Crossref) [2024-10-14]},
}

@article{luo_sensing_2019,
	title = {A Sensing and Tracking Algorithm for Multiple Frequency Line Components in Underwater Acoustic Signals},
	volume = {19},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/19/22/4866},
	doi = {10.3390/s19224866},
	abstract = {Reliable and efficient sensing and tracking of multiple weak or time-varying frequency line components in underwater acoustic signals is the topic of this paper. We propose a method for automatic detection and tracking of multiple frequency lines in lofargram based on hidden Markov model ({HMM}). Instead of being directly subjected to frequency line tracking, the whole lofargram is first segmented into several sub-lofargrams. Then, the sub-lofargrams suspected to contain frequency lines are screened. In these sub-lofargrams, the {HMM}-based method is used for detection of multiple frequency lines. Using image stitching and statistical model method, the frequency lines with overlapping parts detected by different sub-lofargrams are merged to obtain the final detection results. The method can effectively detect multiple time-varying frequency lines of underwater acoustic signals while ensuring the performance under the condition of low signal-to-noise ratio ({SNR}). It can be concluded that the proposed algorithm can provide better multiple frequency lines sensing ability while greatly reducing the amount of calculations and providing potential techniques for feature sensing and tracking processing of unattended equipment such as sonar buoys and submerged buoys.},
	pages = {4866},
	number = {22},
	journaltitle = {Sensors},
	shortjournal = {Sensors},
	author = {Luo, Xinwei and Shen, Zihan},
	urldate = {2024-08-13},
	date = {2019-11-08},
	langid = {english},
	note = {8 citations (Semantic Scholar/{DOI}) [2024-10-15]
6 citations (Crossref) [2024-10-14]},
}

@article{niu_deep-learning_2019,
	title = {Deep-learning source localization using multi-frequency magnitude-only data},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/1903.12319},
	doi = {10.48550/ARXIV.1903.12319},
	abstract = {A deep learning approach based on big data is proposed to locate broadband acoustic sources using a single hydrophone in ocean waveguides with uncertain bottom parameters. Several 50-layer residual neural networks, trained on a huge number of sound field replicas generated by an acoustic propagation model, are used to handle the bottom uncertainty in source localization. A two-step training strategy is presented to improve the training of the deep models. First, the range is discretized in a coarse (5 km) grid. Subsequently, the source range within the selected interval and source depth are discretized on a finer (0.1 km and 2 m) grid. The deep learning methods were demonstrated for simulated magnitude-only multi-frequency data in uncertain environments. Experimental data from the China Yellow Sea also validated the approach.},
	author = {Niu, Haiqiang and Gong, Zaixiao and Ozanich, Emma and Gerstoft, Peter and Wang, Haibin and Li, Zhenglin},
	urldate = {2024-10-10},
	date = {2019},
	note = {89 citations (Semantic Scholar/{arXiv}) [2024-10-15]
Publisher: {arXiv}
Version Number: 2},
}

@inproceedings{park_identifying_2019,
	location = {Jeju, Korea (South)},
	title = {Identifying Tonal Frequencies in a Lofargram with Convolutional Neural Networks},
	isbn = {978-89-93215-17-5},
	url = {https://ieeexplore.ieee.org/document/8971701/},
	doi = {10.23919/ICCAS47443.2019.8971701},
	eventtitle = {2019 19th International Conference on Control, Automation and Systems ({ICCAS})},
	pages = {338--341},
	booktitle = {2019 19th International Conference on Control, Automation and Systems ({ICCAS})},
	publisher = {{IEEE}},
	author = {Park, Jihun and Jung, Dae-Jin},
	urldate = {2024-10-10},
	date = {2019-10},
	note = {7 citations (Semantic Scholar/{DOI}) [2024-10-15]
8 citations (Crossref) [2024-10-14]},
}

@inproceedings{ren_feature_2019,
	location = {Marseille, France},
	title = {Feature Analysis of Passive Underwater Targets Recognition Based on Deep Neural Network},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	isbn = {978-1-72811-450-7},
	url = {https://ieeexplore.ieee.org/document/8867507/},
	doi = {10.1109/OCEANSE.2019.8867507},
	eventtitle = {{OCEANS} 2019 - Marseille},
	pages = {1--5},
	booktitle = {{OCEANS} 2019 - Marseille},
	publisher = {{IEEE}},
	author = {Ren, Jiawei and Huang, Zhaoqiong and Li, Chen and Guo, Xinyi and Xu, Ji},
	urldate = {2024-10-10},
	date = {2019-06},
	note = {9 citations (Semantic Scholar/{DOI}) [2024-10-15]
9 citations (Crossref) [2024-10-14]},
}

@article{shrestha_review_2019,
	title = {Review of Deep Learning Algorithms and Architectures},
	volume = {7},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{OAPA}.html},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/8694781/},
	doi = {10.1109/ACCESS.2019.2912200},
	pages = {53040--53065},
	journaltitle = {{IEEE} Access},
	shortjournal = {{IEEE} Access},
	author = {Shrestha, Ajay and Mahmood, Ausif},
	urldate = {2024-09-23},
	date = {2019},
	note = {1061 citations (Semantic Scholar/{DOI}) [2024-10-15]
1123 citations (Crossref) [2024-10-14]},
}

@article{wang_feature_2019,
	title = {Feature Extraction of Ship-Radiated Noise Based on Intrinsic Time-Scale Decomposition and a Statistical Complexity Measure},
	volume = {21},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1099-4300},
	url = {https://www.mdpi.com/1099-4300/21/11/1079},
	doi = {10.3390/e21111079},
	abstract = {Extracting effective features from ship-radiated noise is an important way to improve the detection and recognition performance of passive sonar. Complexity features of ship-radiated noise have attracted increasing amounts of attention. However, the traditional definition of complexity based on entropy (information stored in the system) is not accurate. To this end, a new statistical complexity measure is proposed in this paper based on spectrum entropy and disequilibrium. Since the spectrum features are unique to the class of the ship, our method can distinguish different ships according to their location in the two-dimensional plane composed of complexity and spectrum entropy ({CSEP}). To weaken the influence of ocean ambient noise, the intrinsic time-scale decomposition ({ITD}) is applied to preprocess the data in this study. The effectiveness of the proposed method is validated through a classification experiment of four types of marine vessels. The recognition rate of the {ITD}-{CSEP} methodology achieved 94\%, which is much higher than that of traditional feature extraction methods. Moreover, the {ITD}-{CSEP} is fast and parameter free. Hence, the method can be applied in the real time processing practical applications.},
	pages = {1079},
	number = {11},
	journaltitle = {Entropy},
	shortjournal = {Entropy},
	author = {Wang, Junxiong and Chen, Zhe},
	urldate = {2024-10-10},
	date = {2019-11-04},
	langid = {english},
	note = {13 citations (Semantic Scholar/{DOI}) [2024-10-15]
13 citations (Crossref) [2024-10-14]},
}

@article{wang_underwater_2019,
	title = {Underwater Acoustic Target Recognition: A Combination of Multi-Dimensional Fusion Features and Modified Deep Neural Network},
	volume = {11},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2072-4292},
	url = {https://www.mdpi.com/2072-4292/11/16/1888},
	doi = {10.3390/rs11161888},
	shorttitle = {Underwater Acoustic Target Recognition},
	abstract = {A method with a combination of multi-dimensional fusion features and a modified deep neural network ({MFF}-{MDNN}) is proposed to recognize underwater acoustic targets in this paper. Specifically, due to the complex and changeable underwater environment, it is difficult to describe underwater acoustic signals with a single feature. The Gammatone frequency cepstral coefficient ({GFCC}) and modified empirical mode decomposition ({MEMD}) are developed to extract multi-dimensional features in this paper. Moreover, to ensure the same time dimension, a dimension reduction method is proposed to obtain multi-dimensional fusion features in the original underwater acoustic signals. Then, to reduce redundant features and further improve recognition accuracy, the Gaussian mixture model ({GMM}) is used to modify the structure of a deep neural network ({DNN}). Finally, the proposed underwater acoustic target recognition method can obtain an accuracy of 94.3\% under a maximum of 800 iterations when the dataset has underwater background noise with weak targets. Compared with other methods, the recognition results demonstrate that the proposed method has higher accuracy and strong adaptability.},
	pages = {1888},
	number = {16},
	journaltitle = {Remote Sensing},
	shortjournal = {Remote Sensing},
	author = {Wang, Xingmei and Liu, Anhua and Zhang, Yu and Xue, Fuzhao},
	urldate = {2024-06-24},
	date = {2019-08-13},
	langid = {english},
	note = {63 citations (Semantic Scholar/{DOI}) [2024-10-15]
61 citations (Crossref) [2024-10-14]},
}

@inproceedings{yang_new_2019,
	location = {Marseille, France},
	title = {A New Cooperative Deep Learning Method for Underwater Acoustic Target Recognition},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	isbn = {978-1-72811-450-7},
	url = {https://ieeexplore.ieee.org/document/8867490/},
	doi = {10.1109/OCEANSE.2019.8867490},
	eventtitle = {{OCEANS} 2019 - Marseille},
	pages = {1--4},
	booktitle = {{OCEANS} 2019 - Marseille},
	publisher = {{IEEE}},
	author = {Yang, Honghui and Xu, Guanghui and Yi, Shuzhen and Li, Yiqing},
	urldate = {2024-10-10},
	date = {2019-06},
	note = {18 citations (Semantic Scholar/{DOI}) [2024-10-15]
21 citations (Crossref) [2024-10-14]},
}

@article{yuan_joint_2019,
	title = {Joint Representation and Recognition for Ship-Radiated Noise Based on Multimodal Deep Learning},
	volume = {7},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2077-1312},
	url = {https://www.mdpi.com/2077-1312/7/11/380},
	doi = {10.3390/jmse7110380},
	abstract = {Ship recognition based on ship-radiated noise is one of the most important and challenging subjects in underwater acoustic signal processing. The recognition methods for ship-radiated noise recognition include traditional methods and deep learning ({DL}) methods. Developing from the {DL} methods and inspired by audio–video speech recognition ({AVSR}), the paper further introduces multimodal deep learning (multimodal-{DL}) methods for the recognition of ship-radiated noise. In this paper, ship-radiated noise (acoustics modality) and visual observation of the ships (visual modality) are two different modalities that the multimodal-{DL} methods model on. The paper specially designs a multimodal-{DL} framework, the multimodal convolutional neural networks (multimodal-{CNNs}) for the recognition of ship-radiated noise. Then the paper proposes a strategy based on canonical correlation analysis ({CCA}-based strategy) to build a joint representation and recognition on the two different single-modality (acoustics modality and visual modality). The multimodal-{CNNs} and the {CCA}-based strategy are tested on real ship-radiated noise data recorded. Experimental results show that, using the {CCA}-based strategy, strong-discriminative information can be built from weak-discriminative information provided from a single-modality. Experimental results also show that as long as any one of the single-modalities can provide information for the recognition, the multimodal-{DL} methods can have a much better multiclass recognition performance than the {DL} methods. The paper also discusses the advantages and superiorities of the multimodal-Dl methods over the traditional methods for ship-radiated noise recognition.},
	pages = {380},
	number = {11},
	journaltitle = {Journal of Marine Science and Engineering},
	shortjournal = {{JMSE}},
	author = {Yuan, Fei and Ke, Xiaoquan and Cheng, En},
	urldate = {2024-06-21},
	date = {2019-10-27},
	langid = {english},
	note = {28 citations (Semantic Scholar/{DOI}) [2024-10-15]
24 citations (Crossref) [2024-10-14]},
}

@misc{dosovitskiy_image_2020,
	title = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/2010.11929},
	doi = {10.48550/ARXIV.2010.11929},
	shorttitle = {An Image is Worth 16x16 Words},
	abstract = {While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on {CNNs} is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks ({ImageNet}, {CIFAR}-100, {VTAB}, etc.), Vision Transformer ({ViT}) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.},
	publisher = {{arXiv}},
	author = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
	urldate = {2024-10-14},
	date = {2020},
	note = {9999 citations (Semantic Scholar/{arXiv}) [2024-10-15]
Version Number: 2},
}

@inproceedings{gao_recognition_2020,
	location = {Beijing, China},
	title = {Recognition Method for Underwater Acoustic Target Based on {DCGAN} and {DenseNet}},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	isbn = {978-1-72816-661-2},
	url = {https://ieeexplore.ieee.org/document/9177493/},
	doi = {10.1109/ICIVC50857.2020.9177493},
	eventtitle = {2020 {IEEE} 5th International Conference on Image, Vision and Computing ({ICIVC})},
	pages = {215--221},
	booktitle = {2020 {IEEE} 5th International Conference on Image, Vision and Computing ({ICIVC})},
	publisher = {{IEEE}},
	author = {Gao, Yingjie and Chen, Yuechao and Wang, Fangyong and He, Yalong},
	urldate = {2024-10-09},
	date = {2020-07},
	note = {8 citations (Semantic Scholar/{DOI}) [2024-10-15]
11 citations (Crossref) [2024-10-14]},
}

@article{han_deeplofargram_2020,
	title = {{DeepLofargram}: A deep learning based fluctuating dim frequency line detection and recovery},
	volume = {148},
	issn = {0001-4966, 1520-8524},
	url = {https://pubs.aip.org/jasa/article/148/4/2182/994355/DeepLofargram-A-deep-learning-based-fluctuating},
	doi = {10.1121/10.0002172},
	shorttitle = {{DeepLofargram}},
	abstract = {This paper investigates the problem of dim frequency line detection and recovery in the so-called lofargram. Theoretically, long enough time integration can always enhance the detection characteristic. But this does not hold for irregularly fluctuating lines. Deep learning has been shown to perform very well for sophisticated visual inference tasks. With the composition of multiple processing layers, very complex high level representations that amplify the important aspects of input while suppressing irrelevant variations can be learned. Hence, {DeepLofargram} is proposed, composed of a deep convolutional neural network and its visualization counterpart. Plugging into specifically designed multi-task loss, an end-to-end training jointly learns to detect and recover the spatial location of potential lines. Leveraging on this deep architecture, performance limits of low {SNR} can be achieved as low as −24 {dB} on average and −26 {dB} for some. This is far beyond the perception of human vision and significantly improves the state-of-the-art.},
	pages = {2182--2194},
	number = {4},
	journaltitle = {The Journal of the Acoustical Society of America},
	author = {Han, Yina and Li, Yuyan and Liu, Qingyu and Ma, Yuanliang},
	urldate = {2024-08-13},
	date = {2020-10-01},
	langid = {english},
	note = {7 citations (Semantic Scholar/{DOI}) [2024-10-15]
7 citations (Crossref) [2024-10-14]},
}

@misc{hu_features_2020,
	title = {An Features Extraction and Recognition Method for Underwater Acoustic Target Based on {ATCNN}},
	rights = {Creative Commons Attribution 4.0 International},
	url = {https://arxiv.org/abs/2011.14336},
	doi = {10.48550/ARXIV.2011.14336},
	abstract = {Facing the complex marine environment, it is extremely challenging to conduct underwater acoustic target recognition ({UATR}) using ship-radiated noise. Inspired by neural mechanism of auditory perception, this paper provides a new deep neural network trained by original underwater acoustic signals with depthwise separable convolution ({DWS}) and time-dilated convolution neural network, named auditory perception inspired time-dilated convolution neural network ({ATCNN}), and then implements detection and classification for underwater acoustic signals. The proposed {ATCNN} model consists of learnable features extractor and integration layer inspired by auditory perception, and time-dilated convolution inspired by language model. This paper decomposes original time-domain ship-radiated noise signals into different frequency components with depthwise separable convolution filter, and then extracts signal features based on auditory perception. The deep features are integrated on integration layer. The time-dilated convolution is used for long-term contextual modeling. As a result, like language model, intra-class and inter-class information can be fully used for {UATR}. For {UATR} task, the classification accuracy reaches 90.9\%, which is the highest in contrast experiment. Experimental results show that {ATCNN} has great potential to improve the performance of {UATR} classification.},
	publisher = {{arXiv}},
	author = {Hu, Gang and Wang, Kejun and Liu, Liangliang},
	urldate = {2024-10-09},
	date = {2020},
	note = {6 citations (Semantic Scholar/{arXiv}) [2024-10-15]
Version Number: 1},
}

@article{jin_deep_2020,
	title = {Deep learning-based framework for expansion, recognition and classification of underwater acoustic signal},
	volume = {32},
	issn = {0952-813X, 1362-3079},
	url = {https://www.tandfonline.com/doi/full/10.1080/0952813X.2019.1647560},
	doi = {10.1080/0952813X.2019.1647560},
	pages = {205--218},
	number = {2},
	journaltitle = {Journal of Experimental \& Theoretical Artificial Intelligence},
	shortjournal = {Journal of Experimental \& Theoretical Artificial Intelligence},
	author = {Jin, Guanghao and Liu, Fan and Wu, Hao and Song, Qingzeng},
	urldate = {2024-10-09},
	date = {2020-03-03},
	langid = {english},
	note = {44 citations (Semantic Scholar/{DOI}) [2024-10-15]
45 citations (Crossref) [2024-10-14]},
}

@article{ju_new_2020,
	title = {A New Low {SNR} Underwater Acoustic Signal Classification Method Based on Intrinsic Modal Features Maintaining Dimensionality Reduction},
	volume = {27},
	rights = {http://creativecommons.org/licenses/by-nc-nd/4.0},
	issn = {2083-7429},
	url = {https://www.sciendo.com/article/10.2478/pomr-2020-0040},
	doi = {10.2478/pomr-2020-0040},
	abstract = {Abstract
            The classification of low signal-to-noise ratio ({SNR}) underwater acoustic signals in complex acoustic environments and increasingly small target radiation noise is a hot research topic.. This paper proposes a new method for signal processing—low {SNR} underwater acoustic signal classification method ({LSUASC})—based on intrinsic modal features maintaining dimensionality reduction. Using the {LSUASC} method, the underwater acoustic signal was first transformed with the Hilbert-Huang Transform ({HHT}) and the intrinsic mode was extracted. the intrinsic mode was then transformed into a corresponding Mel-frequency cepstrum coefficient ({MFCC}) to form a multidimensional feature vector of the low {SNR} acoustic signal. Next, a semi-supervised fuzzy rough Laplacian Eigenmap ({SSFRLE}) method was proposed to perform manifold dimension reduction (local sparse and discrete features of underwater acoustic signals can be maintained in the dimension reduction process) and principal component analysis ({PCA}) was adopted in the process of dimension reduction to define the reduced dimension adaptively. Finally, Fuzzy C-Means ({FCMs}), which are able to classify data with weak features was adopted to cluster the signal features after dimensionality reduction. The experimental results presented here show that the {LSUASC} method is able to classify low {SNR} underwater acoustic signals with high accuracy.},
	pages = {187--198},
	number = {2},
	journaltitle = {Polish Maritime Research},
	author = {Ju, Yang and Wei, Zhengxian and Huangfu, Li and Xiao, Feng},
	urldate = {2024-10-09},
	date = {2020-06-01},
	langid = {english},
	note = {9 citations (Semantic Scholar/{DOI}) [2024-10-15]
9 citations (Crossref) [2024-10-14]},
}

@article{ke_integrated_2020,
	title = {Integrated optimization of underwater acoustic ship-radiated noise recognition based on two-dimensional feature fusion},
	volume = {159},
	issn = {0003682X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0003682X19301781},
	doi = {10.1016/j.apacoust.2019.107057},
	pages = {107057},
	journaltitle = {Applied Acoustics},
	shortjournal = {Applied Acoustics},
	author = {Ke, Xiaoquan and Yuan, Fei and Cheng, En},
	urldate = {2024-08-06},
	date = {2020-02},
	langid = {english},
	note = {34 citations (Semantic Scholar/{DOI}) [2024-10-15]
31 citations (Crossref) [2024-10-14]},
}

@article{khan_survey_2020,
	title = {A survey of the recent architectures of deep convolutional neural networks},
	volume = {53},
	issn = {0269-2821, 1573-7462},
	url = {https://link.springer.com/10.1007/s10462-020-09825-6},
	doi = {10.1007/s10462-020-09825-6},
	pages = {5455--5516},
	number = {8},
	journaltitle = {Artificial Intelligence Review},
	shortjournal = {Artif Intell Rev},
	author = {Khan, Asifullah and Sohail, Anabia and Zahoora, Umme and Qureshi, Aqsa Saeed},
	urldate = {2024-09-23},
	date = {2020-12},
	langid = {english},
	note = {1990 citations (Semantic Scholar/{DOI}) [2024-10-15]
1685 citations (Crossref) [2024-10-14]},
}

@article{khishe_classification_2020,
	title = {Classification of underwater acoustical dataset using neural network trained by Chimp Optimization Algorithm},
	volume = {157},
	issn = {0003682X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0003682X19305067},
	doi = {10.1016/j.apacoust.2019.107005},
	pages = {107005},
	journaltitle = {Applied Acoustics},
	shortjournal = {Applied Acoustics},
	author = {Khishe, M. and Mosavi, M.R.},
	urldate = {2024-10-09},
	date = {2020-01},
	langid = {english},
	note = {107 citations (Semantic Scholar/{DOI}) [2024-10-15]
113 citations (Crossref) [2024-10-14]},
}

@inproceedings{koh_underwater_2020,
	location = {Biloxi, {MS}, {USA}},
	title = {Underwater Signal Denoising Using Deep Learning Approach},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	isbn = {978-1-72815-446-6},
	url = {https://ieeexplore.ieee.org/document/9389338/},
	doi = {10.1109/IEEECONF38699.2020.9389338},
	eventtitle = {Global Oceans 2020: Singapore - U.S. Gulf Coast},
	pages = {1--6},
	booktitle = {Global Oceans 2020: Singapore – U.S. Gulf Coast},
	publisher = {{IEEE}},
	author = {Koh, Shirong and Chia, Chin Swee and Tan, Bien Aik},
	urldate = {2024-09-24},
	date = {2020-10-05},
	note = {10 citations (Semantic Scholar/{DOI}) [2024-10-15]
11 citations (Crossref) [2024-10-14]},
}

@article{li_feature_2020,
	title = {A Feature Optimization Approach Based on Inter-Class and Intra-Class Distance for Ship Type Classification},
	volume = {20},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/20/18/5429},
	doi = {10.3390/s20185429},
	abstract = {Deep learning based methods have achieved state-of-the-art results on the task of ship type classification. However, most existing ship type classification algorithms take time–frequency ({TF}) features as input, the underlying discriminative information of these features has not been explored thoroughly. This paper proposes a novel feature optimization method which is designed to minimize an objective function aimed at increasing inter-class and reducing intra-class feature distance for ship type classification. The objective function we design is able to learn a center for each class and make samples from the same class closer to the corresponding center. This ensures that the features maximize underlying discriminative information involved in the data, particularly for some targets that usually confused by the conventional manual designed feature. Results on the dataset from a real environment show that the proposed feature optimization approach outperforms traditional {TF} features.},
	pages = {5429},
	number = {18},
	journaltitle = {Sensors},
	shortjournal = {Sensors},
	author = {Li, Chen and Liu, Ziyuan and Ren, Jiawei and Wang, Wenchao and Xu, Ji},
	urldate = {2024-10-09},
	date = {2020-09-22},
	langid = {english},
	note = {28 citations (Semantic Scholar/{DOI}) [2024-10-15]
28 citations (Crossref) [2024-10-14]},
}

@inproceedings{li_learning_2020,
	location = {Glasgow, United Kingdom},
	title = {Learning Deep Models from Synthetic Data for Extracting Dolphin Whistle Contours},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	isbn = {978-1-72816-926-2},
	url = {https://ieeexplore.ieee.org/document/9206992/},
	doi = {10.1109/IJCNN48605.2020.9206992},
	eventtitle = {2020 International Joint Conference on Neural Networks ({IJCNN})},
	pages = {1--10},
	booktitle = {2020 International Joint Conference on Neural Networks ({IJCNN})},
	publisher = {{IEEE}},
	author = {Li, Pu and Liu, Xiaobai and Palmer, K. J. and Fleishman, Erica and Gillespie, Douglas and Nosal, Eva-Marie and Shiu, Yu and Klinck, Holger and Cholewiak, Danielle and Helble, Tyler and Roch, Marie A.},
	urldate = {2024-08-13},
	date = {2020-07},
	note = {11 citations (Semantic Scholar/{DOI}) [2024-10-15]
8 citations (Crossref) [2024-10-14]},
}

@article{li_recognition_2020,
	title = {Recognition of ships based on vector sensor and bidirectional long short-term memory networks},
	volume = {164},
	issn = {0003682X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0003682X19310096},
	doi = {10.1016/j.apacoust.2020.107248},
	pages = {107248},
	journaltitle = {Applied Acoustics},
	shortjournal = {Applied Acoustics},
	author = {Li, Sichun and Yang, Shuyu and Liang, Jinghan},
	urldate = {2024-10-09},
	date = {2020-07},
	langid = {english},
	note = {25 citations (Semantic Scholar/{DOI}) [2024-10-15]
24 citations (Crossref) [2024-10-14]},
}

@article{luo_underwater_2020,
	title = {An Underwater Acoustic Target Recognition Method Based on Restricted Boltzmann Machine},
	volume = {20},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/20/18/5399},
	doi = {10.3390/s20185399},
	abstract = {This article focuses on an underwater acoustic target recognition method based on target radiated noise. The difficulty of underwater acoustic target recognition is mainly the extraction of effective classification features and pattern classification. Traditional feature extraction methods based on Low Frequency Analysis Recording ({LOFAR}), Mel-Frequency Cepstral Coefficients ({MFCC}), Gammatone-Frequency Cepstral Coefficients ({GFCC}), etc. essentially compress data according to a certain pre-set model, artificially discarding part of the information in the data, and often losing information helpful for classification. This paper presents a target recognition method based on feature auto-encoding. This method takes the normalized frequency spectrum of the signal as input, uses a restricted Boltzmann machine to perform unsupervised automatic encoding of the data, extracts the deep data structure layer by layer, and classifies the acquired features through the {BP} neural network. This method was tested using actual ship radiated noise database, and the results show that proposed classification system has better recognition accuracy and adaptability than the hand-crafted feature extraction based method.},
	pages = {5399},
	number = {18},
	journaltitle = {Sensors},
	shortjournal = {Sensors},
	author = {Luo, Xinwei and Feng, Yulin},
	urldate = {2024-06-20},
	date = {2020-09-21},
	langid = {english},
	note = {29 citations (Semantic Scholar/{DOI}) [2024-10-15]
27 citations (Crossref) [2024-10-14]},
	keywords = {Initial reading list, {RBM}},
}

@article{martinez-murcia_studying_2020,
	title = {Studying the Manifold Structure of Alzheimer's Disease: A Deep Learning Approach Using Convolutional Autoencoders},
	volume = {24},
	rights = {https://creativecommons.org/licenses/by/4.0/legalcode},
	issn = {2168-2194, 2168-2208},
	url = {https://ieeexplore.ieee.org/document/8737996/},
	doi = {10.1109/JBHI.2019.2914970},
	shorttitle = {Studying the Manifold Structure of Alzheimer's Disease},
	pages = {17--26},
	number = {1},
	journaltitle = {{IEEE} Journal of Biomedical and Health Informatics},
	shortjournal = {{IEEE} J. Biomed. Health Inform.},
	author = {Martinez-Murcia, Francisco J. and Ortiz, Andres and Gorriz, Juan-Manuel and Ramirez, Javier and Castillo-Barnes, Diego},
	urldate = {2024-08-16},
	date = {2020-01},
	note = {130 citations (Semantic Scholar/{DOI}) [2024-10-15]
148 citations (Crossref) [2024-10-14]},
}

@article{neupane_review_2020,
	title = {A Review on Deep Learning-Based Approaches for Automatic Sonar Target Recognition},
	volume = {9},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2079-9292},
	url = {https://www.mdpi.com/2079-9292/9/11/1972},
	doi = {10.3390/electronics9111972},
	abstract = {Underwater acoustics has been implemented mostly in the field of sound navigation and ranging ({SONAR}) procedures for submarine communication, the examination of maritime assets and environment surveying, target and object recognition, and measurement and study of acoustic sources in the underwater atmosphere. With the rapid development in science and technology, the advancement in sonar systems has increased, resulting in a decrement in underwater casualties. The sonar signal processing and automatic target recognition using sonar signals or imagery is itself a challenging process. Meanwhile, highly advanced data-driven machine-learning and deep learning-based methods are being implemented for acquiring several types of information from underwater sound data. This paper reviews the recent sonar automatic target recognition, tracking, or detection works using deep learning algorithms. A thorough study of the available works is done, and the operating procedure, results, and other necessary details regarding the data acquisition process, the dataset used, and the information regarding hyper-parameters is presented in this article. This paper will be of great assistance for upcoming scholars to start their work on sonar automatic target recognition.},
	pages = {1972},
	number = {11},
	journaltitle = {Electronics},
	shortjournal = {Electronics},
	author = {Neupane, Dhiraj and Seok, Jongwon},
	urldate = {2024-06-21},
	date = {2020-11-22},
	langid = {english},
	note = {93 citations (Semantic Scholar/{DOI}) [2024-10-15]
94 citations (Crossref) [2024-10-14]},
	keywords = {Review},
}

@article{premus_machine_2020,
	title = {Machine learning-based classification of recreational fishing vessel kinematics from broadband striation patterns},
	volume = {147},
	issn = {0001-4966, 1520-8524},
	url = {https://pubs.aip.org/jasa/article/147/2/EL184/995419/Machine-learning-based-classification-of},
	doi = {10.1121/10.0000774},
	abstract = {Machine learning is applied to the classification of underwater noise for rapid identification of surface vessel opening and closing behavior. The classification feature employed is the broadband striation pattern observed in a vessel's acoustic spectrogram measured at a nearby hydrophone. Convolutional neural networks are particularly well-suited to the recognition of textures such as interference patterns in broadband noise radiated from moving vessels. Such patterns are known to encode information related to the motion of its source. Rapid understanding of target kinematics through machine learning can provide powerful and informative cues as to the identity and behavior of a detected surface vessel.},
	pages = {EL184--EL188},
	number = {2},
	journaltitle = {The Journal of the Acoustical Society of America},
	author = {Premus, Vincent E. and Evans, Max E. and Abbot, Philip A.},
	urldate = {2024-10-10},
	date = {2020-02-01},
	langid = {english},
	note = {5 citations (Semantic Scholar/{DOI}) [2024-10-15]
8 citations (Crossref) [2024-10-14]},
}

@article{shen_ship_2020,
	title = {Ship Type Classification by Convolutional Neural Networks with Auditory-Like Mechanisms},
	volume = {20},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/20/1/253},
	doi = {10.3390/s20010253},
	abstract = {Ship type classification with radiated noise helps monitor the noise of shipping around the hydrophone deployment site. This paper introduces a convolutional neural network with several auditory-like mechanisms for ship type classification. The proposed model mainly includes a cochlea model and an auditory center model. In cochlea model, acoustic signal decomposition at basement membrane is implemented by time convolutional layer with auditory filters and dilated convolutions. The transformation of neural patterns at hair cells is modeled by a time frequency conversion layer to extract auditory features. In the auditory center model, auditory features are first selectively emphasized in a supervised manner. Then, spectro-temporal patterns are extracted by deep architecture with multistage auditory mechanisms. The whole model is optimized with an objective function of ship type classification to form the plasticity of the auditory system. The contributions compared with an auditory inspired convolutional neural network include the improvements in dilated convolutions, deep architecture and target layer. The proposed model can extract auditory features from a raw hydrophone signal and identify types of ships under different working conditions. The model achieved a classification accuracy of 87.2\% on four ship types and ocean background noise.},
	pages = {253},
	number = {1},
	journaltitle = {Sensors},
	shortjournal = {Sensors},
	author = {Shen, Sheng and Yang, Honghui and Yao, Xiaohui and Li, Junhao and Xu, Guanghui and Sheng, Meiping},
	urldate = {2024-10-10},
	date = {2020-01-01},
	langid = {english},
	note = {36 citations (Semantic Scholar/{DOI}) [2024-10-15]
37 citations (Crossref) [2024-10-14]},
}

@inproceedings{song_deep-shallow_2020,
	location = {Yanuca Island, Cuvu, Fiji},
	title = {A Deep-Shallow Network for Passive Underwater Target Recognition},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	isbn = {978-1-72817-649-9},
	url = {https://ieeexplore.ieee.org/document/9407848/},
	doi = {10.1109/HPCC-SmartCity-DSS50907.2020.00105},
	eventtitle = {2020 {IEEE} 22nd International Conference on High Performance Computing and Communications ({HPCC})},
	pages = {802--807},
	booktitle = {2020 {IEEE} 22nd International Conference on High Performance Computing and Communications ({HPCC})},
	publisher = {{IEEE}},
	author = {Song, Gaoyu and Liu, Xingang and Zeng, Xin and Luo, Hengguang and Wang, Dayu and Zhang, Boxuan},
	urldate = {2024-10-10},
	date = {2020-12},
	note = {1 citations (Semantic Scholar/{DOI}) [2024-10-15]
1 citations (Crossref) [2024-10-14]},
}

@inproceedings{tong_classification_2020,
	location = {Macau, China},
	title = {Classification and Recognition of Underwater Target Based on {MFCC} Feature Extraction},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	isbn = {978-1-72817-202-6},
	url = {https://ieeexplore.ieee.org/document/9259457/},
	doi = {10.1109/ICSPCC50002.2020.9259457},
	eventtitle = {2020 {IEEE} International Conference on Signal Processing, Communications and Computing ({ICSPCC})},
	pages = {1--4},
	booktitle = {2020 {IEEE} International Conference on Signal Processing, Communications and Computing ({ICSPCC})},
	publisher = {{IEEE}},
	author = {Tong, Yuze and Zhang, Xin and Ge, Yizhou},
	urldate = {2024-10-10},
	date = {2020-08-21},
	note = {13 citations (Semantic Scholar/{DOI}) [2024-10-15]
12 citations (Crossref) [2024-10-14]},
}

@article{vieira_underwater_2020,
	title = {Underwater noise recognition of marine vessels passages: two case studies using hidden Markov models},
	volume = {77},
	rights = {https://academic.oup.com/journals/pages/open\_access/funder\_policies/chorus/standard\_publication\_model},
	issn = {1054-3139, 1095-9289},
	url = {https://academic.oup.com/icesjms/article/77/6/2157/5609037},
	doi = {10.1093/icesjms/fsz194},
	shorttitle = {Underwater noise recognition of marine vessels passages},
	abstract = {Abstract
            Passive acoustic monitoring ({PAM}) is emerging as a cost-effective non-intrusive method to monitor the health and biodiversity of marine habitats, including the impacts of anthropogenic noise on marine organisms. When long {PAM} recordings are to be analysed, automatic recognition and identification processes are invaluable tools to extract the relevant information. We propose a pattern recognition methodology based on hidden Markov models ({HMMs}) for the detection and recognition of acoustic signals from marine vessels passages and test it in two different regions, the Tagus estuary in Portugal and the Öresund strait in the Baltic Sea. Results show that the combination of {HMMs} with {PAM} provides a powerful tool to monitor the presence of marine vessels and discriminate different vessels such as small boats, ferries, and large ships. Improvements to enhance the capability to discriminate different types of small recreational boats are discussed.},
	pages = {2157--2170},
	number = {6},
	journaltitle = {{ICES} Journal of Marine Science},
	author = {Vieira, Manuel and Amorim, M Clara P and Sundelöf, Andreas and Prista, Nuno and Fonseca, Paulo J},
	editor = {Ratilal, Purnima},
	urldate = {2024-10-10},
	date = {2020-11-01},
	langid = {english},
	note = {13 citations (Semantic Scholar/{DOI}) [2024-10-15]
14 citations (Crossref) [2024-10-14]},
}

@article{wang_stacked_2020,
	title = {A stacked convolutional sparse denoising autoencoder model for underwater heterogeneous information data},
	volume = {167},
	issn = {0003682X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0003682X20304953},
	doi = {10.1016/j.apacoust.2020.107391},
	pages = {107391},
	journaltitle = {Applied Acoustics},
	shortjournal = {Applied Acoustics},
	author = {Wang, Xingmei and Zhao, Yixu and Teng, Xuyang and Sun, Weiqi},
	urldate = {2024-09-24},
	date = {2020-10},
	langid = {english},
	note = {15 citations (Semantic Scholar/{DOI}) [2024-10-15]
18 citations (Crossref) [2024-10-14]},
	keywords = {Denoising},
}

@article{xie_feature_2020,
	title = {Feature Extraction of Ship-Radiated Noise Based on Enhanced Variational Mode Decomposition, Normalized Correlation Coefficient and Permutation Entropy},
	volume = {22},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1099-4300},
	url = {https://www.mdpi.com/1099-4300/22/4/468},
	doi = {10.3390/e22040468},
	abstract = {Due to the complexity and variability of underwater acoustic channels, ship-radiated noise ({SRN}) detected using the passive sonar is prone to be distorted. The entropy-based feature extraction method can improve this situation, to some extent. However, it is impractical to directly extract the entropy feature for the detected {SRN} signals. In addition, the existing conventional methods have a lack of suitable de-noising processing under the presence of marine environmental noise. To this end, this paper proposes a novel feature extraction method based on enhanced variational mode decomposition ({EVMD}), normalized correlation coefficient ({norCC}), permutation entropy ({PE}), and the particle swarm optimization-based support vector machine ({PSO}-{SVM}). Firstly, {EVMD} is utilized to obtain a group of intrinsic mode functions ({IMFs}) from the {SRN} signals. The noise-dominant {IMFs} are then eliminated by a de-noising processing prior to {PE} calculation. Next, the correlation coefficient between each signal-dominant {IMF} and the raw signal and {PE} of each signal-dominant {IMF} are calculated, respectively. After this, the {norCC} is used to weigh the corresponding {PE} and the sum of these weighted {PE} is considered as the final feature parameter. Finally, the feature vectors are fed into the {PSO}-{SVM} multi-class classifier to classify the {SRN} samples. The experimental results demonstrate that the recognition rate of the proposed methodology is up to 100\%, which is much higher than the currently existing methods. Hence, the method proposed in this paper is more suitable for the feature extraction of {SRN} signals.},
	pages = {468},
	number = {4},
	journaltitle = {Entropy},
	shortjournal = {Entropy},
	author = {Xie, Dongri and Esmaiel, Hamada and Sun, Haixin and Qi, Jie and Qasem, Zeyad A. H.},
	urldate = {2024-10-10},
	date = {2020-04-20},
	langid = {english},
	note = {20 citations (Semantic Scholar/{DOI}) [2024-10-15]
20 citations (Crossref) [2024-10-14]},
}

@article{xie_new_2020,
	title = {A New Feature Extraction Method Based on Improved Variational Mode Decomposition, Normalized Maximal Information Coefficient and Permutation Entropy for Ship-Radiated Noise},
	volume = {22},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1099-4300},
	url = {https://www.mdpi.com/1099-4300/22/6/620},
	doi = {10.3390/e22060620},
	abstract = {Due to the existence of marine environmental noise, coupled with the instability of underwater acoustic channel, ship-radiated noise ({SRN}) signals detected by sensors tend to suffer noise pollution as well as distortion caused by the transmission medium, making the denoising of the raw detected signals the new focus in the field of underwater acoustic target recognition. In view of this, this paper presents a novel hybrid feature extraction scheme integrating improved variational mode decomposition ({IVMD}), normalized maximal information coefficient ({norMIC}) and permutation entropy ({PE}) for {SRN} signals. Firstly, the {IVMD} method is employed to decompose the {SRN} signals into a number of finite intrinsic mode functions ({IMFs}). The noise {IMFs} are then filtered out by a denoising method before {PE} extraction. Next, the {MIC} between each retained {IMF} and the raw {SRN} signal and {PE} of retained {IMFs} are calculated, respectively. After this, the {norMICs} are used to weigh the {PE} values of the retained {IMFs} and the sum of the weighted {PE} results is regarded as the classification parameter. Finally, the feature vectors are fed into the particle swarm optimization-based support vector machine multi-class classifier ({PSO}-{SVM}) to identify different types of {SRN} samples. The experimental results have indicated that the classification accuracy of the proposed method is as high as 99.1667\%, which is much higher than that of other currently existing methods. Hence, the method proposed in this paper is more suitable for feature extraction of {SRN} signals in practical application.},
	pages = {620},
	number = {6},
	journaltitle = {Entropy},
	shortjournal = {Entropy},
	author = {Xie, Dongri and Sun, Haixin and Qi, Jie},
	urldate = {2024-10-10},
	date = {2020-06-03},
	langid = {english},
	note = {20 citations (Semantic Scholar/{DOI}) [2024-10-15]
20 citations (Crossref) [2024-10-14]},
}

@article{yang_underwater_2020,
	title = {Underwater Acoustic Research Trends with Machine Learning: General Background},
	volume = {34},
	issn = {1225-0767, 2287-6715},
	url = {http://joet.org/journal/view.php?doi=10.26748/KSOE.2020.015},
	doi = {10.26748/KSOE.2020.015},
	shorttitle = {Underwater Acoustic Research Trends with Machine Learning},
	pages = {147--154},
	number = {2},
	journaltitle = {Journal of Ocean Engineering and Technology},
	shortjournal = {J. Ocean Eng. Technol.},
	author = {Yang, Haesang and Lee, Keunhwa and Choo, Youngmin and Kim, Kookhyun},
	urldate = {2024-06-24},
	date = {2020-04-30},
	langid = {english},
	note = {26 citations (Semantic Scholar/{DOI}) [2024-10-15]
23 citations (Crossref) [2024-10-14]},
	keywords = {Review},
}

@article{yang_underwater_2020-1,
	title = {Underwater Acoustic Research Trends with Machine Learning: Passive {SONAR} Applications},
	volume = {34},
	issn = {1225-0767, 2287-6715},
	url = {http://joet.org/journal/view.php?doi=10.26748/KSOE.2020.017},
	doi = {10.26748/KSOE.2020.017},
	shorttitle = {Underwater Acoustic Research Trends with Machine Learning},
	pages = {227--236},
	number = {3},
	journaltitle = {Journal of Ocean Engineering and Technology},
	shortjournal = {J. Ocean Eng. Technol.},
	author = {Yang, Haesang and Lee, Keunhwa and Choo, Youngmin and Kim, Kookhyun},
	urldate = {2024-06-24},
	date = {2020-06-30},
	langid = {english},
	note = {35 citations (Semantic Scholar/{DOI}) [2024-10-15]
33 citations (Crossref) [2024-10-14]},
	keywords = {Review},
}

@article{yang_new_2020,
	title = {A New Denoising Method for Underwater Acoustic Signal},
	volume = {8},
	rights = {https://creativecommons.org/licenses/by/4.0/legalcode},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/9247188/},
	doi = {10.1109/ACCESS.2020.3035403},
	pages = {201874--201888},
	journaltitle = {{IEEE} Access},
	shortjournal = {{IEEE} Access},
	author = {Yang, Hong and Li, Lulu and Li, Guohui},
	urldate = {2024-09-24},
	date = {2020},
	note = {21 citations (Semantic Scholar/{DOI}) [2024-10-15]
23 citations (Crossref) [2024-10-14]},
}

@article{zhang_noise_2020,
	title = {Noise reduction in the spectral domain of hyperspectral images using denoising autoencoder methods},
	volume = {203},
	issn = {01697439},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S016974391930718X},
	doi = {10.1016/j.chemolab.2020.104063},
	pages = {104063},
	journaltitle = {Chemometrics and Intelligent Laboratory Systems},
	shortjournal = {Chemometrics and Intelligent Laboratory Systems},
	author = {Zhang, Chu and Zhou, Lei and Zhao, Yiying and Zhu, Susu and Liu, Fei and He, Yong},
	urldate = {2024-09-24},
	date = {2020-08},
	langid = {english},
	note = {49 citations (Semantic Scholar/{DOI}) [2024-10-15]
50 citations (Crossref) [2024-10-14]},
	keywords = {Denoising},
}

@inproceedings{zhang_adaptive_2020,
	location = {Changsha, China},
	title = {Adaptive Variational Mode Time-frequency Analysis of Ship Radiated Noise},
	isbn = {978-1-72816-406-9},
	url = {https://ieeexplore.ieee.org/document/9532095/},
	doi = {10.1109/ICISCE50968.2020.00327},
	eventtitle = {2020 7th International Conference on Information Science and Control Engineering ({ICISCE})},
	pages = {1652--1656},
	booktitle = {2020 7th International Conference on Information Science and Control Engineering ({ICISCE})},
	publisher = {{IEEE}},
	author = {Zhang, Haoyi and Junejo, Naveed Ur Rehman and Sun, Weitao and Chen, Hailan and Yan, Jiaquan},
	urldate = {2024-10-10},
	date = {2020-12},
	note = {3 citations (Semantic Scholar/{DOI}) [2024-10-15]
2 citations (Crossref) [2024-10-14]},
}

@article{zhou_denoising_2020,
	title = {A denoising representation framework for underwater acoustic signal recognition},
	volume = {147},
	issn = {0001-4966, 1520-8524},
	url = {https://pubs.aip.org/jasa/article/147/4/EL377/1058740/A-denoising-representation-framework-for},
	doi = {10.1121/10.0001130},
	abstract = {To suppress the noise interference in underwater acoustic signals for recognition, a practical denoising representation and recognition method is proposed. This algorithm first generates the multi-images between marine noise and target signal by correlation and “dropout” processing, adaptively. Second, a convolutional denoising autoencoder is designed to train the segmented multi-images in parallel to acquire denoising features. Finally, to improve the classification accuracy of random forest ({RF}), the weight fusion is exploited to initialize parallel {RF} classifier. Numerical experiments are shown that demonstrate superiority to three other methods in feature denoising and classification under underwater acoustic scenes.},
	pages = {EL377--EL383},
	number = {4},
	journaltitle = {The Journal of the Acoustical Society of America},
	author = {Zhou, Xingyue and Yang, Kunde},
	urldate = {2024-10-10},
	date = {2020-04-01},
	langid = {english},
	note = {22 citations (Semantic Scholar/{DOI}) [2024-10-15]
22 citations (Crossref) [2024-10-14]},
}

@article{alzubaidi_review_2021,
	title = {Review of deep learning: concepts, {CNN} architectures, challenges, applications, future directions},
	volume = {8},
	issn = {2196-1115},
	url = {https://journalofbigdata.springeropen.com/articles/10.1186/s40537-021-00444-8},
	doi = {10.1186/s40537-021-00444-8},
	shorttitle = {Review of deep learning},
	abstract = {Abstract
            In the last few years, the deep learning ({DL}) computing paradigm has been deemed the Gold Standard in the machine learning ({ML}) community. Moreover, it has gradually become the most widely used computational approach in the field of {ML}, thus achieving outstanding results on several complex cognitive tasks, matching or even beating those provided by human performance. One of the benefits of {DL} is the ability to learn massive amounts of data. The {DL} field has grown fast in the last few years and it has been extensively used to successfully address a wide range of traditional applications. More importantly, {DL} has outperformed well-known {ML} techniques in many domains, e.g., cybersecurity, natural language processing, bioinformatics, robotics and control, and medical information processing, among many others. Despite it has been contributed several works reviewing the State-of-the-Art on {DL}, all of them only tackled one aspect of the {DL}, which leads to an overall lack of knowledge about it. Therefore, in this contribution, we propose using a more holistic approach in order to provide a more suitable starting point from which to develop a full understanding of {DL}. Specifically, this review attempts to provide a more comprehensive survey of the most important aspects of {DL} and including those enhancements recently added to the field. In particular, this paper outlines the importance of {DL}, presents the types of {DL} techniques and networks. It then presents convolutional neural networks ({CNNs}) which the most utilized {DL} network type and describes the development of {CNNs} architectures together with their main features, e.g., starting with the {AlexNet} network and closing with the High-Resolution network ({HR}.Net). Finally, we further present the challenges and suggested solutions to help researchers understand the existing research gaps. It is followed by a list of the major {DL} applications. Computational tools including {FPGA}, {GPU}, and {CPU} are summarized along with a description of their influence on {DL}. The paper ends with the evolution matrix, benchmark datasets, and summary and conclusion.},
	pages = {53},
	number = {1},
	journaltitle = {Journal of Big Data},
	shortjournal = {J Big Data},
	author = {Alzubaidi, Laith and Zhang, Jinglan and Humaidi, Amjad J. and Al-Dujaili, Ayad and Duan, Ye and Al-Shamma, Omran and Santamaría, J. and Fadhel, Mohammed A. and Al-Amidie, Muthana and Farhan, Laith},
	urldate = {2024-09-23},
	date = {2021-03-31},
	langid = {english},
	note = {3255 citations (Semantic Scholar/{DOI}) [2024-10-15]
3128 citations (Crossref) [2024-10-14]},
}

@article{axelsson_neural-network-based_2021,
	title = {Neural-Network-Based Classification of Commercial Ships From Multi-Influence Passive Signatures},
	volume = {46},
	issn = {1558-1691},
	url = {https://ieeexplore.ieee.org/document/9123373/?arnumber=9123373},
	doi = {10.1109/JOE.2020.2982756},
	abstract = {Monitoring the underwater environment is important for maritime security, marine conservation, and mine countermeasures. With developments in computation and artificial intelligence, it is increasingly important to measure and classify underwater ship signatures. In this work, we design an artificial neural network that classifies commercial ships based on their multi-influence signature. In total, 103 ship passages were included in the considered data set, with signatures recorded as the ship crossed a line of passive underwater sensors. The multi-influence signature was formed by feature-level sensor fusion of the hydroacoustic signature, the underwater electric potential, and the static and alternating magnetic signatures. Ships were classified according to size, or type, as broadcast on the {AIS}. With feature-level fusion, the neural network will optimize the relationship between different types of signatures, emphasizing features with greater predictive power. At the same time, weak features, even if not independently adequate for classification, can add information that improves accuracy further. The developed neural network achieved a classification accuracy of 87.4\% when classifying according to size. With augmented data to balance the classes, 85.0\% classification accuracy was achieved when classifying according to ship type. This is a large improvement on the found classification accuracy when using only hydroacoustic or electromagnetic signatures. This article verifies the value of feature-level sensor fusion in classification, and provides guidance on classifier design depending on the exact ship classification task.},
	pages = {634--641},
	number = {2},
	journaltitle = {{IEEE} Journal of Oceanic Engineering},
	author = {Axelsson, Oskar and Rhén, Christin},
	urldate = {2024-10-09},
	date = {2021-04},
	note = {5 citations (Semantic Scholar/{DOI}) [2024-10-15]
3 citations (Crossref) [2024-10-14]
Conference Name: {IEEE} Journal of Oceanic Engineering},
}

@article{bach_classification_2021,
	title = {Classification of Surface Vehicle Propeller Cavitation Noise Using Spectrogram Processing in Combination with Convolution Neural Network},
	volume = {21},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/21/10/3353},
	doi = {10.3390/s21103353},
	abstract = {This paper proposes a method to enhance the quality of detecting and classifying surface vehicle propeller cavitation noise ({VPCN}) in shallow water by using the improved Detection Envelope Modulation On Noise ({DEMON}) algorithm in combination with the modified Convolution Neural Network ({CNN}). To improve the quality of the {VPCN} spectrogram signal, we apply the {DEMON} algorithm while analyzing the amplitude variation ({AV}) to detect the fundamental frequencies of the {VPCN} signal. To enhance the performance of the traditional {CNN}, we adapt the size of the sliding window in accordance with the properties of the {VPCN} spectrogram data, and also reconstruct the {CNN} layer structure. As for the results, the fundamental frequencies contented in the {VPCN} spectrogram data can be detected. The analytical results based on the measured data show that the accuracy of the {VPCN} classification obtained by the proposed method is above 90\%, which is higher than those obtained by traditional methods.},
	pages = {3353},
	number = {10},
	journaltitle = {Sensors},
	shortjournal = {Sensors},
	author = {Bach, Nhat Hoang and Vu, Le Ha and Nguyen, Van Duc},
	urldate = {2024-10-09},
	date = {2021-05-12},
	langid = {english},
	note = {8 citations (Semantic Scholar/{DOI}) [2024-10-15]
10 citations (Crossref) [2024-10-14]},
}

@article{chen_underwater_2021,
	title = {Underwater Target Recognition Based on Multi-Decision {LOFAR} Spectrum Enhancement: A Deep-Learning Approach},
	volume = {13},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1999-5903},
	url = {https://www.mdpi.com/1999-5903/13/10/265},
	doi = {10.3390/fi13100265},
	shorttitle = {Underwater Target Recognition Based on Multi-Decision {LOFAR} Spectrum Enhancement},
	abstract = {Underwater target recognition is an important supporting technology for the development of marine resources, which is mainly limited by the purity of feature extraction and the universality of recognition schemes. The low-frequency analysis and recording ({LOFAR}) spectrum is one of the key features of the underwater target, which can be used for feature extraction. However, the complex underwater environment noise and the extremely low signal-to-noise ratio of the target signal lead to breakpoints in the {LOFAR} spectrum, which seriously hinders the underwater target recognition. To overcome this issue and to further improve the recognition performance, we adopted a deep-learning approach for underwater target recognition, and a novel {LOFAR} spectrum enhancement ({LSE})-based underwater target-recognition scheme was proposed, which consists of preprocessing, offline training, and online testing. In preprocessing, we specifically design a {LOFAR} spectrum enhancement based on multi-step decision algorithm to recover the breakpoints in {LOFAR} spectrum. In offline training, the enhanced {LOFAR} spectrum is adopted as the input of convolutional neural network ({CNN}) and a {LOFAR}-based {CNN} ({LOFAR}-{CNN}) for online recognition is developed. Taking advantage of the powerful capability of {CNN} in feature extraction, the recognition accuracy can be further improved by the proposed {LOFAR}-{CNN}. Finally, extensive simulation results demonstrate that the {LOFAR}-{CNN} network can achieve a recognition accuracy of 95.22\%, which outperforms the state-of-the-art methods.},
	pages = {265},
	number = {10},
	journaltitle = {Future Internet},
	shortjournal = {Future Internet},
	author = {Chen, Jie and Han, Bing and Ma, Xufeng and Zhang, Jian},
	urldate = {2024-10-09},
	date = {2021-10-13},
	langid = {english},
	note = {31 citations (Semantic Scholar/{DOI}) [2024-10-15]
30 citations (Crossref) [2024-10-14]},
}

@article{cheng_underwater_2021,
	title = {Underwater Target Signal Classification Using the Hybrid Routing Neural Network},
	volume = {21},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/21/23/7799},
	doi = {10.3390/s21237799},
	abstract = {In signal analysis and processing, underwater target recognition ({UTR}) is one of the most important technologies. Simply and quickly identify target types using conventional methods in underwater acoustic conditions is quite a challenging task. The problem can be conveniently handled by a deep learning network ({DLN}), which yields better classification results than conventional methods. In this paper, a novel deep learning method with a hybrid routing network is considered, which can abstract the features of time-domain signals. The used network comprises multiple routing structures and several options for the auxiliary branch, which promotes impressive effects as a result of exchanging the learned features of different branches. The experiment shows that the used network possesses more advantages in the underwater signal classification task.},
	pages = {7799},
	number = {23},
	journaltitle = {Sensors},
	shortjournal = {Sensors},
	author = {Cheng, Xiao and Zhang, Hao},
	urldate = {2024-10-09},
	date = {2021-11-24},
	langid = {english},
	note = {2 citations (Semantic Scholar/{DOI}) [2024-10-15]
2 citations (Crossref) [2024-10-14]},
}

@misc{fujimura_noisy-target_2021,
	title = {Noisy-target Training: A Training Strategy for {DNN}-based Speech Enhancement without Clean Speech},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/2101.08625},
	doi = {10.48550/ARXIV.2101.08625},
	shorttitle = {Noisy-target Training},
	abstract = {Deep neural network ({DNN})-based speech enhancement ordinarily requires clean speech signals as the training target. However, collecting clean signals is very costly because they must be recorded in a studio. This requirement currently restricts the amount of training data for speech enhancement to less than 1/1000 of that of speech recognition which does not need clean signals. Increasing the amount of training data is important for improving the performance, and hence the requirement of clean signals should be relaxed. In this paper, we propose a training strategy that does not require clean signals. The proposed method only utilizes noisy signals for training, which enables us to use a variety of speech signals in the wild. Our experimental results showed that the proposed method can achieve the performance similar to that of a {DNN} trained with clean signals.},
	publisher = {{arXiv}},
	author = {Fujimura, Takuya and Koizumi, Yuma and Yatabe, Kohei and Miyazaki, Ryoichi},
	urldate = {2024-09-24},
	date = {2021},
	note = {37 citations (Semantic Scholar/{arXiv}) [2024-10-15]
Version Number: 2},
}

@misc{gong_ast_2021,
	title = {{AST}: Audio Spectrogram Transformer},
	rights = {Creative Commons Attribution 4.0 International},
	url = {https://arxiv.org/abs/2104.01778},
	doi = {10.48550/ARXIV.2104.01778},
	shorttitle = {{AST}},
	abstract = {In the past decade, convolutional neural networks ({CNNs}) have been widely adopted as the main building block for end-to-end audio classification models, which aim to learn a direct mapping from audio spectrograms to corresponding labels. To better capture long-range global context, a recent trend is to add a self-attention mechanism on top of the {CNN}, forming a {CNN}-attention hybrid model. However, it is unclear whether the reliance on a {CNN} is necessary, and if neural networks purely based on attention are sufficient to obtain good performance in audio classification. In this paper, we answer the question by introducing the Audio Spectrogram Transformer ({AST}), the first convolution-free, purely attention-based model for audio classification. We evaluate {AST} on various audio classification benchmarks, where it achieves new state-of-the-art results of 0.485 {mAP} on {AudioSet}, 95.6\% accuracy on {ESC}-50, and 98.1\% accuracy on Speech Commands V2.},
	publisher = {{arXiv}},
	author = {Gong, Yuan and Chung, Yu-An and Glass, James},
	urldate = {2024-10-14},
	date = {2021},
	note = {648 citations (Semantic Scholar/{arXiv}) [2024-10-15]
Version Number: 3},
}

@inproceedings{haiyan_semi-supervised_2021,
	location = {Harbin, China},
	title = {Semi-Supervised Noise Classification Based on Auto-Encoder},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	isbn = {978-1-72818-190-5},
	url = {https://ieeexplore.ieee.org/document/9520064/},
	doi = {10.1109/COA50123.2021.9520064},
	eventtitle = {2021 {OES} China Ocean Acoustics ({COA})},
	pages = {982--985},
	booktitle = {2021 {OES} China Ocean Acoustics ({COA})},
	publisher = {{IEEE}},
	author = {Haiyan, Ni and Wenbo, Wang and Meng, Zhao and Qunyan, Ren and Li, Ma},
	urldate = {2024-10-09},
	date = {2021-07-14},
	note = {1 citations (Semantic Scholar/{DOI}) [2024-10-15]
0 citations (Crossref) [2024-10-14]},
}

@misc{he_masked_2021,
	title = {Masked Autoencoders Are Scalable Vision Learners},
	rights = {Creative Commons Attribution 4.0 International},
	url = {https://arxiv.org/abs/2111.06377},
	doi = {10.48550/ARXIV.2111.06377},
	abstract = {This paper shows that masked autoencoders ({MAE}) are scalable self-supervised learners for computer vision. Our {MAE} approach is simple: we mask random patches of the input image and reconstruct the missing pixels. It is based on two core designs. First, we develop an asymmetric encoder-decoder architecture, with an encoder that operates only on the visible subset of patches (without mask tokens), along with a lightweight decoder that reconstructs the original image from the latent representation and mask tokens. Second, we find that masking a high proportion of the input image, e.g., 75\%, yields a nontrivial and meaningful self-supervisory task. Coupling these two designs enables us to train large models efficiently and effectively: we accelerate training (by 3x or more) and improve accuracy. Our scalable approach allows for learning high-capacity models that generalize well: e.g., a vanilla {ViT}-Huge model achieves the best accuracy (87.8\%) among methods that use only {ImageNet}-1K data. Transfer performance in downstream tasks outperforms supervised pre-training and shows promising scaling behavior.},
	publisher = {{arXiv}},
	author = {He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Dollár, Piotr and Girshick, Ross},
	urldate = {2024-09-23},
	date = {2021},
	note = {5800 citations (Semantic Scholar/{arXiv}) [2024-10-15]
Version Number: 3},
}

@article{hong_underwater_2021,
	title = {Underwater Acoustic Target Recognition with a Residual Network and the Optimized Feature Extraction Method},
	volume = {11},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2076-3417},
	url = {https://www.mdpi.com/2076-3417/11/4/1442},
	doi = {10.3390/app11041442},
	abstract = {Underwater Acoustic Target Recognition ({UATR}) remains one of the most challenging tasks in underwater signal processing due to the lack of labeled data acquisition, the impact of the time-space varying intrinsic characteristics, and the interference from other noise sources. Although some deep learning methods have been proven to achieve state-of-the-art accuracy, the accuracy of the recognition task can be improved by designing a Residual Network and optimizing feature extraction. To give a more comprehensive representation of the underwater acoustic signal, we first propose the three-dimensional fusion features along with the data augment strategy of {SpecAugment}. Afterward, an 18-layer Residual Network ({ResNet}18), which contains the center loss function with the embedding layer, is designed to train the aggregated features with an adaptable learning rate. The recognition experiments are conducted on the ship-radiated noise dataset from a real environment, and the accuracy results of 94.3\% indicate that the proposed method is appropriate for underwater acoustic recognition problems and sufficiently surpasses other classification methods.},
	pages = {1442},
	number = {4},
	journaltitle = {Applied Sciences},
	shortjournal = {Applied Sciences},
	author = {Hong, Feng and Liu, Chengwei and Guo, Lijuan and Chen, Feng and Feng, Haihong},
	urldate = {2024-08-06},
	date = {2021-02-05},
	langid = {english},
	note = {43 citations (Semantic Scholar/{DOI}) [2024-10-15]
50 citations (Crossref) [2024-10-14]},
}

@article{hu_underwater_2021,
	title = {Underwater Acoustic Target Recognition Based on Depthwise Separable Convolution Neural Networks},
	volume = {21},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/21/4/1429},
	doi = {10.3390/s21041429},
	abstract = {Facing the complex marine environment, it is extremely challenging to conduct underwater acoustic target feature extraction and recognition using ship-radiated noise. In this paper, firstly, taking the one-dimensional time-domain raw signal of the ship as the input of the model, a new deep neural network model for underwater target recognition is proposed. Depthwise separable convolution and time-dilated convolution are used for passive underwater acoustic target recognition for the first time. The proposed model realizes automatic feature extraction from the raw data of ship radiated noise and temporal attention in the process of underwater target recognition. Secondly, the measured data are used to evaluate the model, and cluster analysis and visualization analysis are performed based on the features extracted from the model. The results show that the features extracted from the model have good characteristics of intra-class aggregation and inter-class separation. Furthermore, the cross-folding model is used to verify that there is no overfitting in the model, which improves the generalization ability of the model. Finally, the model is compared with traditional underwater acoustic target recognition, and its accuracy is significantly improved by 6.8\%.},
	pages = {1429},
	number = {4},
	journaltitle = {Sensors},
	shortjournal = {Sensors},
	author = {Hu, Gang and Wang, Kejun and Liu, Liangliang},
	urldate = {2024-10-09},
	date = {2021-02-18},
	langid = {english},
	note = {47 citations (Semantic Scholar/{DOI}) [2024-10-15]
51 citations (Crossref) [2024-10-14]},
}

@article{huang_line_2021,
	title = {Line spectrum extraction based on autoassociative neural networks},
	volume = {1},
	issn = {2691-1191},
	url = {https://pubs.aip.org/jel/article/1/1/016003/219734/Line-spectrum-extraction-based-on-autoassociative},
	doi = {10.1121/10.0003038},
	abstract = {Line spectrum is an important feature for the detection and classification of underwater targets. This letter presents a method for extracting the line spectrum submerged in underwater ambient noise through autoassociative neural networks ({AANN}). Compared with the traditional methods, the proposed method based on {AANN} can directly enhance the line spectrum from the raw time-domain noise data without relying on prior information and spectral features. Moreover, the proposed method can suppress the background noise while extracting the line spectrum. Both the numerical simulation and experimental data test results demonstrate that the proposed method provides a good ability to extract the line spectrum from the strong background noise.},
	pages = {016003},
	number = {1},
	journaltitle = {{JASA} Express Letters},
	author = {Huang, Chunlong and Yang, Kunde and Yang, Qiulong and Zhang, Hao},
	urldate = {2024-10-09},
	date = {2021-01-01},
	langid = {english},
	note = {2 citations (Semantic Scholar/{DOI}) [2024-10-15]
1 citations (Crossref) [2024-10-14]},
}

@article{irfan_novel_2021,
	title = {A novel lifelong learning model based on cross domain knowledge extraction and transfer to classify underwater images},
	volume = {552},
	issn = {00200255},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0020025520311464},
	doi = {10.1016/j.ins.2020.11.048},
	pages = {80--101},
	journaltitle = {Information Sciences},
	shortjournal = {Information Sciences},
	author = {Irfan, Muhammad and Jiangbin, Zheng and Iqbal, Muhammad and Arif, Muhammad Hassan},
	urldate = {2024-08-14},
	date = {2021-04},
	langid = {english},
	note = {28 citations (Semantic Scholar/{DOI}) [2024-10-15]
27 citations (Crossref) [2024-10-14]},
}

@article{irfan_brain_2021,
	title = {Brain inspired lifelong learning model based on neural based learning classifier system for underwater data classification},
	volume = {186},
	issn = {09574174},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417421011660},
	doi = {10.1016/j.eswa.2021.115798},
	pages = {115798},
	journaltitle = {Expert Systems with Applications},
	shortjournal = {Expert Systems with Applications},
	author = {Irfan, Muhammad and Jiangbin, Zheng and Iqbal, Muhammad and Masood, Zafar and Arif, Muhammad Hassan and Hassan, Syed Rauf Ul},
	urldate = {2024-08-19},
	date = {2021-12},
	langid = {english},
	note = {17 citations (Semantic Scholar/{DOI}) [2024-10-15]
19 citations (Crossref) [2024-10-14]},
}

@article{irfan_enhancing_2021,
	title = {Enhancing learning classifier systems through convolutional autoencoder to classify underwater images},
	volume = {25},
	issn = {1432-7643, 1433-7479},
	url = {https://link.springer.com/10.1007/s00500-021-05738-w},
	doi = {10.1007/s00500-021-05738-w},
	pages = {10423--10440},
	number = {15},
	journaltitle = {Soft Computing},
	shortjournal = {Soft Comput},
	author = {Irfan, Muhammad and Jiangbin, Zheng and Iqbal, Muhammad and Arif, Muhammad Hassan},
	urldate = {2024-08-19},
	date = {2021-08},
	langid = {english},
	note = {17 citations (Semantic Scholar/{DOI}) [2024-10-15]
19 citations (Crossref) [2024-10-14]},
}

@article{irfan_deepship_2021,
	title = {{DeepShip}: An underwater acoustic benchmark dataset and a separable convolution based autoencoder for classification},
	volume = {183},
	doi = {10.1016/j.eswa.2021.115270},
	abstract = {Abstract   Underwater acoustic classification is a challenging problem because of presence of high background noise and complex sound propagation patterns in the sea environment. Various algorithms proposed in last few years used own privately collected datasets for design and validation. Such data is not publicly available. To conduct research in this field, there is a dire need of publicly available dataset. To bridge this gap, we construct and present an underwater acoustic dataset, named {DeepShip}, which consists of 47h and 4min of real world underwater recordings of 265 different ships belong to four classes. The proposed dataset includes recording from throughout the year with different sea states and noise levels. The presented dataset will not only help to evaluate the performance of existing algorithms but it shall also benefit the research community in future. Using the proposed dataset, we also conducted a comprehensive study of various machine learning and deep learning algorithms on six time–frequency based extracted features. In addition, we propose a novel separable convolution based autoencoder network for better classification accuracy. Experiments results, which are compared based on classification accuracy, precision, recall, f1-score, and analyzed by using paired sampled statistical t-test, show that the proposed network achieves classification accuracy of 77.53\% using {CQT} feature, which is better than as achieved by other methods.},
	pages = {115270},
	journaltitle = {Expert Systems With Applications},
	author = {Irfan, Muhammad and Zheng, Jiangbin and {Jiangbin Zheng} and Jiangbin, Zheng and {Shahid Ali} and Ali, Shahid and Ali, Shahid and {Muhammad Iqbal} and Iqbal, Muhammad and {Zafar Masood} and Masood, Zafar and {Umar Zakir Abdul Hamid} and Hamid, Umar},
	date = {2021-11-30},
	doi = {10.1016/j.eswa.2021.115270},
	note = {119 citations (Semantic Scholar/{DOI}) [2024-10-15]
107 citations (Crossref) [2024-10-14]
{MAG} {ID}: 3172124183},
}

@article{jiang_interpretable_2021,
	title = {Interpretable features for underwater acoustic target recognition},
	volume = {173},
	issn = {02632241},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0263224120310988},
	doi = {10.1016/j.measurement.2020.108586},
	pages = {108586},
	journaltitle = {Measurement},
	shortjournal = {Measurement},
	author = {Jiang, Junjun and Wu, Zhenning and Lu, Junan and Huang, Min and Xiao, Zhongzhe},
	urldate = {2024-09-24},
	date = {2021-03},
	langid = {english},
	note = {22 citations (Semantic Scholar/{DOI}) [2024-10-15]
19 citations (Crossref) [2024-10-14]},
}

@article{kamal_passive_2021,
	title = {Passive sonar automated target classifier for shallow waters using end-to-end learnable deep convolutional {LSTMs}},
	volume = {24},
	issn = {22150986},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2215098621000227},
	doi = {10.1016/j.jestch.2021.01.014},
	pages = {860--871},
	number = {4},
	journaltitle = {Engineering Science and Technology, an International Journal},
	shortjournal = {Engineering Science and Technology, an International Journal},
	author = {Kamal, Suraj and Satheesh Chandran, C. and Supriya, M.H.},
	urldate = {2024-10-09},
	date = {2021-08},
	langid = {english},
	note = {17 citations (Semantic Scholar/{DOI}) [2024-10-15]
9 citations (Crossref) [2024-10-14]},
}

@article{li_refined_2021,
	title = {Refined Composite Multi-Scale Reverse Weighted Permutation Entropy and Its Applications in Ship-Radiated Noise},
	volume = {23},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1099-4300},
	url = {https://www.mdpi.com/1099-4300/23/4/476},
	doi = {10.3390/e23040476},
	abstract = {Ship-radiated noise is one of the important signal types under the complex ocean background, which can well reflect physical properties of ships. As one of the valid measures to characterize the complexity of ship-radiated noise, permutation entropy ({PE}) has the advantages of high efficiency and simple calculation. However, {PE} has the problems of missing amplitude information and single scale. To address the two drawbacks, refined composite multi-scale reverse weighted {PE} ({RCMRWPE}), as a novel measurement technology of describing the signal complexity, is put forward based on refined composite multi-scale processing ({RCMP}) and reverse weighted {PE} ({RWPE}). {RCMP} is an improved method of coarse-graining, which not only solves the problem of single scale, but also improves the stability of traditional coarse-graining; {RWPE} has been proposed more recently, and has better inter-class separability and robustness performance to noise than {PE}, weighted {PE} ({WPE}), and reverse {PE} ({RPE}). Additionally, a feature extraction scheme of ship-radiated noise is proposed based on {RCMRWPE}, furthermore, {RCMRWPE} is combined with discriminant analysis classifier ({DAC}) to form a new classification method. After that, a large number of comparative experiments of feature extraction schemes and classification methods with two artificial random signals and six ship-radiated noise are carried out, which show that the proposed feature extraction scheme has better performance in distinguishing ability and stability than the other three similar feature extraction schemes based on multi-scale {PE} ({MPE}), multi-scale {WPE} ({MWPE}), and multi-scale {RPE} ({MRPE}), and the proposed classification method also has the highest recognition rate.},
	pages = {476},
	number = {4},
	journaltitle = {Entropy},
	shortjournal = {Entropy},
	author = {Li, Yuxing and Geng, Bo and Jiao, Shangbin},
	urldate = {2024-10-09},
	date = {2021-04-17},
	langid = {english},
	note = {11 citations (Semantic Scholar/{DOI}) [2024-10-15]
10 citations (Crossref) [2024-10-14]},
}

@article{li_comparative_2021,
	title = {A comparative study of four multi-scale entropies combined with grey relational degree in classification of ship-radiated noise},
	volume = {176},
	issn = {0003682X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0003682X20309701},
	doi = {10.1016/j.apacoust.2020.107865},
	pages = {107865},
	journaltitle = {Applied Acoustics},
	shortjournal = {Applied Acoustics},
	author = {Li, Yuxing and Jiao, Shangbin and Geng, Bo},
	urldate = {2024-10-09},
	date = {2021-05},
	langid = {english},
	note = {14 citations (Semantic Scholar/{DOI}) [2024-10-15]
15 citations (Crossref) [2024-10-14]},
}

@article{li_rcmfrde_2021,
	title = {{RCMFRDE}: Refined Composite Multiscale Fluctuation-Based Reverse Dispersion Entropy for Feature Extraction of Ship-Radiated Noise},
	volume = {2021},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1563-5147, 1024-123X},
	url = {https://www.hindawi.com/journals/mpe/2021/7150921/},
	doi = {10.1155/2021/7150921},
	shorttitle = {{RCMFRDE}},
	abstract = {Dispersion entropy ({DE}), as a newly proposed entropy, has achieved remarkable results in its application. In this paper, on the basis of {DE}, combined with coarse-grained processing, we introduce the fluctuation and distance information of signal and propose the refined composite multiscale fluctuation-based reverse dispersion entropy ({RCMFRDE}). As an emerging complexity analysis mode, {RCMFRDE} has been used for the first time for the feature extraction of ship-radiated noise signals to mitigate the loss caused by the misclassification of ships on the ocean. Meanwhile, a classification and recognition method combined with K-nearest neighbor ({KNN}) came into being, namely, {RCMFRDE}-{KNN}. The experimental results indicated that {RCMFRDE} has the highest recognition rate in the single feature case and up to 100\% in the double feature case, far better than multiscale {DE} ({MDE}), multiscale fluctuation-based {DE} ({MFDE}), multiscale permutation entropy ({MPE}), and multiscale reverse dispersion entropy ({MRDE}), and all the experimental results show that the {RCMFRDE} proposed in this paper improves the separability of the commonly used entropy in the hydroacoustic domain.},
	pages = {1--18},
	journaltitle = {Mathematical Problems in Engineering},
	shortjournal = {Mathematical Problems in Engineering},
	author = {Li, Yuxing and Jiao, Shangbin and Geng, Bo and Jiang, Xinru},
	editor = {Abdollahzadeh Jamalabadi, Mohammad Yaghoub},
	urldate = {2024-10-09},
	date = {2021-12-16},
	langid = {english},
	note = {6 citations (Semantic Scholar/{DOI}) [2024-10-15]
5 citations (Crossref) [2024-10-14]},
}

@article{li_research_2021,
	title = {Research on feature extraction of ship-radiated noise based on multi-scale reverse dispersion entropy},
	volume = {173},
	issn = {0003682X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0003682X20308410},
	doi = {10.1016/j.apacoust.2020.107737},
	pages = {107737},
	journaltitle = {Applied Acoustics},
	shortjournal = {Applied Acoustics},
	author = {Li, Yuxing and Jiao, Shangbin and Geng, Bo and Zhou, Yuan},
	urldate = {2024-10-09},
	date = {2021-02},
	langid = {english},
	note = {28 citations (Semantic Scholar/{DOI}) [2024-10-15]
28 citations (Crossref) [2024-10-14]},
}

@inproceedings{liuUnderwaterAcousticTarget2021,
	location = {San Diego, {CA}, {USA}},
	title = {Underwater Acoustic Target Recognition Based on Dual Attention Networks and Multiresolution Convolutional Neural Networks},
	rights = {https://doi.org/10.15223/policy-029},
	isbn = {978-0-692-93559-0},
	url = {https://ieeexplore.ieee.org/document/9706009/},
	doi = {10.23919/OCEANS44145.2021.9706009},
	eventtitle = {{OCEANS} 2021: San Diego – Porto},
	pages = {1--5},
	booktitle = {{OCEANS} 2021: San Diego – Porto},
	publisher = {{IEEE}},
	author = {Liu, Chengwei and Hong, Feng and Feng, Haihong and Hu, Menglu},
	urldate = {2024-10-09},
	date = {2021-09-20},
	note = {9 citations (Semantic Scholar/{DOI}) [2024-10-15]
8 citations (Crossref) [2024-10-14]},
}

@inproceedings{liu_few-shot_2021,
	location = {Harbin, China},
	title = {Few-shot Learning with Data Enhancement and Transfer Learning for Underwater Target Recognition},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	isbn = {978-1-72818-190-5},
	url = {https://ieeexplore.ieee.org/document/9519853/},
	doi = {10.1109/COA50123.2021.9519853},
	eventtitle = {2021 {OES} China Ocean Acoustics ({COA})},
	pages = {992--994},
	booktitle = {2021 {OES} China Ocean Acoustics ({COA})},
	publisher = {{IEEE}},
	author = {Liu, Feng and Ding, Hao and Li, Daihui and Wang, Tao and Luo, Zailei and Chen, Liang},
	urldate = {2024-10-09},
	date = {2021-07-14},
	note = {7 citations (Semantic Scholar/{DOI}) [2024-10-15]
3 citations (Crossref) [2024-10-14]},
}

@article{liuUnderwaterTargetRecognition2021,
	title = {Underwater target recognition using convolutional recurrent neural networks with 3-D Mel-spectrogram and data augmentation},
	volume = {178},
	issn = {0003682X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0003682X21000827},
	doi = {10.1016/j.apacoust.2021.107989},
	pages = {107989},
	journaltitle = {Applied Acoustics},
	shortjournal = {Applied Acoustics},
	author = {Liu, Feng and Shen, Tongsheng and Luo, Zailei and Zhao, Dexin and Guo, Shaojun},
	urldate = {2024-08-06},
	date = {2021-07},
	langid = {english},
	note = {88 citations (Semantic Scholar/{DOI}) [2024-10-15]
88 citations (Crossref) [2024-10-14]},
}

@article{luo_underwater_2021,
	title = {An Underwater Acoustic Target Recognition Method Based on Combined Feature With Automatic Coding and Reconstruction},
	volume = {9},
	rights = {https://creativecommons.org/licenses/by/4.0/legalcode},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/9411863/},
	doi = {10.1109/ACCESS.2021.3075344},
	pages = {63841--63854},
	journaltitle = {{IEEE} Access},
	shortjournal = {{IEEE} Access},
	author = {Luo, Xinwei and Feng, Yulin and Zhang, Minghong},
	urldate = {2024-08-13},
	date = {2021},
	note = {24 citations (Semantic Scholar/{DOI}) [2024-10-15]
29 citations (Crossref) [2024-10-14]},
	keywords = {{RBM}},
}

@article{luo_space-frequency_2021,
	title = {A space-frequency joint detection and tracking method for line-spectrum components of underwater acoustic signals},
	volume = {172},
	issn = {0003682X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0003682X20307131},
	doi = {10.1016/j.apacoust.2020.107609},
	pages = {107609},
	journaltitle = {Applied Acoustics},
	shortjournal = {Applied Acoustics},
	author = {Luo, Xinwei and Shen, Zihan},
	urldate = {2024-08-13},
	date = {2021-01},
	langid = {english},
	note = {14 citations (Semantic Scholar/{DOI}) [2024-10-15]
14 citations (Crossref) [2024-10-14]},
}

@article{ma_fast_2021,
	title = {A Fast Instantaneous Frequency Estimation for Underwater Acoustic Target Feature Extraction},
	volume = {2031},
	issn = {1742-6588, 1742-6596},
	url = {https://iopscience.iop.org/article/10.1088/1742-6596/2031/1/012018},
	doi = {10.1088/1742-6596/2031/1/012018},
	abstract = {Abstract
            Traditional auditory features merely present the amplitude characteristics of target signals in frequency domain. Such features are susceptible to environmental noise, resulting in significant degradation of recognition stability. Inspired by instantaneous information applied in speech signal processing field, this paper proposed a feature extraction method using sub-based instantaneous frequency. A fast instantaneous frequency information extraction algorithm is proposed with the normalized Gammatone filterbanks. Experiments confirm that the proposed feature extraction method can effectively maintain the recognition accuracy under low {SNR} conditions while reduce the computation cost.},
	pages = {012018},
	number = {1},
	journaltitle = {Journal of Physics: Conference Series},
	shortjournal = {J. Phys.: Conf. Ser.},
	author = {Ma, Yanxin and Zhang, Yifan and Zhu, Jiahua and Xu, Ke and Cai, Yujin},
	urldate = {2024-10-10},
	date = {2021-09-01},
	note = {2 citations (Semantic Scholar/{DOI}) [2024-10-15]
0 citations (Crossref) [2024-10-14]},
}

@article{miao_underwater_2021,
	title = {Underwater Acoustic Signal Classification Based on Sparse Time–Frequency Representation and Deep Learning},
	volume = {46},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {0364-9059, 1558-1691, 2373-7786},
	url = {https://ieeexplore.ieee.org/document/9319209/},
	doi = {10.1109/JOE.2020.3039037},
	pages = {952--962},
	number = {3},
	journaltitle = {{IEEE} Journal of Oceanic Engineering},
	shortjournal = {{IEEE} J. Oceanic Eng.},
	author = {Miao, Yongchun and Zakharov, Yuriy V. and Sun, Haixin and Li, Jianghui and Wang, Junfeng},
	urldate = {2024-06-20},
	date = {2021-07},
	note = {29 citations (Semantic Scholar/{DOI}) [2024-10-15]
29 citations (Crossref) [2024-10-14]},
	keywords = {Initial reading list},
}

@article{mishachandar_diverse_2021,
	title = {Diverse ocean noise classification using deep learning},
	volume = {181},
	issn = {0003682X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0003682X21002358},
	doi = {10.1016/j.apacoust.2021.108141},
	pages = {108141},
	journaltitle = {Applied Acoustics},
	shortjournal = {Applied Acoustics},
	author = {Mishachandar, B. and Vairamuthu, S.},
	urldate = {2024-10-02},
	date = {2021-10},
	langid = {english},
	note = {36 citations (Semantic Scholar/{DOI}) [2024-10-15]
33 citations (Crossref) [2024-10-14]},
}

@article{satheesh_passive_2021,
	title = {Passive Sonar Target Classification Using Deep Generative \${\textbackslash}beta \$-{VAE}},
	volume = {28},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {1070-9908, 1558-2361},
	url = {https://ieeexplore.ieee.org/document/9397277/},
	doi = {10.1109/LSP.2021.3071255},
	pages = {808--812},
	journaltitle = {{IEEE} Signal Processing Letters},
	shortjournal = {{IEEE} Signal Process. Lett.},
	author = {Satheesh, C. and Kamal, Suraj and Mujeeb, A. and Supriya, M. H.},
	urldate = {2024-10-10},
	date = {2021},
	note = {16 citations (Semantic Scholar/{DOI}) [2024-10-15]
20 citations (Crossref) [2024-10-14]},
}

@article{song_machine_2021,
	title = {A machine learning-based underwater noise classification method},
	volume = {184},
	issn = {0003682X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0003682X21004278},
	doi = {10.1016/j.apacoust.2021.108333},
	pages = {108333},
	journaltitle = {Applied Acoustics},
	shortjournal = {Applied Acoustics},
	author = {Song, Guoli and Guo, Xinyi and Wang, Wenbo and Ren, Qunyan and Li, Jun and Ma, Li},
	urldate = {2024-10-02},
	date = {2021-12},
	langid = {english},
	note = {14 citations (Semantic Scholar/{DOI}) [2024-10-15]
17 citations (Crossref) [2024-10-14]},
}

@inproceedings{sonz_feature_2021,
	location = {Xi'an, China},
	title = {Feature Extraction and Classification of Ship Targets Based on Gammatone Filter Bank},
	rights = {https://doi.org/10.15223/policy-029},
	isbn = {978-1-66542-918-4},
	url = {https://ieeexplore.ieee.org/document/9565001/},
	doi = {10.1109/ICSPCC52875.2021.9565001},
	eventtitle = {2021 {IEEE} International Conference on Signal Processing, Communications and Computing ({ICSPCC})},
	pages = {1--4},
	booktitle = {2021 {IEEE} International Conference on Signal Processing, Communications and Computing ({ICSPCC})},
	publisher = {{IEEE}},
	author = {Sonz, Weixin and Zhang, Xin},
	urldate = {2024-10-10},
	date = {2021-08-17},
	note = {3 citations (Semantic Scholar/{DOI}) [2024-10-15]
1 citations (Crossref) [2024-10-14]},
}

@article{tian_deep_2021,
	title = {Deep convolution stack for waveform in underwater acoustic target recognition},
	volume = {11},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-021-88799-z},
	doi = {10.1038/s41598-021-88799-z},
	abstract = {Abstract
            In underwater acoustic target recognition, deep learning methods have been proved to be effective on recognizing original signal waveform. Previous methods often utilize large convolutional kernels to extract features at the beginning of neural networks. It leads to a lack of depth and structural imbalance of networks. The power of nonlinear transformation brought by deep network has not been fully utilized. Deep convolution stack is a kind of network frame with flexible and balanced structure and it has not been explored well in underwater acoustic target recognition, even though such frame has been proven to be effective in other deep learning fields. In this paper, a multiscale residual unit ({MSRU}) is proposed to construct deep convolution stack network. Based on {MSRU}, a multiscale residual deep neural network ({MSRDN}) is presented to classify underwater acoustic target. Dataset acquired in a real-world scenario is used to verify the proposed unit and model. By adding {MSRU} into Generative Adversarial Networks, the validity of {MSRU} is proved. Finally, {MSRDN} achieves the best recognition accuracy of 83.15\%, improved by 6.99\% from the structure related networks which take the original signal waveform as input and 4.48\% from the networks which take the time-frequency representation as input.},
	pages = {9614},
	number = {1},
	journaltitle = {Scientific Reports},
	shortjournal = {Sci Rep},
	author = {Tian, Shengzhao and Chen, Duanbing and Wang, Hang and Liu, Jingfa},
	urldate = {2024-10-10},
	date = {2021-05-05},
	langid = {english},
	note = {38 citations (Semantic Scholar/{DOI}) [2024-10-15]
35 citations (Crossref) [2024-10-14]},
}

@article{wang_ship_2021,
	title = {Ship Radiated Noise Recognition Technology Based on {ML}‐{DS} Decision Fusion},
	volume = {2021},
	issn = {1687-5265, 1687-5273},
	url = {https://onlinelibrary.wiley.com/doi/10.1155/2021/8901565},
	doi = {10.1155/2021/8901565},
	abstract = {Ship radiated noise is an important information source of underwater acoustic targets, and it is of great significance to the identification and classification of ship targets. However, there are a lot of interference noises in the water, which leads to the reduction of the model recognition rate. Therefore, the recognition results of radiated noise targets are severely affected. This paper proposes a machine learning Dempster–Shafer ({ML}‐{DS}) decision fusion method. The algorithm combines the recognition results of machine learning and deep learning. It uses evidence‐based decision‐making theory to realize feature fusion under different neural network classifiers and improve the accuracy of judgment. First, deep learning algorithms are used to classify two‐dimensional spectrogram features and one‐dimensional amplitude features extracted from {CNN} and {LSTM} networks. The machine learning algorithm {SVM} is used to classify the chromaticity characteristics of radiated noise. Then, according to the classification results of different classifiers, a basic probability assignment model ({BPA}) was designed to fuse the recognition results of the classifiers. Finally, according to the classification characteristics of machine learning and deep learning, combined with the decision‐making of D‐S evidence theory of different times, the decision‐making fusion of radiated noise is realized. The results of the experiment show that the two fusions of deep learning combined with one fusion of machine learning can significantly improve the recognition results of low signal‐to‐noise ratio ({SNR}) datasets. The lowest fusion recognition result can reach 76.01\%, and the average fusion recognition rate can reach 94.92\%. Compared with the traditional single feature recognition algorithm, the recognition accuracy is greatly improved. Compared with the traditional one‐step fusion algorithm, it can effectively integrate the recognition results of heterogeneous data and heterogeneous networks. The identification method based on {ML}‐{DS} proposed in this paper can be applied in the field of ship radiated noise identification.},
	pages = {8901565},
	number = {1},
	journaltitle = {Computational Intelligence and Neuroscience},
	shortjournal = {Computational Intelligence and Neuroscience},
	author = {Wang, Biao and Wu, Chengxi and Zhu, Yunan and Zhang, Mingliang and Li, Hanqiong and Zhang, Wei},
	editor = {G, Thippa Reddy},
	urldate = {2024-10-10},
	date = {2021-01},
	langid = {english},
	note = {8 citations (Semantic Scholar/{DOI}) [2024-10-15]
4 citations (Crossref) [2024-10-14]},
}

@article{xie_optimized_2021,
	title = {Optimized Variational Mode Decomposition and Permutation Entropy with Their Application in Feature Extraction of Ship-Radiated Noise},
	volume = {23},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1099-4300},
	url = {https://www.mdpi.com/1099-4300/23/5/503},
	doi = {10.3390/e23050503},
	abstract = {The complex and changeable marine environment surrounded by a variety of noise, including sounds of marine animals, industrial noise, traffic noise and the noise formed by molecular movement, not only interferes with the normal life of residents near the port, but also exerts a significant influence on feature extraction of ship-radiated noise (S-{RN}). In this paper, a novel feature extraction technique for S-{RN} signals based on optimized variational mode decomposition ({OVMD}), permutation entropy ({PE}), and normalized Spearman correlation coefficient ({NSCC}) is proposed. Firstly, with the mode number determined by reverse weighted permutation entropy ({RWPE}), {OVMD} decomposes the target signal into a set of intrinsic mode functions ({IMFs}). The {PE} of all the {IMFs} and {SCC} between each {IMF} with the raw signal are then calculated, respectively. Subsequently, feature parameters are extracted through the sum of {PE} weighted by {NSCC} for the {IMFs}. Lastly, the obtained feature vectors are input into the support vector machine multi-class classifier ({SVM}) to discriminate various types of ships. Experimental results indicate that five kinds of S-{RN} samples can be accurately identified with a recognition rate of 94\% by the proposed scheme, which is higher than other previously published methods. Hence, the proposed method is more advantageous in practical applications.},
	pages = {503},
	number = {5},
	journaltitle = {Entropy},
	shortjournal = {Entropy},
	author = {Xie, Dongri and Hong, Shaohua and Yao, Chaojun},
	urldate = {2024-10-10},
	date = {2021-04-22},
	langid = {english},
	note = {25 citations (Semantic Scholar/{DOI}) [2024-10-15]
24 citations (Crossref) [2024-10-14]},
}

@inproceedings{xu_research_2021,
	location = {Shenyang, China},
	title = {Research on Feature Extraction Method of Underwater Acoustic Passive Target},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	isbn = {978-1-66542-839-2},
	url = {https://ieeexplore.ieee.org/document/9668817/},
	doi = {10.1109/AUTEEE52864.2021.9668817},
	eventtitle = {2021 {IEEE} 4th International Conference on Automation, Electronics and Electrical Engineering ({AUTEEE})},
	pages = {668--671},
	booktitle = {2021 {IEEE} 4th International Conference on Automation, Electronics and Electrical Engineering ({AUTEEE})},
	publisher = {{IEEE}},
	author = {Xu, Feng and Guo, Yinjing},
	urldate = {2024-10-10},
	date = {2021-11-19},
	note = {1 citations (Semantic Scholar/{DOI}) [2024-10-15]
0 citations (Crossref) [2024-10-14]},
}

@article{yang_transfer_2021,
	title = {Transfer learning for denoising the echolocation clicks of finless porpoise ( \textit{Neophocaena phocaenoides sunameri} ) using deep convolutional autoencoders},
	volume = {150},
	issn = {0001-4966, 1520-8524},
	url = {https://pubs.aip.org/jasa/article/150/2/1243/615497/Transfer-learning-for-denoising-the-echolocation},
	doi = {10.1121/10.0005887},
	abstract = {Ocean noise has a negative impact on the acoustic recordings of odontocetes' echolocation clicks. In this study, deep convolutional autoencoders ({DCAEs}) are presented to denoise the echolocation clicks of the finless porpoise (Neophocaena phocaenoides sunameri). A {DCAE} consists of an encoder network and a decoder network. The encoder network is composed of convolutional layers and fully connected layers, whereas the decoder network consists of fully connected layers and transposed convolutional layers. The training scheme of the denoising autoencoder was applied to learn the {DCAE} parameters. In addition, transfer learning was employed to address the difficulty in collecting a large number of echolocation clicks that are free of ambient sea noise. Gabor functions were used to generate simulated clicks to pretrain the {DCAEs}; subsequently, the parameters of the {DCAEs} were fine-tuned using the echolocation clicks of the finless porpoise. The experimental results showed that a {DCAE} pretrained with simulated clicks achieved better denoising results than a {DCAE} trained only with echolocation clicks. Moreover, deep fully convolutional autoencoders, which are special {DCAEs} that do not contain fully connected layers, generally achieved better performance than the {DCAEs} that contain fully connected layers.},
	pages = {1243--1250},
	number = {2},
	journaltitle = {The Journal of the Acoustical Society of America},
	author = {Yang, Wuyi and Chang, Wenlei and Song, Zhongchang and Zhang, Yu and Wang, Xianyan},
	urldate = {2024-09-23},
	date = {2021-08-01},
	langid = {english},
	note = {6 citations (Semantic Scholar/{DOI}) [2024-10-15]
6 citations (Crossref) [2024-10-14]},
	keywords = {Denoising},
}

@article{zhang_integrated_2021,
	title = {Integrated neural networks based on feature fusion for underwater target recognition},
	volume = {182},
	issn = {0003682X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0003682X21003558},
	doi = {10.1016/j.apacoust.2021.108261},
	pages = {108261},
	journaltitle = {Applied Acoustics},
	shortjournal = {Applied Acoustics},
	author = {Zhang, Qi and Da, Lianglong and Zhang, Yanhou and Hu, Yaohui},
	urldate = {2024-10-10},
	date = {2021-11},
	langid = {english},
	note = {42 citations (Semantic Scholar/{DOI}) [2024-10-15]
43 citations (Crossref) [2024-10-14]},
}

@inproceedings{ashok_improving_2022,
	title = {An Improving Recognition Accuracy of Underwater Acoustic Targets based on Gated Recurrent Unit({GRU}) Neural network Method},
	url = {https://ieeexplore.ieee.org/abstract/document/10040289},
	doi = {10.1109/ICCST55948.2022.10040289},
	abstract = {Underwater acoustic target classification methods remain a major problem due to the continuous changeable event in an oceanic environment. Even with a reliable phoneme, it is difficult to increase the recognition accuracy rate. This work represents a new method to increase the recognition accuracy rate of underwater acoustic signals by the {ANN} method, which integrates {ID}-{CNN} and {GRU}. The input to this network framework is constructed using ship acoustic data and then evaluated the performance. Visual analysis shows this method produces a better recognition rate and classification of acoustic targets. This method gives a considerably high recognition accuracy rate of 97.73\% compared with traditional single neural network methods and it leads to a strong path for deep learning applications in the area of underwater acoustic signal recognition.},
	eventtitle = {2022 1st International Conference on Computational Science and Technology ({ICCST})},
	pages = {1--6},
	booktitle = {2022 1st International Conference on Computational Science and Technology ({ICCST})},
	author = {Ashok, P. and Latha, B.},
	urldate = {2024-10-09},
	date = {2022-11},
	note = {2 citations (Semantic Scholar/{DOI}) [2024-10-15]
1 citations (Crossref) [2024-10-14]},
}

@inproceedings{bach_improving_2022,
	title = {Improving the classification of propeller ships using {LOFAR} and triple loss variational auto encoder},
	url = {https://ieeexplore.ieee.org/document/9873436/?arnumber=9873436},
	doi = {10.1109/ICECET55527.2022.9873436},
	abstract = {This paper presents an underwater signal processing model for the purpose of detecting and classifying propeller ship by the Low Frequency Analysis and Recording ({LOFAR}) algorithm combined with the Triple loss Variational Auto-Encoder network ({TL}- {VAE}). The results of the model have been tested on real data sets of Deepship, and showed better classification accuracy than Convolutional Neural Network ({CNN}) {VGG}-19. By replacing {FFT} with {STFT} before normalizing by {TPSW} (Two pass split window) and using the spatial domain probability distribution, the proposed model {LOFAR}-{TL}-{VAE} improved the classification accuracy by 10\% even with low signal to noise ratio actual signals.},
	eventtitle = {2022 International Conference on Electrical, Computer and Energy Technologies ({ICECET})},
	pages = {1--5},
	booktitle = {2022 International Conference on Electrical, Computer and Energy Technologies ({ICECET})},
	author = {Bach, Nhat Hoang and Nguyen, Van Duc and Vu, Le Ha},
	urldate = {2024-10-09},
	date = {2022-07},
	note = {4 citations (Semantic Scholar/{DOI}) [2024-10-15]
3 citations (Crossref) [2024-10-14]},
}

@article{barros_development_2022,
	title = {Development of a ship classification method based on Convolutional neural network and Cyclostationarity Analysis},
	volume = {170},
	issn = {08883270},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0888327021010918},
	doi = {10.1016/j.ymssp.2021.108778},
	pages = {108778},
	journaltitle = {Mechanical Systems and Signal Processing},
	shortjournal = {Mechanical Systems and Signal Processing},
	author = {Barros, Rodrigo Emanoel De B.A. and Ebecken, Nelson F.F.},
	urldate = {2024-10-09},
	date = {2022-05},
	langid = {english},
	note = {12 citations (Semantic Scholar/{DOI}) [2024-10-15]
9 citations (Crossref) [2024-10-14]},
}

@article{beckler_multilabel_2022,
	title = {Multilabel Classification of Heterogeneous Underwater Soundscapes With Bayesian Deep Learning},
	volume = {47},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{USG}.html},
	issn = {0364-9059, 1558-1691, 2373-7786},
	url = {https://ieeexplore.ieee.org/document/9832855/},
	doi = {10.1109/JOE.2022.3177850},
	pages = {1143--1154},
	number = {4},
	journaltitle = {{IEEE} Journal of Oceanic Engineering},
	shortjournal = {{IEEE} J. Oceanic Eng.},
	author = {Beckler, Brandon and Pfau, Andrew and Orescanin, Marko and Atchley, Sabrina and Villemez, Nicholas and Joseph, John E. and Miller, Christopher W. and Margolina, Tetyana},
	urldate = {2024-06-20},
	date = {2022-10},
	note = {7 citations (Semantic Scholar/{DOI}) [2024-10-15]
4 citations (Crossref) [2024-10-14]},
	keywords = {Initial reading list},
}

@article{cao_distinguishing_2022,
	title = {Distinguishing multiple surface ships using one acoustic vector sensor based on a convolutional neural network},
	volume = {2},
	issn = {2691-1191},
	url = {https://pubs.aip.org/jel/article/2/5/054803/2843410/Distinguishing-multiple-surface-ships-using-one},
	doi = {10.1121/10.0010492},
	abstract = {A direction of arrival ({DOA}) estimation method based on a convolutional neural network ({CNN}) using an acoustic vector sensor is proposed to distinguish multiple surface ships in a selected frequency band. The cross-spectrum of the pressure and particle velocity are provided as inputs to the {CNN}, which is trained using data obtained by employing an acoustic propagation model under different environmental and source parameters. By learning the characteristics of acoustic propagation, the multisource distinguishing performance of the {CNN} is improved. The proposed method is experimentally validated using real data.},
	pages = {054803},
	number = {5},
	journaltitle = {{JASA} Express Letters},
	author = {Cao, Huaigang and Ren, Qunyan},
	urldate = {2024-10-09},
	date = {2022-05-01},
	langid = {english},
	note = {3 citations (Semantic Scholar/{DOI}) [2024-10-15]
2 citations (Crossref) [2024-10-14]},
}

@article{chen_timefrequency_2022,
	title = {Time–Frequency Mask-Aware Bidirectional {LSTM}: A Deep Learning Approach for Underwater Acoustic Signal Separation},
	volume = {22},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/22/15/5598},
	doi = {10.3390/s22155598},
	shorttitle = {Time–Frequency Mask-Aware Bidirectional {LSTM}},
	abstract = {Underwater acoustic signal separation is a key technique for underwater communications. The existing methods are mostly model-based, and cannot accurately characterize the practical underwater acoustic communication environment. They are only suitable for binary signal separation and cannot handle multivariate signal separation. However, recurrent neural networks ({RNNs}) show a powerful ability to extract the features of temporal sequences. Inspired by this, in this paper, we present a data-driven approach for underwater acoustic signal separation using deep learning technology. We use a bidirectional long short-term memory (Bi-{LSTM}) approach to explore the features of a time–frequency (T-F) mask, and propose a T-F-mask-aware Bi-{LSTM} for signal separation. Taking advantage of the sparseness of the T-F image, the designed Bi-{LSTM} network is able to extract the discriminative features for separation, which further improves the separation performance. In particular, this method breaks through the limitations of the existing methods and not only achieves good results in multivariate separation but also effectively separates signals when they are mixed with 40 {dB} Gaussian noise signals. The experimental results show that this method can achieve a 97\% guarantee ratio ({PSR}), and the average similarity coefficient of the multivariate signal separation is stable above 0.8 under high noise conditions. It should be noted that our model can only handle known signals such as test signals for calibration.},
	pages = {5598},
	number = {15},
	journaltitle = {Sensors},
	shortjournal = {Sensors},
	author = {Chen, Jie and Liu, Chang and Xie, Jiawu and An, Jie and Huang, Nan},
	urldate = {2024-10-09},
	date = {2022-07-26},
	langid = {english},
	note = {7 citations (Semantic Scholar/{DOI}) [2024-10-15]
9 citations (Crossref) [2024-10-14]},
}

@inproceedings{chen_underwater_2022,
	location = {Chengdu, China},
	title = {Underwater Acoustic Target Classification with Joint Learning Framework and Data Augmentation},
	rights = {https://doi.org/10.15223/policy-029},
	isbn = {978-1-66549-913-2},
	url = {https://ieeexplore.ieee.org/document/9820117/},
	doi = {10.1109/ICAIBD55127.2022.9820117},
	eventtitle = {2022 5th International Conference on Artificial Intelligence and Big Data ({ICAIBD})},
	pages = {23--28},
	booktitle = {2022 5th International Conference on Artificial Intelligence and Big Data ({ICAIBD})},
	publisher = {{IEEE}},
	author = {Chen, Liang and Liu, Feng and Li, Daihui and Shen, Tongsheng and Zhao, Dexin},
	urldate = {2024-10-09},
	date = {2022-05-27},
	note = {6 citations (Semantic Scholar/{DOI}) [2024-10-15]
3 citations (Crossref) [2024-10-14]},
}

@inproceedings{de_souza_passive_2022,
	location = {Montevideo, Uruguay},
	title = {Passive Sonar Classification Using Time-Domain Information and Recurrent Neural Networks},
	rights = {https://doi.org/10.15223/policy-029},
	isbn = {978-1-66548-858-7},
	url = {https://ieeexplore.ieee.org/document/9981792/},
	doi = {10.1109/LA-CCI54402.2022.9981792},
	eventtitle = {2022 {IEEE} Latin American Conference on Computational Intelligence ({LA}-{CCI})},
	pages = {1--6},
	booktitle = {2022 {IEEE} Latin American Conference on Computational Intelligence ({LA}-{CCI})},
	publisher = {{IEEE}},
	author = {De Souza, Marlon Jovenil and De Moura Junior, Natanael Nunes and De Seixas, Jose Manoel},
	urldate = {2024-10-09},
	date = {2022-11-23},
	note = {2 citations (Semantic Scholar/{DOI}) [2024-10-15]
1 citations (Crossref) [2024-10-14]},
}

@article{doan_underwater_2022,
	title = {Underwater Acoustic Target Classification Based on Dense Convolutional Neural Network},
	volume = {19},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {1545-598X, 1558-0571},
	url = {https://ieeexplore.ieee.org/document/9229102/},
	doi = {10.1109/LGRS.2020.3029584},
	pages = {1--5},
	journaltitle = {{IEEE} Geoscience and Remote Sensing Letters},
	shortjournal = {{IEEE} Geosci. Remote Sensing Lett.},
	author = {Doan, Van-Sang and Huynh-The, Thien and Kim, Dong-Seong},
	urldate = {2024-06-24},
	date = {2022},
	note = {74 citations (Semantic Scholar/{DOI}) [2024-10-15]
73 citations (Crossref) [2024-10-14]},
	keywords = {Private dataset},
}

@article{domingos_survey_2022,
	title = {A Survey of Underwater Acoustic Data Classification Methods Using Deep Learning for Shoreline Surveillance},
	volume = {22},
	doi = {10.3390/s22062181},
	abstract = {This paper presents a comprehensive overview of current deep-learning methods for automatic object classification of underwater sonar data for shoreline surveillance, concentrating mostly on the classification of vessels from passive sonar data and the identification of objects of interest from active sonar (such as minelike objects, human figures or debris of wrecked ships). Not only is the contribution of this work to provide a systematic description of the state of the art of this field, but also to identify five main ingredients in its current development: the application of deep-learning methods using convolutional layers alone; deep-learning methods that apply biologically inspired feature-extraction filters as a preprocessing step; classification of data from frequency and time–frequency analysis; methods using machine learning to extract features from original signals; and transfer learning methods. This paper also describes some of the most important datasets cited in the literature and discusses data-augmentation techniques. The latter are used for coping with the scarcity of annotated sonar datasets from real maritime missions.},
	pages = {2181--2181},
	number = {6},
	journaltitle = {Sensors},
	author = {Domingos, Lucas C. F. and Santos, Paulo E. and Santos, Paulo E. and Skelton, Phillip S.M. and {Phillip S. M. Skelton} and Brinkworth, Russell S. A. and {Russell S. A. Brinkworth} and Sammut, Karl and {Karl Sammut}},
	date = {2022-03-11},
	doi = {10.3390/s22062181},
	note = {28 citations (Semantic Scholar/{DOI}) [2024-10-15]
25 citations (Crossref) [2024-10-14]
{MAG} {ID}: 4220669915},
	keywords = {Review},
}

@article{domingos_investigation_2022,
	title = {An Investigation of Preprocessing Filters and Deep Learning Methods for Vessel Type Classification With Underwater Acoustic Data},
	volume = {10},
	rights = {https://creativecommons.org/licenses/by/4.0/legalcode},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/9940921/},
	doi = {10.1109/ACCESS.2022.3220265},
	pages = {117582--117596},
	journaltitle = {{IEEE} Access},
	shortjournal = {{IEEE} Access},
	author = {Domingos, Lucas C. F. and Santos, Paulo E. and Skelton, Phillip S. M. and Brinkworth, Russell S. A. and Sammut, Karl},
	urldate = {2024-10-09},
	date = {2022},
	note = {10 citations (Semantic Scholar/{DOI}) [2024-10-15]
12 citations (Crossref) [2024-10-14]},
}

@article{dong_bidirectional_2022,
	title = {Bidirectional Denoising Autoencoders-Based Robust Representation Learning for Underwater Acoustic Target Signal Denoising},
	volume = {71},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {0018-9456, 1557-9662},
	url = {https://ieeexplore.ieee.org/document/9906298/},
	doi = {10.1109/TIM.2022.3210979},
	pages = {1--8},
	journaltitle = {{IEEE} Transactions on Instrumentation and Measurement},
	shortjournal = {{IEEE} Trans. Instrum. Meas.},
	author = {Dong, Yafen and Shen, Xiaohong and Wang, Haiyan},
	urldate = {2024-09-23},
	date = {2022},
	note = {9 citations (Semantic Scholar/{DOI}) [2024-10-15]
4 citations (Crossref) [2024-10-14]},
	keywords = {Denoising},
}

@article{feng_transformer-based_2022,
	title = {A Transformer-Based Deep Learning Network for Underwater Acoustic Target Recognition},
	volume = {19},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {1545-598X, 1558-0571},
	url = {https://ieeexplore.ieee.org/document/9866066/},
	doi = {10.1109/LGRS.2022.3201396},
	pages = {1--5},
	journaltitle = {{IEEE} Geoscience and Remote Sensing Letters},
	shortjournal = {{IEEE} Geosci. Remote Sensing Lett.},
	author = {Feng, Sheng and Zhu, Xiaoqian},
	urldate = {2024-10-09},
	date = {2022},
	note = {36 citations (Semantic Scholar/{DOI}) [2024-10-15]
24 citations (Crossref) [2024-10-14]},
}

@article{han_underwater_2022,
	title = {Underwater acoustic target recognition method based on a joint neural network},
	volume = {17},
	issn = {1932-6203},
	url = {https://dx.plos.org/10.1371/journal.pone.0266425},
	doi = {10.1371/journal.pone.0266425},
	abstract = {To improve the recognition accuracy of underwater acoustic targets by artificial neural network, this study presents a new recognition method that integrates a one-dimensional convolutional neural network and a long short-term memory network. This new network framework is constructed and applied to underwater acoustic target recognition for the first time. Ship acoustic data are used as input to evaluate the network performance. A visual analysis of the recognition results is performed. The results show that this method can realize the recognition and classification of underwater acoustic targets. Compared with a single neural network, the relevant indices, such as the recognition accuracy of the joint network are considerably higher. This provides a new direction for the application of deep learning in the field of underwater acoustic target recognition.},
	pages = {e0266425},
	number = {4},
	journaltitle = {{PLOS} {ONE}},
	shortjournal = {{PLoS} {ONE}},
	author = {Han, Xing Cheng and Ren, Chenxi and Wang, Liming and Bai, Yunjiao},
	editor = {Ntalampiras, Stavros},
	urldate = {2024-10-09},
	date = {2022-04-29},
	langid = {english},
	note = {15 citations (Semantic Scholar/{DOI}) [2024-10-15]
13 citations (Crossref) [2024-10-14]},
}

@article{honghui_underwater_2022,
	title = {Underwater acoustic target multi-attribute correlation perception method based on deep learning},
	volume = {190},
	issn = {0003682X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0003682X22000184},
	doi = {10.1016/j.apacoust.2022.108644},
	pages = {108644},
	journaltitle = {Applied Acoustics},
	shortjournal = {Applied Acoustics},
	author = {Honghui, Yang and Junhao, Li and Meiping, Sheng},
	urldate = {2024-10-09},
	date = {2022-03},
	langid = {english},
	note = {24 citations (Semantic Scholar/{DOI}) [2024-10-15]
24 citations (Crossref) [2024-10-14]},
}

@article{jiang_classification_2022,
	title = {Classification of Underwater Target Based on S-{ResNet} and Modified {DCGAN} Models},
	volume = {22},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/22/6/2293},
	doi = {10.3390/s22062293},
	abstract = {Underwater target classification has been an important topic driven by its general applications. Convolutional neural network ({CNN}) has been shown to exhibit excellent performance on classifications especially in the field of image processing. However, when applying {CNN} and related deep learning models to underwater target classifications, the problems, including small sample size of underwater target and low complexity requirement, impose a great challenge. In this paper, we have proposed the modified {DCGAN} model to augment data for targets with small sample size. The data generated from the proposed model help to improve classification performance under imbalanced category conditions. Furthermore, we have proposed the S-{ResNet} model to obtain good classification accuracy while significantly reducing complexity of the model, and achieve a good tradeoff between classification accuracy and model complexity. The effectiveness of proposed models is verified through measured data from sea trial and lake tests.},
	pages = {2293},
	number = {6},
	journaltitle = {Sensors},
	shortjournal = {Sensors},
	author = {Jiang, Zhe and Zhao, Chen and Wang, Haiyan},
	urldate = {2024-10-09},
	date = {2022-03-16},
	langid = {english},
	note = {11 citations (Semantic Scholar/{DOI}) [2024-10-15]
15 citations (Crossref) [2024-10-14]},
}

@article{jospin_hands-bayesian_2022,
	title = {Hands-on Bayesian Neural Networks -- a Tutorial for Deep Learning Users},
	volume = {17},
	issn = {1556-603X, 1556-6048},
	url = {http://arxiv.org/abs/2007.06823},
	doi = {10.1109/MCI.2022.3155327},
	abstract = {Modern deep learning methods constitute incredibly powerful tools to tackle a myriad of challenging problems. However, since deep learning methods operate as black boxes, the uncertainty associated with their predictions is often challenging to quantify. Bayesian statistics offer a formalism to understand and quantify the uncertainty associated with deep neural network predictions. This tutorial provides an overview of the relevant literature and a complete toolset to design, implement, train, use and evaluate Bayesian Neural Networks, i.e. Stochastic Artificial Neural Networks trained using Bayesian methods.},
	pages = {29--48},
	number = {2},
	journaltitle = {{IEEE} Computational Intelligence Magazine},
	shortjournal = {{IEEE} Comput. Intell. Mag.},
	author = {Jospin, Laurent Valentin and Buntine, Wray and Boussaid, Farid and Laga, Hamid and Bennamoun, Mohammed},
	urldate = {2024-06-20},
	date = {2022-05},
	eprinttype = {arxiv},
	eprint = {2007.06823 [cs, stat]},
	note = {506 citations (Semantic Scholar/{arXiv}) [2024-10-15]
506 citations (Semantic Scholar/{DOI}) [2024-10-15]
282 citations (Crossref) [2024-10-14]},
	keywords = {Initial reading list},
}

@article{ju_deeplearningbased_2022,
	title = {Deep‐learning‐based line enhancer for passive sonar systems},
	volume = {16},
	rights = {http://creativecommons.org/licenses/by-nc-nd/4.0/},
	issn = {1751-8784, 1751-8792},
	url = {https://onlinelibrary.wiley.com/doi/10.1049/rsn2.12205},
	doi = {10.1049/rsn2.12205},
	pages = {589--601},
	number = {3},
	journaltitle = {{IET} Radar, Sonar \& Navigation},
	shortjournal = {{IET} Radar Sonar \& Navi},
	author = {Ju, Donghao and Chi, Cheng and Li, Zigao and Li, Yu and Zhang, Chunhua and Huang, Haining},
	urldate = {2024-10-09},
	date = {2022-03},
	langid = {english},
	note = {6 citations (Semantic Scholar/{DOI}) [2024-10-15]
6 citations (Crossref) [2024-10-14]},
}

@inproceedings{kuzin_automated_2022,
	location = {Vladivostok, Russian Federation},
	title = {Automated sea vehicle classification system based on neural network},
	rights = {https://doi.org/10.15223/policy-029},
	isbn = {978-1-66547-372-9},
	url = {https://ieeexplore.ieee.org/document/10033384/},
	doi = {10.1109/ICOS55803.2022.10033384},
	eventtitle = {2022 International Conference on Ocean Studies ({ICOS})},
	pages = {87--90},
	booktitle = {2022 International Conference on Ocean Studies ({ICOS})},
	publisher = {{IEEE}},
	author = {Kuzin, Denis and Statsenko, Lyubov and Smirnova, Maria},
	urldate = {2024-10-09},
	date = {2022-10-05},
	note = {1 citations (Semantic Scholar/{DOI}) [2024-10-15]
0 citations (Crossref) [2024-10-14]},
}

@article{li_generalizable_2022,
	title = {Generalizable Underwater Acoustic Target Recognition Using Feature Extraction Module of Neural Network},
	volume = {12},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2076-3417},
	url = {https://www.mdpi.com/2076-3417/12/21/10804},
	doi = {10.3390/app122110804},
	abstract = {The underwater acoustic target signal is affected by factors such as the underwater environment and the ship’s working conditions, causing the generalization of the recognition model is essential. This study is devoted to improving the generalization of recognition models, proposing a feature extraction module based on neural network and time-frequency analysis, and validating the feasibility of the model-based transfer learning method. A network-based filter based on one-dimensional convolution is built according to the calculation mode of the finite impulse response filter. An attention-based model is constructed using the convolution network components and full-connection components. The attention-based network utilizes convolution components to perform the Fourier transform and feeds back the optimization gradient of a specific task to the network-based filter. The network-based filter is designed to filter the observed signal for adaptive perception, and the attention-based model is constructed to extract the time-frequency features of the signal. In addition, model-based transfer learning is utilized to further improve the model’s performance. Experiments show that the model can perceive the frequency domain features of underwater acoustic targets, and the proposed method demonstrates competitive performance in various classification tasks on real data, especially those requiring high generalizability.},
	pages = {10804},
	number = {21},
	journaltitle = {Applied Sciences},
	shortjournal = {Applied Sciences},
	author = {Li, Daihui and Liu, Feng and Shen, Tongsheng and Chen, Liang and Yang, Xiaodan and Zhao, Dexin},
	urldate = {2024-10-09},
	date = {2022-10-25},
	langid = {english},
	note = {5 citations (Semantic Scholar/{DOI}) [2024-10-15]
5 citations (Crossref) [2024-10-14]},
}

@article{li_novel_2022,
	title = {A novel method for frequency feature extraction of ship radiated noise based on variational mode decomposition, double coupled Duffing chaotic oscillator and multivariate multiscale dispersion entropy},
	volume = {61},
	issn = {11100168},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1110016821007924},
	doi = {10.1016/j.aej.2021.11.059},
	pages = {6329--6347},
	number = {8},
	journaltitle = {Alexandria Engineering Journal},
	shortjournal = {Alexandria Engineering Journal},
	author = {Li, Guohui and Hou, Yongming and Yang, Hong},
	urldate = {2024-10-09},
	date = {2022-08},
	langid = {english},
	note = {23 citations (Semantic Scholar/{DOI}) [2024-10-15]
23 citations (Crossref) [2024-10-14]},
}

@article{li_research_2022,
	title = {Research on feature extraction method of ship radiated noise with K-nearest neighbor mutual information variational mode decomposition, neural network estimation time entropy and self-organizing map neural network},
	volume = {199},
	issn = {02632241},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0263224122006741},
	doi = {10.1016/j.measurement.2022.111446},
	pages = {111446},
	journaltitle = {Measurement},
	shortjournal = {Measurement},
	author = {Li, Guohui and Liu, Feng and Yang, Hong},
	urldate = {2024-10-09},
	date = {2022-08},
	langid = {english},
	note = {24 citations (Semantic Scholar/{DOI}) [2024-10-15]
19 citations (Crossref) [2024-10-14]},
}

@article{li_underwater_2022,
	title = {Underwater Acoustic Target Recognition Based on Attention Residual Network},
	volume = {24},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1099-4300},
	url = {https://www.mdpi.com/1099-4300/24/11/1657},
	doi = {10.3390/e24111657},
	abstract = {Underwater acoustic target recognition is very complex due to the lack of labeled data sets, the complexity of the marine environment, and the interference of background noise. In order to enhance it, we propose an attention-based residual network recognition method ({AResnet}). The method can be used to identify ship-radiated noise in different environments. Firstly, a residual network is used to extract the deep abstract features of three-dimensional fusion features, and then a channel attention module is used to enhance different channels. Finally, the features are classified by the joint supervision of cross-entropy and central loss functions. At the same time, for the recognition of ship-radiated noise in other environments, we use the pre-training network {AResnet} to extract the deep acoustic features and apply the network structure to underwater acoustic target recognition after fine-tuning. The two sets of ship radiation noise datasets are verified, the {DeepShip} dataset is trained and verified, and the average recognition accuracy is 99\%. Then, the trained {AResnet} structure is fine-tuned and applied to the {ShipsEar} dataset. The average recognition accuracy is 98\%, which is better than the comparison method.},
	pages = {1657},
	number = {11},
	journaltitle = {Entropy},
	shortjournal = {Entropy},
	author = {Li, Juan and Wang, Baoxiang and Cui, Xuerong and Li, Shibao and Liu, Jianhang},
	urldate = {2024-08-06},
	date = {2022-11-15},
	langid = {english},
	note = {13 citations (Semantic Scholar/{DOI}) [2024-10-15]
11 citations (Crossref) [2024-10-14]},
	keywords = {{DeepShip}, {ShipsEar}},
}

@article{li_stm_2022,
	title = {{STM}: Spectrogram Transformer Model for Underwater Acoustic Target Recognition},
	volume = {10},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2077-1312},
	url = {https://www.mdpi.com/2077-1312/10/10/1428},
	doi = {10.3390/jmse10101428},
	shorttitle = {{STM}},
	abstract = {With the evolution of machine learning and deep learning, more and more researchers have utilized these methods in the field of underwater acoustic target recognition. In these studies, convolutional neural networks ({CNNs}) are the main components of recognition models. In recent years, a neural network model Transformer that uses a self-attention mechanism was proposed and achieved good performance in deep learning. In this paper, we propose a Transformer-based underwater acoustic target recognition model {STM}. To the best of our knowledge, this is the first work to introduce Transformer into the underwater acoustic field. We compared the performance of {STM} with {CNN}, {ResNet}18, and other multi-class algorithm models. Experimental results illustrate that under two commonly used dataset partitioning methods, {STM} achieves 97.7\% and 89.9\% recognition accuracy, respectively, which are 13.7\% and 50\% higher than the {CNN} Model. {STM} also outperforms the state-of-the-art model {CRNN}-9 by 3.1\% and {ResNet}18 by 1.8\%.},
	pages = {1428},
	number = {10},
	journaltitle = {Journal of Marine Science and Engineering},
	shortjournal = {{JMSE}},
	author = {Li, Peng and Wu, Ji and Wang, Yongxian and Lan, Qiang and Xiao, Wenbin},
	urldate = {2024-10-09},
	date = {2022-10-04},
	langid = {english},
	note = {21 citations (Semantic Scholar/{DOI}) [2024-10-15]
20 citations (Crossref) [2024-10-14]},
}

@article{li_optimized_2022,
	title = {Optimized Ship-Radiated Noise Feature Extraction Approaches Based on {CEEMDAN} and Slope Entropy},
	volume = {24},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1099-4300},
	url = {https://www.mdpi.com/1099-4300/24/9/1265},
	doi = {10.3390/e24091265},
	abstract = {Slope entropy (Slopen) has been demonstrated to be an excellent approach to extracting ship-radiated noise signals (S-{NSs}) features by analyzing the complexity of the signals; however, its recognition ability is limited because it extracts the features of undecomposed S-{NSs}. To solve this problem, in this study, we combined complete ensemble empirical mode decomposition with adaptive noise ({CEEMDAN}) to explore the differences of Slopen between the intrinsic mode components ({IMFs}) of the S-{NSs} and proposed a single-{IMF} optimized feature extraction approach. Aiming to further enhance its performance, the optimized combination of dual-{IMFs} was selected, and a dual-{IMF} optimized feature extraction approach was also proposed. We conducted three experiments to demonstrate the effectiveness of {CEEMDAN}, Slopen, and the proposed approaches. The experimental and comparative results revealed both of the proposed single- and dual-{IMF} optimized feature extraction approaches based on Slopen and {CEEMDAN} to be more effective than the original ship signal-based and {IMF}-based feature extraction approaches.},
	pages = {1265},
	number = {9},
	journaltitle = {Entropy},
	shortjournal = {Entropy},
	author = {Li, Yuxing and Tang, Bingzhao and Jiao, Shangbin},
	urldate = {2024-10-09},
	date = {2022-09-08},
	langid = {english},
	note = {24 citations (Semantic Scholar/{DOI}) [2024-10-15]
30 citations (Crossref) [2024-10-14]},
}

@article{li_novel_2022-1,
	title = {A novel complexity-based mode feature representation for feature extraction of ship-radiated noise using {VMD} and slope entropy},
	volume = {196},
	issn = {0003682X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0003682X22002730},
	doi = {10.1016/j.apacoust.2022.108899},
	pages = {108899},
	journaltitle = {Applied Acoustics},
	shortjournal = {Applied Acoustics},
	author = {Li, Yuxing and Tang, Bingzhao and Yi, Yingmin},
	urldate = {2024-10-09},
	date = {2022-07},
	langid = {english},
	note = {80 citations (Semantic Scholar/{DOI}) [2024-10-15]
74 citations (Crossref) [2024-10-14]},
}

@article{li_denoising_2022,
	title = {A Denoising Method for Ship-Radiated Noise Based on Optimized Variational Mode Decomposition with Snake Optimization and Dual-Threshold Criteria of Correlation Coefficient},
	volume = {2022},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1563-5147, 1024-123X},
	url = {https://www.hindawi.com/journals/mpe/2022/8024753/},
	doi = {10.1155/2022/8024753},
	abstract = {The ship-radiated noise ({SN}) is easily affected by other hydroacoustic objects or complex ocean noise when it spreads through water. In order to reduce the impact from the environment, a denoising method for {SN} based on optimized variational mode decomposition with snake optimization ({SO}-{VMD}) and dual-threshold criteria of correlation coefficient ({CC}) is proposed in this paper. The first step is to optimize the parameter combination, that is, decomposition number K and penalty factor α, of variational mode decomposition ({VMD}) by snake optimization ({SO}) with envelope entropy ({EE}). Then, the input signal using the optimized results is decomposed and the intrinsic mode functions ({IMFs}) are obtained. After that, the {IMFs} are classified into three classes with the dual-threshold criteria of {CC}, including signal components, signal-noise components, and noise components. Finally, all the signal components and the processed signal-noise components denoised by wavelet threshold ({WT}) are reconstructed together. Simulations performed in this paper demonstrate that {SO} is the more appropriate optimization for {VMD} and the proposed method has the more outstanding performance in denoising different kinds of test signals. In addition, experiments on measured {SNs} show that the proposed method is effective and accurate in denoising.},
	pages = {1--21},
	journaltitle = {Mathematical Problems in Engineering},
	shortjournal = {Mathematical Problems in Engineering},
	author = {Li, Yuxing and Xiao, Luqi and Tang, Bingzhao and Liang, Lili and Lou, Yilan and Guo, Xinyao and Xue, Xiaohui},
	editor = {Ding, Baiyuan},
	urldate = {2024-10-09},
	date = {2022-08-04},
	langid = {english},
	note = {16 citations (Semantic Scholar/{DOI}) [2024-10-15]
8 citations (Crossref) [2024-10-14]},
}

@inproceedings{lian_feature_2022,
	location = {Beijing, China},
	title = {Feature Extraction of Underwater Acoustic Target Signals Using Gammatone Filterbank and Subband Instantaneous Frequency},
	rights = {https://doi.org/10.15223/policy-029},
	isbn = {978-1-66545-864-1},
	url = {https://ieeexplore.ieee.org/document/9929447/},
	doi = {10.1109/IAEAC54830.2022.9929447},
	eventtitle = {2022 {IEEE} 6th Advanced Information Technology, Electronic and Automation Control Conference ({IAEAC} )},
	pages = {944--949},
	booktitle = {2022 {IEEE} 6th Advanced Information Technology, Electronic and Automation Control Conference ({IAEAC} )},
	publisher = {{IEEE}},
	author = {Lian, Zixu and Wu, Tianshu},
	urldate = {2024-10-09},
	date = {2022-10-03},
	note = {2 citations (Semantic Scholar/{DOI}) [2024-10-15]
1 citations (Crossref) [2024-10-14]},
}

@article{park_autoencoder-based_2022,
	title = {Autoencoder-Based Signal Modulation and Demodulation Methods for Sonobuoy Signal Transmission and Reception},
	volume = {22},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/22/17/6510},
	doi = {10.3390/s22176510},
	abstract = {Sonobuoy is a disposable device that collects underwater acoustic information and is designed to transmit signals collected in a particular area to nearby aircraft or ships and sink to the seabed upon completion of its mission. In a conventional sonobuoy signal transmission and reception system, collected signals are modulated and transmitted using techniques such as frequency division modulation or Gaussian frequency shift keying. They are received and demodulated by an aircraft or a ship. However, this method has the disadvantage of a large amount of information being transmitted and low security due to relatively simple modulation and demodulation methods. Therefore, in this paper, we propose a method that uses an autoencoder to encode a transmission signal into a low-dimensional latent vector to transmit the latent vector to an aircraft or vessel. The method also uses an autoencoder to decode the received latent vector to improve signal security and to reduce the amount of transmission information by approximately a factor of a hundred compared to the conventional method. In addition, a denoising autoencoder, which reduces ambient noises in the reconstructed outputs while maintaining the merit of the proposed autoencoder, is also proposed. To evaluate the performance of the proposed autoencoders, we simulated a bistatic active and a passive sonobuoy environments. As a result of analyzing the sample spectrograms of the reconstructed outputs and mean square errors between original and reconstructed signals, we confirmed that the original signal could be restored from a low-dimensional latent vector by using the proposed autoencoder within approximately 4\% errors. Furthermore, we verified that the proposed denoising autoencoder reduces ambient noise successfully by comparing spectrograms and by measuring the overall signal-to-noise ratio and the log-spectral distance of noisy input and reconstructed output signals.},
	pages = {6510},
	number = {17},
	journaltitle = {Sensors},
	shortjournal = {Sensors},
	author = {Park, Jinuk and Seok, Jongwon and Hong, Jungpyo},
	urldate = {2024-09-23},
	date = {2022-08-29},
	langid = {english},
	note = {5 citations (Semantic Scholar/{DOI}) [2024-10-15]
5 citations (Crossref) [2024-10-14]},
	keywords = {Denoising},
}

@inproceedings{pauline_low-complexity_2022,
	location = {Chennai, India},
	title = {A Low-Complexity Underwater Acoustic Signal Denoising Technique based on Multi-Stage Adaptive Filter Configuration},
	rights = {https://doi.org/10.15223/policy-029},
	isbn = {978-1-66541-821-8},
	url = {https://ieeexplore.ieee.org/document/9775479/},
	doi = {10.1109/OCEANSChennai45887.2022.9775479},
	eventtitle = {{OCEANS} 2022 - Chennai},
	pages = {1--4},
	booktitle = {{OCEANS} 2022 - Chennai},
	publisher = {{IEEE}},
	author = {Pauline, S. Hannah and Narayanamoorthi, R. and Dhanalakshmi, Samiappan},
	urldate = {2024-09-24},
	date = {2022-02-21},
	note = {6 citations (Semantic Scholar/{DOI}) [2024-10-15]
6 citations (Crossref) [2024-10-14]},
}

@misc{preciado-grijalva_self-supervised_2022,
	title = {Self-supervised Learning for Sonar Image Classification},
	url = {http://arxiv.org/abs/2204.09323},
	doi = {10.48550/arXiv.2204.09323},
	abstract = {Self-supervised learning has proved to be a powerful approach to learn image representations without the need of large labeled datasets. For underwater robotics, it is of great interest to design computer vision algorithms to improve perception capabilities such as sonar image classification. Due to the confidential nature of sonar imaging and the difficulty to interpret sonar images, it is challenging to create public large labeled sonar datasets to train supervised learning algorithms. In this work, we investigate the potential of three self-supervised learning methods ({RotNet}, Denoising Autoencoders, and Jigsaw) to learn high-quality sonar image representation without the need of human labels. We present pre-training and transfer learning results on real-life sonar image datasets. Our results indicate that self-supervised pre-training yields classification performance comparable to supervised pre-training in a few-shot transfer learning setup across all three methods. Code and self-supervised pre-trained models are be available at https://github.com/agrija9/ssl-sonar-images},
	number = {{arXiv}:2204.09323},
	publisher = {{arXiv}},
	author = {Preciado-Grijalva, Alan and Wehbe, Bilal and Firvida, Miguel Bande and Valdenegro-Toro, Matias},
	urldate = {2024-06-20},
	date = {2022-04-20},
	eprinttype = {arxiv},
	eprint = {2204.09323 [cs]},
	note = {12 citations (Semantic Scholar/{arXiv}) [2024-10-15]},
	keywords = {Initial reading list},
}

@article{ren_ualf_2022,
	title = {{UALF}: A learnable front-end for intelligent underwater acoustic classification system},
	volume = {264},
	issn = {00298018},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0029801822016833},
	doi = {10.1016/j.oceaneng.2022.112394},
	shorttitle = {{UALF}},
	abstract = {In practical ocean engineering application, variable target characteristics and inevitable environmental noise will decrease the recognition accuracy of underwater acoustic classification system. Thus, an intelligent Underwater Acoustic classification system with a Learnable Front-end ({UALF}) is proposed to improve automation. Similar to the cognitive process of the human, {UALF} extracts characteristics of underwater acoustic from multiple perspectives and adaptively adjusts the feature extraction and classifier modules to suit different application scenarios. Datasets under different recording conditions and scenarios are used for the experiments. The results showed that {UALF} outperforms all baseline methods, which verified its intelligence and feasibility for practical engineering application.},
	pages = {112394},
	journaltitle = {Ocean Engineering},
	shortjournal = {Ocean Engineering},
	author = {Ren, Jiawei and Xie, Yuan and Zhang, Xiaowei and Xu, Ji},
	urldate = {2024-10-10},
	date = {2022-11},
	langid = {english},
	note = {31 citations (Semantic Scholar/{DOI}) [2024-10-15]
25 citations (Crossref) [2024-10-14]},
}

@article{shin_passive_2022,
	title = {Passive Sonar Target Identification Using Multiple-Measurement Sparse Bayesian Learning},
	volume = {22},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/22/21/8511},
	doi = {10.3390/s22218511},
	abstract = {Accurate estimation of the frequency component is an important issue to identify and track marine objects (e.g., surface ship, submarine, etc.). In general, a passive sonar system consists of a sensor array, and each sensor receives data that have common information of the target signal. In this paper, we consider multiple-measurement sparse Bayesian learning ({MM}-{SBL}), which reconstructs sparse solutions in a linear system using Bayesian frameworks, to detect the common frequency components received by each sensor. In addition, the direction of arrival estimation was performed on each detected common frequency component using the {MM}-{SBL} based on beamforming. The azimuth for each common frequency component was confirmed in the frequency-azimuth plot, through which we identified the target. In addition, we perform target tracking using the target detection results along time, which are derived from the sum of the signal spectrum at the azimuth angle. The performance of the {MM}-{SBL} and the conventional target detection method based on energy detection were compared using in-situ data measured near the Korean peninsula, where {MM}-{SBL} displays superior detection performance and high-resolution results.},
	pages = {8511},
	number = {21},
	journaltitle = {Sensors},
	shortjournal = {Sensors},
	author = {Shin, Myoungin and Hong, Wooyoung and Lee, Keunhwa and Choo, Youngmin},
	urldate = {2024-06-20},
	date = {2022-11-04},
	langid = {english},
	note = {1 citations (Semantic Scholar/{DOI}) [2024-10-15]
1 citations (Crossref) [2024-10-14]},
	keywords = {Initial reading list, Private dataset},
}

@article{smith_underwater_2022,
	title = {Underwater radiated noise from marine vessels: A review of noise reduction methods and technology},
	volume = {266},
	issn = {00298018},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0029801822021461},
	doi = {10.1016/j.oceaneng.2022.112863},
	shorttitle = {Underwater radiated noise from marine vessels},
	pages = {112863},
	journaltitle = {Ocean Engineering},
	shortjournal = {Ocean Engineering},
	author = {Smith, Tom A. and Rigby, Jake},
	urldate = {2024-10-10},
	date = {2022-12},
	langid = {english},
	note = {41 citations (Semantic Scholar/{DOI}) [2024-10-15]
35 citations (Crossref) [2024-10-14]},
}

@article{vaz_marine_2022,
	title = {Marine Acoustic Signature Recognition Using Convolutional Neural Networks},
	issn = {1556-5068},
	url = {https://www.ssrn.com/abstract=4119910},
	doi = {10.2139/ssrn.4119910},
	journaltitle = {{SSRN} Electronic Journal},
	shortjournal = {{SSRN} Journal},
	author = {Vaz, Guilherme and Correia, Alexandre and Vicente, Miguel and Sousa, Joao and Cruz, Erica and Dommergues, Benedicte},
	urldate = {2024-10-10},
	date = {2022},
	langid = {english},
	note = {0 citations (Semantic Scholar/{DOI}) [2024-10-15]
0 citations (Crossref) [2024-10-14]},
}

@article{wang_passive_2022,
	title = {Passive tracking of underwater acoustic targets based on multi-beam {LOFAR} and deep learning},
	volume = {17},
	issn = {1932-6203},
	url = {https://dx.plos.org/10.1371/journal.pone.0273898},
	doi = {10.1371/journal.pone.0273898},
	abstract = {Conventional passive tracking methods for underwater acoustic targets in sonar engineering generate time azimuth histogram and use it as a basis for target azimuth and tracking. Passive underwater acoustic targets only have azimuth information on the time azimuth histogram, which is easy to be lost and disturbed by ocean noise. To improve the accuracy of passive tracking, we propose to adopt the processed multi-beam Low Frequency Analysis and Recording ({LOFAR}) as the dataset for passive tracking. In this paper, an improved {LeNet}-5 convolutional neural network model ({CNN}) model is used to identify targets, and a passive tracking method for underwater acoustic targets based on multi-beam {LOFAR} and deep learning is proposed, combined with Extended Kalman Filter ({EKF}) to improve the tracking accuracy. The performance of the method under realistic conditions is evaluated through simulation analysis and validation using data obtained from marine experiments.},
	pages = {e0273898},
	number = {12},
	journaltitle = {{PLOS} {ONE}},
	shortjournal = {{PLoS} {ONE}},
	author = {Wang, Maofa and Qiu, Baochun and Zhu, Zefei and Ma, Li and Zhou, Chuanping},
	editor = {Mohammadzadeh, Ardashir},
	urldate = {2024-10-10},
	date = {2022-12-01},
	langid = {english},
	note = {4 citations (Semantic Scholar/{DOI}) [2024-10-15]
3 citations (Crossref) [2024-10-14]},
}

@inproceedings{wang_auditory-based_2022,
	location = {Beijing, China},
	title = {Auditory-Based Multi-Scale Amplitude-Aware Permutation Entropy as a Measure for Feature Extraction of Ship Radiated Noise},
	rights = {https://doi.org/10.15223/policy-029},
	isbn = {978-1-66545-864-1},
	url = {https://ieeexplore.ieee.org/document/9929729/},
	doi = {10.1109/IAEAC54830.2022.9929729},
	eventtitle = {2022 {IEEE} 6th Advanced Information Technology, Electronic and Automation Control Conference ({IAEAC} )},
	pages = {1550--1555},
	booktitle = {2022 {IEEE} 6th Advanced Information Technology, Electronic and Automation Control Conference ({IAEAC} )},
	publisher = {{IEEE}},
	author = {Wang, Ping and Chen, Mingsong and Wang, Junyi and Deng, Xiaofang and Chen, Zhe},
	urldate = {2024-10-10},
	date = {2022-10-03},
	note = {3 citations (Semantic Scholar/{DOI}) [2024-10-15]
1 citations (Crossref) [2024-10-14]},
}

@article{xiao_feature_2022,
	title = {Feature Extraction of Ship-Radiated Noise Based on Hierarchical Dispersion Entropy},
	volume = {2022},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1875-9203, 1070-9622},
	url = {https://www.hindawi.com/journals/sv/2022/3238461/},
	doi = {10.1155/2022/3238461},
	abstract = {The classification and recognition of ship-radiated noise ({SRN}) is of great significance to the processing of underwater acoustic signals. In order to improve the stability of recognition and more accurately identify {SRN}, single feature extraction and dual feature extraction based on hierarchical dispersion entropy ({HDE}) are proposed. For single feature extraction, {HDE} of the best node among the eight nodes of the third layer decomposition is extracted. For dual feature extraction, {HDE} of the best two nodes among the 14 nodes of the first-, second-, and third-layer decompositions are required. The results show that the recognition rate of single and dual feature extraction originated from the method based on {HDE} reaches 85\% and 100\%, respectively, better than the method of hierarchical reverse dispersion entropy ({HRDE}) and hierarchical permutation entropy ({HPE}).},
	pages = {1--10},
	journaltitle = {Shock and Vibration},
	shortjournal = {Shock and Vibration},
	author = {Xiao, Leilei},
	editor = {Li, Yuxing},
	urldate = {2024-10-10},
	date = {2022-05-28},
	langid = {english},
	note = {2 citations (Semantic Scholar/{DOI}) [2024-10-15]
2 citations (Crossref) [2024-10-14]},
}

@article{xie_adaptive_2022,
	title = {Adaptive ship-radiated noise recognition with learnable fine-grained wavelet transform},
	volume = {265},
	issn = {00298018},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0029801822019096},
	doi = {10.1016/j.oceaneng.2022.112626},
	pages = {112626},
	journaltitle = {Ocean Engineering},
	shortjournal = {Ocean Engineering},
	author = {Xie, Yuan and Ren, Jiawei and Xu, Ji},
	urldate = {2024-10-10},
	date = {2022-12},
	langid = {english},
	note = {27 citations (Semantic Scholar/{DOI}) [2024-10-15]
21 citations (Crossref) [2024-10-14]},
}

@article{xie_underwater-art_2022,
	title = {Underwater-art: Expanding information perspectives with text templates for underwater acoustic target recognition},
	volume = {152},
	issn = {0001-4966, 1520-8524},
	url = {https://pubs.aip.org/jasa/article/152/5/2641/2839510/Underwater-art-Expanding-information-perspectives},
	doi = {10.1121/10.0015053},
	shorttitle = {Underwater-art},
	abstract = {Underwater acoustic target recognition is an intractable task due to the complex acoustic source characteristics and sound propagation patterns. Limited by insufficient data and narrow information perspective, recognition models based on deep learning seem far from satisfactory in practical underwater scenarios. Although underwater acoustic signals are severely influenced by distance, channel depth, or other factors, annotations of relevant information are often nonuniform, incomplete, and hard to use. In this work, the proposal is to implement underwater acoustic recognition based on templates made up of rich relevant information ({UART}). The templates are designed to integrate relevant information from different perspectives into descriptive natural language. {UART} adopts an audio-spectrogram-text trimodal contrastive learning framework, which endows {UART} with the ability to guide the learning of acoustic representations by descriptive natural language. These experiments reveal that {UART} has better recognition capability and generalization performance than traditional paradigms. Furthermore, the pretrained {UART} model could provide superior prior knowledge for the recognition model in the scenario without any auxiliary annotation.},
	pages = {2641--2651},
	number = {5},
	journaltitle = {The Journal of the Acoustical Society of America},
	author = {Xie, Yuan and Ren, Jiawei and Xu, Ji},
	urldate = {2024-10-10},
	date = {2022-11-01},
	langid = {english},
	note = {14 citations (Semantic Scholar/{DOI}) [2024-10-15]
13 citations (Crossref) [2024-10-14]},
}

@article{xue_novel_2022,
	title = {A Novel Deep-Learning Method with Channel Attention Mechanism for Underwater Target Recognition},
	volume = {22},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/22/15/5492},
	doi = {10.3390/s22155492},
	abstract = {The core of underwater acoustic recognition is to extract the spectral features of targets. The running speed and track of the targets usually result in a Doppler shift, which poses significant challenges for recognizing targets with different Doppler frequencies. This paper proposes deep learning with a channel attention mechanism approach for underwater acoustic recognition. It is based on three crucial designs. Feature structures can obtain high-dimensional underwater acoustic data. The feature extraction model is the most important. First, we develop a {ResNet} to extract the deep abstraction spectral features of the targets. Then, the channel attention mechanism is introduced in the {camResNet} to enhance the energy of stable spectral features of residual convolution. This is conducive to subtly represent the inherent characteristics of the targets. Moreover, a feature classification approach based on one-dimensional convolution is applied to recognize targets. We evaluate our approach on challenging data containing four kinds of underwater acoustic targets with different working conditions. Our experiments show that the proposed approach achieves the best recognition accuracy (98.2\%) compared with the other approaches. Moreover, the proposed approach is better than the {ResNet} with a widely used channel attention mechanism for data with different working conditions.},
	pages = {5492},
	number = {15},
	journaltitle = {Sensors},
	shortjournal = {Sensors},
	author = {Xue, Lingzhi and Zeng, Xiangyang and Jin, Anqi},
	urldate = {2024-10-10},
	date = {2022-07-23},
	langid = {english},
	note = {18 citations (Semantic Scholar/{DOI}) [2024-10-15]
18 citations (Crossref) [2024-10-14]},
}

@article{yi_feature_2022,
	title = {Feature extraction method of ship radiated noise based on {BOA}-{VMD} and slope entropy},
	volume = {10},
	issn = {2296-424X},
	url = {https://www.frontiersin.org/articles/10.3389/fphy.2022.1043070/full},
	doi = {10.3389/fphy.2022.1043070},
	abstract = {Although the technical requirements for the feature extraction of ship radiated noise ({SRN}) in the fields of national defense and economy increase with each passing day, the complexity of the marine environment makes the feature extraction of {SRN} difficult. The traditional feature extraction method based on variational mode decomposition ({VMD}) is widely used in the feature extraction of {SRN}. Nevertheless, the use of {VMD} is greatly affected by parameters. In this paper, the butterfly optimization algorithm ({BOA}) is introduced to optimize {VMD}, which is called {BOA}-{VMD} algorithm, and realizes the optimal selection of {VMD} parameters
              
                
                  
                    K
                  
                
              
              and
              
                
                  
                    α
                  
                
              
              . To further improve the efficiency of feature extraction method, combined with slope entropy ({SE}), a feature extraction method of {SRN} based on {BOA}-{VMD} and {SE} is proposed. The experimental results of the simulated signal show that the {BOA}-{VMD} algorithm has a smaller envelope entropy value and better decomposition effect than the genetic algorithm ({GA}) and particle swarm optimization ({PSO}). The experimental results of feature extraction of {SRN} show that the highest recognition rate of the four entropy values improve with the increase of the number of extracted features, compared with the three entropy values of dispersion entropy ({DE}), fluctuation dispersion entropy ({FDE}) and permutation entropy ({PE}), the {SRN} feature extraction method based on {BOA}-{VMD} and {SE} has the highest recognition rate under different quantity features, and the recognition rate has reached 100\% under three features.},
	pages = {1043070},
	journaltitle = {Frontiers in Physics},
	shortjournal = {Front. Phys.},
	author = {Yi, Yingmin and Tian, Ge},
	urldate = {2024-10-10},
	date = {2022-10-17},
	note = {5 citations (Semantic Scholar/{DOI}) [2024-10-15]
4 citations (Crossref) [2024-10-14]},
}

@inproceedings{zhang_multi-features_2022,
	location = {Guiyang, China},
	title = {Multi-Features Fusion for Underwater Acoustic Target Recognition based on Convolution Recurrent Neural Networks},
	rights = {https://doi.org/10.15223/policy-029},
	isbn = {978-1-66548-796-2},
	url = {https://ieeexplore.ieee.org/document/9874151/},
	doi = {10.1109/BigDIA56350.2022.9874151},
	eventtitle = {2022 8th International Conference on Big Data and Information Analytics ({BigDIA})},
	pages = {342--346},
	booktitle = {2022 8th International Conference on Big Data and Information Analytics ({BigDIA})},
	publisher = {{IEEE}},
	author = {Zhang, Wen and Lin, Bin and Yan, Yulin and Zhou, Aolong and Ye, Yanqing and Zhu, Xiaomin},
	urldate = {2024-10-10},
	date = {2022-08-24},
	note = {8 citations (Semantic Scholar/{DOI}) [2024-10-15]
8 citations (Crossref) [2024-10-14]},
}

@article{zhang_surface_2022,
	title = {Surface and Underwater Acoustic Source Discrimination Based on Machine Learning Using a Single Hydrophone},
	volume = {10},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2077-1312},
	url = {https://www.mdpi.com/2077-1312/10/3/321},
	doi = {10.3390/jmse10030321},
	abstract = {In shallow water, passive sonar usually has great difficulty in discriminating a surface acoustic source from an underwater one. To solve this problem, a supervised machine learning method using only one hydrophone is implemented in this paper. Firstly, simulated training data are generated by a normal mode model {KRAKEN} with the same environment setup as that in {SACLANT} 1993 experiment. Secondly, the k-nearest neighbor ({kNN}) classifiers are trained and evaluated using the scores of precision, recall, F1 and accuracy. Thirdly, the random subspace {kNN} classifiers are finely trained on three hyperparameters (the number of nearest neighbors, the number of predictors selected at random and the number of learners in the ensemble) to obtain the best model. Fourthly, a deep learning method called {ResNet}-18 is also applied, and it reaches the best balance between precision and recall, while the accuracies of both simulation and experimental data are all 1.0. Further, data from all 48 hydrophones of the vertical linear array ({VLA}) are analyzed using the three kinds of machine learning methods ({kNN}, random subspace {kNN} and {ResNet}-18) separately, and the results are compared. It is concluded that the performance of random subspace {kNN} is the best. Both the simulation and experimental results suggest the feasibility of machine learning as a surface and underwater acoustic source discrimination method even with only a single hydrophone.},
	pages = {321},
	number = {3},
	journaltitle = {Journal of Marine Science and Engineering},
	shortjournal = {{JMSE}},
	author = {Zhang, Wen and Wu, Yanqun and Shi, Jian and Leng, Hongze and Zhao, Yun and Guo, Jizhou},
	urldate = {2024-10-10},
	date = {2022-02-24},
	langid = {english},
	note = {10 citations (Semantic Scholar/{DOI}) [2024-10-15]
9 citations (Crossref) [2024-10-14]},
}

@article{chen_new_2023,
	title = {A New Method of Ship Type Identification Based on Underwater Radiated Noise Signals},
	volume = {11},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2077-1312},
	url = {https://www.mdpi.com/2077-1312/11/5/963},
	doi = {10.3390/jmse11050963},
	abstract = {Ship type identification is an important basis for ship management and monitoring. The paper proposed a new method of ship type identification by combining characteristic parameters from the energy difference between high and low frequencies and the sensitive {IMF} variance mean value based on the modal decomposition of the underwater radiated noise signals using the Ensemble Empirical Mode Decomposition ({EEMD}) method. The comparison shows that the characteristic parameters of different types of ship, underwater radiated noises are different, whereas those of the same types of ship, underwater radiated noises fall in close range. Validation experiments based on randomly selected ship underwater radiated noise samples manifest that the method is of good separability for the four types of ship underwater radiated noises in the Deepship dataset. It has a higher identification rate than other methods within the distance range of ship underwater radiated noise detection in the dataset. The accuracy of this method tends to decrease with distance in the classification experiments of the ship underwater radiated noises at different distances.},
	pages = {963},
	number = {5},
	journaltitle = {Journal of Marine Science and Engineering},
	shortjournal = {{JMSE}},
	author = {Chen, Shanshan and Guan, Sheng and Wang, Hui and Ye, Ningqi and Wei, Zexun},
	urldate = {2024-10-09},
	date = {2023-04-30},
	langid = {english},
	note = {2 citations (Semantic Scholar/{DOI}) [2024-10-15]
2 citations (Crossref) [2024-10-14]},
}

@article{daihui_li_data_2023,
	title = {Data augmentation method for underwater acoustic target recognition based on underwater acoustic channel modeling and transfer learning},
	volume = {208},
	doi = {10.1016/j.apacoust.2023.109344},
	abstract = {Data augmentation methods as a critical technique in deep learning have not been well studied in the underwater acoustic target recognition, which leads difficult for recognition models to cope with data scarcity and noise interference. This study proposes a data augmentation method based on underwater acoustic channel modeling and Transfer learning to address these challenges. A underwater acoustic channel modeling approach is proposed to generate the augmented signal. A feature-based transfer learning method is presented to narrow the distribution differences between augmented and observed data, and the noise is randomly added to enhance model robustness during training. Dataset acquired in a real-world scenario is used to verify the proposed methods. The proposed methods' effectiveness is proved by utilizing data augmentation in the model training process, which effectively improves the accuracy and noise robustness of the recognition model, especially when observed data is scarce.},
	pages = {109344--109344},
	author = {{Daihui Li} and {Feng Liu} and {Tongsheng Shen} and {Liang Chen} and {Dexin Zhao}},
	date = {2023-06-01},
	doi = {10.1016/j.apacoust.2023.109344},
	note = {15 citations (Semantic Scholar/{DOI}) [2024-10-15]
10 citations (Crossref) [2024-10-14]
{MAG} {ID}: 4365140193},
	keywords = {{ShipsEar}},
}

@article{jin_novel_2023,
	title = {A Novel Deep Learning Method for Underwater Target Recognition Based on Res-Dense Convolutional Neural Network with Attention Mechanism},
	volume = {11},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2077-1312},
	url = {https://www.mdpi.com/2077-1312/11/1/69},
	doi = {10.3390/jmse11010069},
	abstract = {Long-range underwater targets must be accurately and quickly identified for both defense and civil purposes. However, the performance of an underwater acoustic target recognition ({UATR}) system can be significantly affected by factors such as lack of data and ship working conditions. As the marine environment is very complex, {UATR} relies heavily on feature engineering, and manually extracted features are occasionally ineffective in the statistical model. In this paper, an end-to-end model of {UATR} based on a convolutional neural network and attention mechanism is proposed. Using raw time domain data as input, the network model combines residual neural networks and densely connected convolutional neural networks to take full advantage of both. Based on this, a channel attention mechanism and a temporal attention mechanism are added to extract the information in the channel dimension and the temporal dimension. After testing the measured four types of ship-radiated noise dataset in experiments, the results show that the proposed method achieves the highest correct recognition rate of 97.69\% under different working conditions and outperforms other deep learning methods.},
	pages = {69},
	number = {1},
	journaltitle = {Journal of Marine Science and Engineering},
	shortjournal = {{JMSE}},
	author = {Jin, Anqi and Zeng, Xiangyang},
	urldate = {2024-08-06},
	date = {2023-01-02},
	langid = {english},
	note = {18 citations (Semantic Scholar/{DOI}) [2024-10-15]
21 citations (Crossref) [2024-10-14]},
	keywords = {Private dataset},
}

@article{jin_offshore_2023,
	title = {Offshore ship recognition based on center frequency projection of improved {EMD} and {KNN} algorithm},
	volume = {189},
	issn = {08883270},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S088832702201144X},
	doi = {10.1016/j.ymssp.2022.110076},
	pages = {110076},
	journaltitle = {Mechanical Systems and Signal Processing},
	shortjournal = {Mechanical Systems and Signal Processing},
	author = {Jin, Shu-Ya and Su, Yu and Guo, Chuan-Jie and Fan, Ya-Xian and Tao, Zhi-Yong},
	urldate = {2024-08-06},
	date = {2023-04},
	langid = {english},
	note = {14 citations (Semantic Scholar/{DOI}) [2024-10-15]
13 citations (Crossref) [2024-10-14]},
	keywords = {{ShipsEar}},
}

@article{kamalipour_passive_2023,
	title = {Passive ship detection and classification using hybrid cepstrums and deep compound autoencoders},
	volume = {35},
	issn = {0941-0643, 1433-3058},
	url = {https://link.springer.com/10.1007/s00521-022-08075-7},
	doi = {10.1007/s00521-022-08075-7},
	pages = {7833--7851},
	number = {10},
	journaltitle = {Neural Computing and Applications},
	shortjournal = {Neural Comput \& Applic},
	author = {Kamalipour, Maryam and Agahi, Hamed and Khishe, Mohammad and Mahmoodzadeh, Azar},
	urldate = {2024-10-09},
	date = {2023-04},
	langid = {english},
	note = {11 citations (Semantic Scholar/{DOI}) [2024-10-15]
10 citations (Crossref) [2024-10-14]},
}

@article{li_robust_2023,
	title = {A Robust Feature Extraction Method for Underwater Acoustic Target Recognition Based on Multi-Task Learning},
	volume = {12},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2079-9292},
	url = {https://www.mdpi.com/2079-9292/12/7/1708},
	doi = {10.3390/electronics12071708},
	abstract = {Target classification and recognition have always been complex problems in underwater acoustic signal processing because of noise interference and feature instability. In this paper, a robust feature extraction method based on multi-task learning is proposed, which provides an effective solution. Firstly, an {MLP}-based network model suitable for underwater acoustic signal processing is proposed to optimize feature extraction. Then, multi-task learning is deployed on the model in hard parameter-sharing so that the model can extract anti-noise interference features and embed prior feature extraction knowledge. In the model training stage, the simultaneous training method enables the model to improve the robustness and representation of classification features with the knowledge of different tasks. Furthermore, the optimized classification features are sent to the classification network to complete target recognition. The proposed method is evaluated by the dataset collected in the real environment. The results show that the proposed method effectively improves recognition accuracy and maintains high performance under different noise levels, which is better than popular methods.},
	pages = {1708},
	number = {7},
	journaltitle = {Electronics},
	shortjournal = {Electronics},
	author = {Li, Daihui and Liu, Feng and Shen, Tongsheng and Chen, Liang and Zhao, Dexin},
	urldate = {2024-10-09},
	date = {2023-04-04},
	langid = {english},
	note = {3 citations (Semantic Scholar/{DOI}) [2024-10-15]
3 citations (Crossref) [2024-10-14]},
}

@article{li_research_2023,
	title = {Research on noise reduction method for ship radiate noise based on secondary decomposition},
	volume = {268},
	issn = {00298018},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0029801822026956},
	doi = {10.1016/j.oceaneng.2022.113412},
	pages = {113412},
	journaltitle = {Ocean Engineering},
	shortjournal = {Ocean Engineering},
	author = {Li, Guohui and Bu, Wenjia and Yang, Hong},
	urldate = {2024-09-24},
	date = {2023-01},
	langid = {english},
	note = {30 citations (Semantic Scholar/{DOI}) [2024-10-15]
22 citations (Crossref) [2024-10-14]},
}

@article{li_method_2023,
	title = {A method for extracting interference striations in lofargram based on decomposition and clustering},
	volume = {17},
	issn = {1751-9659, 1751-9667},
	url = {https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/ipr2.12768},
	doi = {10.1049/ipr2.12768},
	abstract = {Abstract
            In complex underwater noise environment, target detection, recognition, and tracking are proceeded through the frequency spectrum analysis of the signals received by sonar systems, in which the lofargram plays a major role. Typically, if the distance of the target experiences far‐near‐far variation, there will be parabolic interference striations presented in the lofargram. However, the existing striations extraction methods sometimes lack objectivity and fail to extract the wide striations accurately. In this paper, a novel method for wide type interference striations extraction is developed based on efficient decomposition and ensemble clustering. To obtain valuable information, the lofargram is decomposed into smooth background, striations area, and noise, then a multi‐phase ensemble clustering algorithm is employed to extract parabolas from the decomposed striations area pixels. Experimental results on simulated and real‐life datasets exhibit the effectiveness of the proposed method, and verify that it has comparable performance with prevalent Hough transform while extracting striations.},
	pages = {1951--1958},
	number = {6},
	journaltitle = {{IET} Image Processing},
	shortjournal = {{IET} Image Processing},
	author = {Li, Xinyan and Wang, Dianpeng and Tian, Yubin and Kong, Xiangshun},
	urldate = {2024-08-13},
	date = {2023-05},
	langid = {english},
	note = {0 citations (Semantic Scholar/{DOI}) [2024-10-15]
0 citations (Crossref) [2024-10-14]},
}

@article{li_so-slope_2023,
	title = {{SO}-slope entropy coupled with {SVMD}: A novel adaptive feature extraction method for ship-radiated noise},
	volume = {280},
	issn = {00298018},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0029801823010612},
	doi = {10.1016/j.oceaneng.2023.114677},
	shorttitle = {{SO}-slope entropy coupled with {SVMD}},
	pages = {114677},
	journaltitle = {Ocean Engineering},
	shortjournal = {Ocean Engineering},
	author = {Li, Yuxing and Tang, Bingzhao and Jiao, Shangbin},
	urldate = {2024-10-09},
	date = {2023-07},
	langid = {english},
	note = {59 citations (Semantic Scholar/{DOI}) [2024-10-15]
56 citations (Crossref) [2024-10-14]},
}

@article{li_joint_2023,
	title = {Joint Detection and Reconstruction of Weak Spectral Lines under Non-Gaussian Impulsive Noise with Deep Learning},
	volume = {15},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2072-4292},
	url = {https://www.mdpi.com/2072-4292/15/13/3268},
	doi = {10.3390/rs15133268},
	abstract = {Non-Gaussian impulsive noise in marine environments strongly influences the detection of weak spectral lines. However, existing detection algorithms based on the Gaussian noise model are futile under non-Gaussian impulsive noise. Therefore, a deep-learning method called {AINP}+{LR}-{DRNet} is proposed for joint detection and the reconstruction of weak spectral lines. First, non-Gaussian impulsive noise suppression was performed by an impulsive noise preprocessor ({AINP}). Second, a special detection and reconstruction network ({DRNet}) was proposed. An end-to-end training application learns to detect and reconstruct weak spectral lines by adding into an adaptive weighted loss function based on dual classification. Finally, a spectral line-detection algorithm based on {DRNet} ({LR}-{DRNet}) was proposed to improve the detection performance. The simulation indicated that the proposed {AINP}+{LR}-{DRNet} can detect and reconstruct weak spectral line features under non-Gaussian impulsive noise, even for a mixed signal-to-noise ratio as low as −26 {dB}. The performance of the proposed method was validated using experimental data. The proposed {AINP}+{LR}-{DRNet} detects and reconstructs spectral lines under strong background noise and interference with better reliability than other algorithms.},
	pages = {3268},
	number = {13},
	journaltitle = {Remote Sensing},
	shortjournal = {Remote Sensing},
	author = {Li, Zhen and Guo, Junyuan and Wang, Xiaohan},
	urldate = {2024-08-13},
	date = {2023-06-25},
	langid = {english},
	note = {1 citations (Semantic Scholar/{DOI}) [2024-10-15]
1 citations (Crossref) [2024-10-14]},
}

@article{lingzhi_completion-attention_2023,
	title = {Completion-Attention Ladder Network for Few-Shot Underwater Acoustic Recognition},
	volume = {55},
	issn = {1370-4621, 1573-773X},
	url = {https://link.springer.com/10.1007/s11063-023-11214-3},
	doi = {10.1007/s11063-023-11214-3},
	pages = {9563--9579},
	number = {7},
	journaltitle = {Neural Processing Letters},
	shortjournal = {Neural Process Lett},
	author = {Lingzhi, Xue and Xiangyang, Zeng and Xiang, Yan and Shuang, Yang},
	urldate = {2024-10-09},
	date = {2023-12},
	langid = {english},
	note = {3 citations (Semantic Scholar/{DOI}) [2024-10-15]
2 citations (Crossref) [2024-10-14]},
}

@article{luo_survey_2023,
	title = {A Survey of Underwater Acoustic Target Recognition Methods Based on Machine Learning},
	volume = {11},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2077-1312},
	url = {https://www.mdpi.com/2077-1312/11/2/384},
	doi = {10.3390/jmse11020384},
	abstract = {Underwater acoustic target recognition ({UATR}) technology has been implemented widely in the fields of marine biodiversity detection, marine search and rescue, and seabed mapping, providing an essential basis for human marine economic and military activities. With the rapid development of machine-learning-based technology in the acoustics field, these methods receive wide attention and display a potential impact on {UATR} problems. This paper reviews current {UATR} methods based on machine learning. We focus mostly, but not solely, on the recognition of target-radiated noise from passive sonar. First, we provide an overview of the underwater acoustic acquisition and recognition process and briefly introduce the classical acoustic signal feature extraction methods. In this paper, recognition methods for {UATR} are classified based on the machine learning algorithms used as {UATR} technologies using statistical learning methods, {UATR} methods based on deep learning models, and transfer learning and data augmentation technologies for {UATR}. Finally, the challenges of {UATR} based on the machine learning method are summarized and directions for {UATR} development in the future are put forward.},
	pages = {384},
	number = {2},
	journaltitle = {Journal of Marine Science and Engineering},
	shortjournal = {{JMSE}},
	author = {Luo, Xinwei and Chen, Lu and Zhou, Hanlu and Cao, Hongli},
	urldate = {2024-06-21},
	date = {2023-02-09},
	langid = {english},
	note = {19 citations (Semantic Scholar/{DOI}) [2024-10-15]
20 citations (Crossref) [2024-10-14]},
	keywords = {Review},
}

@article{nie_contrastive-learning-based_2023,
	title = {A Contrastive-Learning-Based Method for the Few-Shot Identification of Ship-Radiated Noises},
	volume = {11},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2077-1312},
	url = {https://www.mdpi.com/2077-1312/11/4/782},
	doi = {10.3390/jmse11040782},
	abstract = {For identifying each vessel from ship-radiated noises with only a very limited number of data samples available, an approach based on the contrastive learning was proposed. The input was sample pairs in the training, and the parameters of the models were optimized by maximizing the similarity of sample pairs from the same vessel and minimizing that from different vessels. In practical inference, the method calculated the distance between the features of testing samples and those of registration templates and assigned the testing sample into the closest templates for it to achieve the parameter-free classification. Experimental results on different sea-trial data demonstrated the advantages of the proposed method. On the five-ship identification task based on the open-source data, the proposed method achieved an accuracy of 0.68 when only five samples per vessel were available, that was significantly higher than conventional solutions with accuracies of 0.26 and 0.48. Furthermore, the convergence of the method and the behavior of its performance with increasing data samples available for the training were discussed empirically.},
	pages = {782},
	number = {4},
	journaltitle = {Journal of Marine Science and Engineering},
	shortjournal = {{JMSE}},
	author = {Nie, Leixin and Li, Chao and Wang, Haibin and Wang, Jun and Zhang, Yonglin and Yin, Fan and Marzani, Franck and Bozorg Grayeli, Alexis},
	urldate = {2024-10-10},
	date = {2023-04-04},
	langid = {english},
	note = {4 citations (Semantic Scholar/{DOI}) [2024-10-15]
4 citations (Crossref) [2024-10-14]},
}

@article{niu_advances_2023,
	title = {Advances and applications of machine learning in underwater acoustics},
	volume = {1},
	doi = {10.1007/s44295-023-00005-0},
	abstract = {Abstract Recent advancements in machine learning ({ML}) techniques applied to underwater acoustics have significantly impacted various aspects of this field, such as source localization, target recognition, communication, and geoacoustic inversion. This review provides a comprehensive summary and evaluation of these developments. As a data-driven approach, {ML} played a pivotal role in discerning intricate relationships between input features and desired labels based on the provided training dataset. They are achieving success in ocean acoustic applications through {ML} hinges on several critical factors, including well-designed input feature preprocessing, appropriate labels, choice of {ML} models, effective training strategy, and availability of ample training and validation datasets. This review highlights noteworthy results from published studies to illustrate the effectiveness of {ML} methods in diverse application scenarios. In addition, it delves into the essential techniques employed within these applications. To understand the utility of {ML} in underwater acoustics, one must analyze its advantages and limitations. This assessment will aid in identifying scenarios where {ML} excels and those where it may face challenges. In addition, it provides insights into promising avenues for future research, shedding light on potential research directions that warrant exploration.},
	number = {1},
	journaltitle = {Intelligent Marine Technology and Systems},
	author = {Niu, Haiqiang and Li, Xiaolei and Zhang, Yonglin and Ji, Xu},
	date = {2023-10-20},
	doi = {10.1007/s44295-023-00005-0},
	note = {6 citations (Semantic Scholar/{DOI}) [2024-10-15]
6 citations (Crossref) [2024-10-14]
{MAG} {ID}: 4387836979},
	keywords = {Review},
}

@inproceedings{prasad_deep_2023,
	location = {Jaipur, India},
	title = {Deep Learning Techniques for Detection of Underwater Acoustic Sources},
	rights = {https://doi.org/10.15223/policy-029},
	isbn = {978-1-66547-512-9},
	url = {https://ieeexplore.ieee.org/document/10092324/},
	doi = {10.1109/IEMECON56962.2023.10092324},
	eventtitle = {2023 11th International Conference on Internet of Everything, Microwave Engineering, Communication and Networks ({IEMECON})},
	pages = {1--6},
	booktitle = {2023 11th International Conference on Internet of Everything, Microwave Engineering, Communication and Networks ({IEMECON})},
	publisher = {{IEEE}},
	author = {Prasad, Sanjana K. R and Gurugopinath, Sanjeev},
	urldate = {2024-10-10},
	date = {2023-02-10},
	note = {2 citations (Semantic Scholar/{DOI}) [2024-10-15]
1 citations (Crossref) [2024-10-14]},
}

@article{qi_underwater_2023,
	title = {Underwater acoustic target recognition using {RCRNN} and wavelet-auditory feature},
	volume = {83},
	issn = {1573-7721},
	url = {https://link.springer.com/10.1007/s11042-023-17406-2},
	doi = {10.1007/s11042-023-17406-2},
	pages = {47295--47317},
	number = {16},
	journaltitle = {Multimedia Tools and Applications},
	shortjournal = {Multimed Tools Appl},
	author = {Qi, Pengyuan and Yin, Guisheng and Zhang, Liguo},
	urldate = {2024-08-06},
	date = {2023-10-26},
	langid = {english},
	note = {2 citations (Semantic Scholar/{DOI}) [2024-10-15]
2 citations (Crossref) [2024-10-14]},
	keywords = {{ShipsEar}},
}

@article{schmitt_there_2023,
	title = {There Are No Data Like More Data: Datasets for deep learning in Earth observation},
	volume = {11},
	issn = {2168-6831},
	url = {https://ieeexplore.ieee.org/document/10213439},
	doi = {10.1109/MGRS.2023.3293459},
	shorttitle = {There Are No Data Like More Data},
	abstract = {Carefully curated and annotated datasets are the foundation of machine learning ({ML}), with particularly data-hungry deep neural networks forming the core of what is often called artificial intelligence ({AI}). Due to the massive success of deep learning ({DL}) applied to Earth observation ({EO}) problems, the focus of the community has been largely on the development of evermore sophisticated deep neural network architectures and training strategies. For that purpose, numerous task-specific datasets have been created that were largely ignored by previously published review articles on {AI} for {EO}. With this article, we want to change the perspective and put {ML} datasets dedicated to {EO} data and applications into the spotlight. Based on a review of historical developments, currently available resources are described and a perspective for future developments is formed. We hope to contribute to an understanding that the nature of our data is what distinguishes the {EO} community from many other communities that apply {DL} techniques to image data, and that a detailed understanding of {EO} data peculiarities is among the core competencies of our discipline.},
	pages = {63--97},
	number = {3},
	journaltitle = {{IEEE} Geoscience and Remote Sensing Magazine},
	author = {Schmitt, Michael and Ahmadi, Seyed Ali and Xu, Yonghao and Taşkin, Gülşen and Verma, Ujjwal and Sica, Francescopaolo and Hänsch, Ronny},
	urldate = {2024-09-09},
	date = {2023-09},
	note = {14 citations (Semantic Scholar/{DOI}) [2024-10-15]
6 citations (Crossref) [2024-10-14]
Conference Name: {IEEE} Geoscience and Remote Sensing Magazine},
}

@article{song_novel_2023,
	title = {A novel noise reduction technique for underwater acoustic signals based on dual‐path recurrent neural network},
	volume = {17},
	rights = {http://creativecommons.org/licenses/by/4.0/},
	issn = {1751-8628, 1751-8636},
	url = {https://onlinelibrary.wiley.com/doi/10.1049/cmu2.12518},
	doi = {10.1049/cmu2.12518},
	pages = {135--144},
	number = {2},
	journaltitle = {{IET} Communications},
	shortjournal = {{IET} Communications},
	author = {Song, Yongqiang and Liu, Feng and Shen, Tongsheng},
	urldate = {2024-10-10},
	date = {2023-01},
	langid = {english},
	note = {4 citations (Semantic Scholar/{DOI}) [2024-10-15]
6 citations (Crossref) [2024-10-14]},
}

@article{sun_underwater_2023,
	title = {Underwater acoustic target recognition based on automatic feature and contrastive coding},
	volume = {17},
	issn = {1751-8784, 1751-8792},
	url = {https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/rsn2.12418},
	doi = {10.1049/rsn2.12418},
	abstract = {Abstract
            Underwater acoustic target recognition ({UATR}) technology based on deep learning and automatic encoding has become an important research direction in the underwater acoustic field in recent years. However, the existing methods do not have favourable self‐adaptability for different data because of the complex and changeable underwater environment, which easily leads to an unsatisfactory recognition effect. The concept of contrastive learning is introduced into {UATR} and a model named Contrastive Coding for {UATR} ({CCU}) is proposed. Based on the unsupervised contrastive learning framework, the model has been modified for the underwater acoustic field. Thus, the {CCU} can generate adaptable automatic features according to different data. The experimental test shows that the model is superior to other automatic encoding models and has achieved excellent recognition performance on different underwater acoustic datasets.},
	pages = {1277--1285},
	number = {8},
	journaltitle = {{IET} Radar, Sonar \& Navigation},
	shortjournal = {{IET} Radar Sonar \&amp; Navi},
	author = {Sun, Baogui and Luo, Xinwei},
	urldate = {2024-08-13},
	date = {2023-08},
	langid = {english},
	note = {2 citations (Semantic Scholar/{DOI}) [2024-10-15]
2 citations (Crossref) [2024-10-14]},
	keywords = {{DeepShip}, {ShipsEar}},
}

@article{tian_joint_2023,
	title = {Joint learning model for underwater acoustic target recognition},
	volume = {260},
	issn = {09507051},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0950705122012151},
	doi = {10.1016/j.knosys.2022.110119},
	pages = {110119},
	journaltitle = {Knowledge-Based Systems},
	shortjournal = {Knowledge-Based Systems},
	author = {Tian, Sheng-Zhao and Chen, Duan-Bing and Fu, Yan and Zhou, Jun-Lin},
	urldate = {2024-08-06},
	date = {2023-01},
	langid = {english},
	note = {21 citations (Semantic Scholar/{DOI}) [2024-10-15]
20 citations (Crossref) [2024-10-14]},
	keywords = {{DeepShip}, {ONC}},
}

@article{tian_few-shot_2023,
	title = {Few-shot learning for joint model in underwater acoustic target recognition},
	volume = {13},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-023-44641-2},
	doi = {10.1038/s41598-023-44641-2},
	abstract = {Abstract
            In underwater acoustic target recognition, there is a lack of massive high-quality labeled samples to train robust deep neural networks, and it is difficult to collect and annotate a large amount of base class data in advance unlike the image recognition field. Therefore, conventional few-shot learning methods are difficult to apply in underwater acoustic target recognition. In this report, following advanced self-supervised learning frameworks, a learning framework for underwater acoustic target recognition model with few samples is proposed. Meanwhile, a semi-supervised fine-tuning method is proposed to improve the fine-tuning performance by mining and labeling partial unlabeled samples based on the similarity of deep features. A set of small sample datasets with different amounts of labeled data are constructed, and the performance baselines of four underwater acoustic target recognition models are established based on these datasets. Compared with the baselines, using the proposed framework effectively improves the recognition effect of four models. Especially for the joint model, the recognition accuracy has increased by 2.04\% to 12.14\% compared with the baselines. The model performance on only 10 percent of the labeled data can exceed that on the full dataset, effectively reducing the dependence of model on the number of labeled samples. The problem of lack of labeled samples in underwater acoustic target recognition is alleviated.},
	pages = {17502},
	number = {1},
	journaltitle = {Scientific Reports},
	shortjournal = {Sci Rep},
	author = {Tian, Shengzhao and Bai, Di and Zhou, Junlin and Fu, Yan and Chen, Duanbing},
	urldate = {2024-10-10},
	date = {2023-10-16},
	langid = {english},
	note = {3 citations (Semantic Scholar/{DOI}) [2024-10-15]
3 citations (Crossref) [2024-10-14]},
}

@article{wang_underwater_2023,
	title = {An Underwater Acoustic Target Recognition Method Based on {AMNet}},
	volume = {20},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {1545-598X, 1558-0571},
	url = {https://ieeexplore.ieee.org/document/10012335/},
	doi = {10.1109/LGRS.2023.3235659},
	pages = {1--5},
	journaltitle = {{IEEE} Geoscience and Remote Sensing Letters},
	shortjournal = {{IEEE} Geosci. Remote Sensing Lett.},
	author = {Wang, Biao and Zhang, Wei and Zhu, Yunan and Wu, Chengxi and Zhang, Shizhen},
	urldate = {2024-08-06},
	date = {2023},
	note = {16 citations (Semantic Scholar/{DOI}) [2024-10-15]
8 citations (Crossref) [2024-10-14]},
	keywords = {Private dataset, {ShipsEar}},
}

@article{wang_self-supervised_2023,
	title = {Self-Supervised Pre-Training Joint Framework: Assisting Lightweight Detection Network for Underwater Object Detection},
	volume = {11},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2077-1312},
	url = {https://www.mdpi.com/2077-1312/11/3/604},
	doi = {10.3390/jmse11030604},
	shorttitle = {Self-Supervised Pre-Training Joint Framework},
	abstract = {In the computer vision field, underwater object detection has been a challenging task. Due to the attenuation of light in a medium and the scattering of light by suspended particles in water, underwater optical images often face the problems of color distortion and target feature blurring, which greatly affect the detection accuracy of underwater object detection. Although deep learning-based algorithms have achieved state-of-the-art results in the field of object detection, most of them cannot be applied to practice because of the limited computing capacity of a low-power processor embedded in unmanned underwater vehicles. This paper proposes a lightweight underwater object detection network based on the {YOLOX} model called {LUO}-{YOLOX}. A novel weighted ghost-{CSPDarknet} and simplified {PANet} were used in {LUO}-{YOLOX} to reduce the parameters of the whole model. Moreover, aiming to solve the problems of color distortion and unclear features of targets in underwater images, this paper proposes an efficient self-supervised pre-training joint framework based on underwater auto-encoder transformation ({UAET}). After the end-to-end pre-training process with the self-supervised pre-training joint framework, the backbone of the object detection network can extract more essential and robust features from degradation images when retrained on underwater datasets. Numerous experiments on the {URPC}2021 and detecting underwater objects ({DUO}) datasets verify the performance of our proposed method. Our work can assist unmanned underwater vehicles to perform underwater object detection tasks more accurately.},
	pages = {604},
	number = {3},
	journaltitle = {Journal of Marine Science and Engineering},
	shortjournal = {{JMSE}},
	author = {Wang, Zhuo and Chen, Haojie and Qin, Hongde and Chen, Qin},
	urldate = {2024-06-20},
	date = {2023-03-13},
	langid = {english},
	note = {10 citations (Semantic Scholar/{DOI}) [2024-10-15]
8 citations (Crossref) [2024-10-14]},
	keywords = {Initial reading list},
}

@article{wu_vfr_2023,
	title = {{VFR}: The Underwater Acoustic Target Recognition Using Cross-Domain Pre-Training with {FBank} Fusion Features},
	volume = {11},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2077-1312},
	url = {https://www.mdpi.com/2077-1312/11/2/263},
	doi = {10.3390/jmse11020263},
	shorttitle = {{VFR}},
	abstract = {Underwater acoustic target recognition is a hot research area in acoustic signal processing. With the development of deep learning, feature extraction and neural network computation have become two major steps of recognition. Due to the complexity of the marine environment, traditional feature extraction cannot express the characteristics of the targets well. In this paper, we propose an underwater acoustic target recognition approach named {VFR}. {VFR} adopts a novel feature extraction method by fusing three-dimensional {FBank} features, and inputs the extracted features into a residual network, instead of the classical {CNN} network, plus cross-domain pre-training to perform target recognition. The experimental results show that {VFR} achieves 98.5\% recognition accuracy on the randomly divided {ShipsEar} dataset and 93.8\% on the time-divided dataset, respectively, which are better than state-of-the-art results.},
	pages = {263},
	number = {2},
	journaltitle = {Journal of Marine Science and Engineering},
	shortjournal = {{JMSE}},
	author = {Wu, Ji and Li, Peng and Wang, Yongxian and Lan, Qiang and Xiao, Wenbin and Wang, Zhenghua},
	urldate = {2024-10-10},
	date = {2023-01-23},
	langid = {english},
	note = {7 citations (Semantic Scholar/{DOI}) [2024-10-15]
8 citations (Crossref) [2024-10-14]},
}

@inproceedings{xie_guiding_2023,
	location = {Limerick, Ireland},
	title = {Guiding the underwater acoustic target recognition with interpretable contrastive learning},
	rights = {https://doi.org/10.15223/policy-029},
	isbn = {9798350332261},
	url = {https://ieeexplore.ieee.org/document/10244447/},
	doi = {10.1109/OCEANSLimerick52467.2023.10244447},
	eventtitle = {{OCEANS} 2023 - Limerick},
	pages = {1--6},
	booktitle = {{OCEANS} 2023 - Limerick},
	publisher = {{IEEE}},
	author = {Xie, Yuan and Ren, Jiawei and Xu, Ji},
	urldate = {2024-10-10},
	date = {2023-06-05},
	note = {4 citations (Semantic Scholar/{DOI}) [2024-10-15]
1 citations (Crossref) [2024-10-14]},
}

@article{xie_data_2023,
	title = {Data augmentation and deep neural network classification based on ship radiated noise},
	volume = {10},
	issn = {2296-7745},
	url = {https://www.frontiersin.org/articles/10.3389/fmars.2023.1113224/full},
	doi = {10.3389/fmars.2023.1113224},
	abstract = {Introduction
              Various types of ships sail at sea, and identifying maritime ship types through shipradiated noise is one of the tasks of ocean observation. The ocean environment is complex and changeable, such rapid environmental changes underline the difficulties of obtaining a huge amount of samples. Meanwhile, the length of each sample has a decisive influence on the classification results, but there is no universal sampling length selection standard.
            
            
              Methods
              This study proposes an effective framework for ship-radiated noise classification. The framework includes: i) A comprehensive judgment method based on multiple features for sample length selecting. ii) One-dimensional deep convolution generative adversarial network (1-{DDCGAN}) model to augment the training datasets for small sample problem. iii) One-dimensional convolution neural network ({CNN}) trained by generated data and real data for ship-radiated noise classification. On this basis, a onedimensional residual network ({ResNet}) is designed to improve classification accuracy.
            
            
              Results
              Experiments are performed to verify the proposed framework using public datasets. After data augmentation, statistical parameters are used to measure the similarity between the original samples and the generated samples. Then, the generated samples are integrated into the training set. The convergence speed of the network is clearly accelerated, and the classification accuracy is significantly improved in the one-dimensional {CNN} and {ResNet}.
            
            
              Discussion
              In this study, we propose an effective framework for the lack of scientific sample length selection and lack of sample number in the classification of ship-radiated noise, but there aret still some problems: high complexity, structural redundancy, poor adaptability, and so on. They are also long-standing problems in this field that needs to be solved urgently.},
	pages = {1113224},
	journaltitle = {Frontiers in Marine Science},
	shortjournal = {Front. Mar. Sci.},
	author = {Xie, Zhuofan and Lin, Rongbin and Wang, Lingzhe and Zhang, Anmin and Lin, Jiaqing and Tang, Xiaoda},
	urldate = {2024-10-10},
	date = {2023-02-07},
	note = {4 citations (Semantic Scholar/{DOI}) [2024-10-15]
4 citations (Crossref) [2024-10-14]},
}

@article{xu_self-supervised_2023,
	title = {Self-supervised learning–based underwater acoustical signal classification via mask modeling},
	volume = {154},
	issn = {0001-4966},
	url = {https://pubs.aip.org/jasa/article/154/1/5/2901063/Self-supervised-learning-based-underwater},
	doi = {10.1121/10.0019937},
	abstract = {The classification of underwater acoustic signals has garnered a great deal of attention in recent years due to its potential applications in military and civilian contexts. While deep neural networks have emerged as the preferred method for this task, the representation of the signals plays a crucial role in determining the performance of the classification. However, the representation of underwater acoustic signals remains an under-explored area. In addition, the annotation of large-scale datasets for the training of deep networks is a challenging and expensive task. To tackle these challenges, we propose a novel self-supervised representation learning method for underwater acoustic signal classification. Our approach consists of two stages: a pretext learning stage using unlabeled data and a downstream fine-tuning stage using a small amount of labeled data. The pretext learning stage involves randomly masking the log Mel spectrogram and reconstructing the masked part using the Swin Transformer architecture. This allows us to learn a general representation of the acoustic signal. Our method achieves a classification accuracy of 80.22\% on the {DeepShip} dataset, outperforming or matching previous competitive methods. Furthermore, our classification method demonstrates good performance in low signal-to-noise ratio or few-shot settings.},
	pages = {5--15},
	number = {1},
	journaltitle = {The Journal of the Acoustical Society of America},
	author = {Xu, Kele and Xu, Qisheng and You, Kang and Zhu, Boqing and Feng, Ming and Feng, Dawei and Liu, Bo},
	urldate = {2024-06-20},
	date = {2023-07-01},
	langid = {english},
	note = {7 citations (Semantic Scholar/{DOI}) [2024-10-15]
8 citations (Crossref) [2024-10-14]},
	keywords = {{DeepShip}, Initial reading list},
}

@article{yang_lightweight_2023,
	title = {A Lightweight Network Model Based on an Attention Mechanism for Ship-Radiated Noise Classification},
	volume = {11},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2077-1312},
	url = {https://www.mdpi.com/2077-1312/11/2/432},
	doi = {10.3390/jmse11020432},
	abstract = {Recently, deep learning has been widely used in ship-radiated noise classification. To improve classification efficiency, avoiding high computational costs is an important research direction in ship-radiated noise classification. We propose a lightweight squeeze and excitation residual network 10 ({LW}-{SEResNet}10). In ablation experiments of {LW}-{SEResNet}10, the use of {ResNet}10 instead of {ResNet}18 reduced 56.1\% of parameters, while the accuracy is equivalent to {ResNet}18. The improved accuracy indicates that the {ReLU}6 enhanced the model stability, and an attention mechanism captured the channel dependence. The {ReLU}6 activation function does not introduce additional parameters, and the number of parameters introduced by the attention mechanism accounts for 0.2‰ of the model parameters. The 3D dynamic {MFCC} feature performs better than {MFCC}, Mel-spectrogram, 3D dynamic Mel-spectrogram, and {CQT}. Moreover, the {LW}-{SEResNet}10 model is also compared with {ResNet} and two classic lightweight models. The experimental results show that the proposed model achieves higher classification accuracy and is lightweight in terms of not only the model parameters, but also the time consumption. {LW}-{SEResNet}10 also outperforms the state-of-the-art model {CRNN}-9 by 3.1\% and {ResNet} by 3.4\% and has the same accuracy as {AudioSet} pretrained {STM}, which achieves the trade-off between accuracy and model efficiency.},
	pages = {432},
	number = {2},
	journaltitle = {Journal of Marine Science and Engineering},
	shortjournal = {{JMSE}},
	author = {Yang, Shuang and Xue, Lingzhi and Hong, Xi and Zeng, Xiangyang},
	urldate = {2024-08-06},
	date = {2023-02-16},
	langid = {english},
	note = {12 citations (Semantic Scholar/{DOI}) [2024-10-15]
13 citations (Crossref) [2024-10-14]},
	keywords = {{ShipsEar}},
}

@article{yao_underwater_2023,
	title = {Underwater Acoustic Target Recognition Based on Data Augmentation and Residual {CNN}},
	volume = {12},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2079-9292},
	url = {https://www.mdpi.com/2079-9292/12/5/1206},
	doi = {10.3390/electronics12051206},
	abstract = {In the field of underwater acoustic recognition, machine learning methods rely on a large number of datasets to achieve high accuracy, while the actual collected signal samples are often very scarce, which has a great impact on the recognition performance. This paper presents a recognition method of an underwater acoustic target by the data augmentation technique and the residual convolutional neural network ({CNN}) model, which is used to expand training samples to improve recognition performance. As a representative model in residual {CNN}, the {ResNet}18 model is used for recognition. The whole process mainly includes mel-frequency cepstral coefficient ({MFCC}) feature extraction, data augmentation processing, and {ResNet}18 model recognition. On the base of the traditional data augmentation, this study used the deep convolutional generative adversarial network ({DCGAN}) model to realize the expansion of underwater acoustic samples and compared the recognition performance of support vector machine ({SVM}), common {CNN}, {VGG}19, and {ResNet}18. The recognition results of the {MFCC}, constant Q transform ({CQT}), and low-frequency analyzer and recorder ({LOFAR}) spectrum were also analyzed and compared. Experimental results showed that the recognition accuracy of the {MFCC} feature was better than that of other features at the same method, and using the data augmentation method could obviously improve the recognition performance. Moreover, the recognition performance of {ResNet}18 using data enhancement technology was better than that of other models, which was due to the combination of the data expansion advantage of data augmentation technology and the deep feature extracting ability of the residual {CNN} model. In addition, although this method was used for ship recognition in this paper, it is not limited to this. This method is also applicable to other target voice recognition, such as natural sound and underwater voice biometrics.},
	pages = {1206},
	number = {5},
	journaltitle = {Electronics},
	shortjournal = {Electronics},
	author = {Yao, Qihai and Wang, Yong and Yang, Yixin},
	urldate = {2024-08-06},
	date = {2023-03-02},
	langid = {english},
	note = {12 citations (Semantic Scholar/{DOI}) [2024-10-15]
10 citations (Crossref) [2024-10-14]},
	keywords = {{DeepShip}},
}

@article{yin_research_2023,
	title = {Research on the line spectrum denoising detection based on multi-scale feature autoencoder},
	volume = {2517},
	issn = {1742-6588, 1742-6596},
	url = {https://iopscience.iop.org/article/10.1088/1742-6596/2517/1/012006},
	doi = {10.1088/1742-6596/2517/1/012006},
	abstract = {Abstract
            Line spectrum detection is an important research direction in the field of underwater acoustic target detection. The relevant features of the target can be obtained by using the target line spectrum in the signal power spectrogram, but the radiated noise signal is susceptible to the influence of external noise, which degrades the quality of the target line spectrum and thus affects the complete extraction of the line spectrum. A denoising method is proposed in this paper based on deep learning network architecture and classical filter to extract the target line spectrum from the power spectrogram with strong background noise while maintaining the continuity of the line spectrum and improving the efficiency of line spectrum detection. The simulated signal power spectrogram is used to train the multi-scale feature autoencoder to remove different scale noise interference in the line spectrum part and then pass the morphological attribute filter to remove the background noise further and keep the line spectrum continuity. The experimental analysis of the measured fishing vessel noise signal and the simulated signal shows that the algorithm proposed in this paper can effectively remove the line spectrum noise interference, improve the line spectrum signal-to-noise ratio quality, and realize the effective detection of the line spectrum.},
	pages = {012006},
	number = {1},
	journaltitle = {Journal of Physics: Conference Series},
	shortjournal = {J. Phys.: Conf. Ser.},
	author = {Yin, Yaping and Dai, Weiguo and Zhang, Zongtang and Shi, Yanzi and Sun, Shilin},
	urldate = {2024-09-23},
	date = {2023-06-01},
	note = {0 citations (Semantic Scholar/{DOI}) [2024-10-15]
0 citations (Crossref) [2024-10-14]},
	keywords = {Denoising},
}

@article{zare_novel_2023,
	title = {A novel hybrid feature extraction approach of marine vessel signal via improved empirical mode decomposition and measuring complexity},
	volume = {271},
	issn = {00298018},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0029801823001117},
	doi = {10.1016/j.oceaneng.2023.113727},
	pages = {113727},
	journaltitle = {Ocean Engineering},
	shortjournal = {Ocean Engineering},
	author = {Zare, Mehdi and Nouri, Nowrouz Mohammad},
	urldate = {2024-10-10},
	date = {2023-03},
	langid = {english},
	note = {9 citations (Semantic Scholar/{DOI}) [2024-10-15]
8 citations (Crossref) [2024-10-14]},
}

@article{zhou_dbsa-net_2023,
	title = {{DBSA}-Net: Dual Branch Self-Attention Network for Underwater Acoustic Signal Denoising},
	volume = {31},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {2329-9290, 2329-9304},
	url = {https://ieeexplore.ieee.org/document/10122557/},
	doi = {10.1109/TASLP.2023.3275030},
	shorttitle = {{DBSA}-Net},
	pages = {1851--1865},
	journaltitle = {{IEEE}/{ACM} Transactions on Audio, Speech, and Language Processing},
	shortjournal = {{IEEE}/{ACM} Trans. Audio Speech Lang. Process.},
	author = {Zhou, Aolong and Zhang, Wen and Xu, Guojun and Li, Xiaoyong and Deng, Kefeng and Song, Junqiang},
	urldate = {2024-09-24},
	date = {2023},
	note = {4 citations (Semantic Scholar/{DOI}) [2024-10-15]
4 citations (Crossref) [2024-10-14]},
}

@inproceedings{zhou_weak_2023,
	location = {Xi'an, China},
	title = {A Weak Acoustic Signal Line-Spectrum Detection Method Based on Stochastic Resonance},
	rights = {https://doi.org/10.15223/policy-029},
	isbn = {9798350339994},
	url = {https://ieeexplore.ieee.org/document/10390708/},
	doi = {10.1109/ICICSP59554.2023.10390708},
	eventtitle = {2023 6th International Conference on Information Communication and Signal Processing ({ICICSP})},
	pages = {471--475},
	booktitle = {2023 6th International Conference on Information Communication and Signal Processing ({ICICSP})},
	publisher = {{IEEE}},
	author = {Zhou, Hanlu and Luo, Xinwei and Chen, Lu},
	urldate = {2024-08-13},
	date = {2023-09-23},
	note = {1 citations (Semantic Scholar/{DOI}) [2024-10-15]
1 citations (Crossref) [2024-10-14]},
}

@article{ahmad_deep_2024,
	title = {Deep Learning Based Classification of Underwater Acoustic Signals},
	volume = {235},
	issn = {18770509},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1877050924007828},
	doi = {10.1016/j.procs.2024.04.106},
	pages = {1115--1124},
	journaltitle = {Procedia Computer Science},
	shortjournal = {Procedia Computer Science},
	author = {Ahmad, Faiyaz and Ansari, Mohd Zeeshan and Anwar, Ramsha and Shahzad, Bushra and Ikram, Asma},
	urldate = {2024-06-24},
	date = {2024},
	langid = {english},
	note = {0 citations (Semantic Scholar/{DOI}) [2024-10-15]
0 citations (Crossref) [2024-10-14]},
	keywords = {{DeepShip}},
}

@article{aslam_underwater_2024,
	title = {Underwater sound classification using learning based methods: A review},
	volume = {255},
	issn = {09574174},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417424013654},
	doi = {10.1016/j.eswa.2024.124498},
	shorttitle = {Underwater sound classification using learning based methods},
	pages = {124498},
	journaltitle = {Expert Systems with Applications},
	shortjournal = {Expert Systems with Applications},
	author = {Aslam, Muhammad Azeem and Zhang, Lefang and Liu, Xin and Irfan, Muhammad and Xu, Yimei and Li, Na and Zhang, Ping and Jiangbin, Zheng and Yaan, Li},
	urldate = {2024-08-06},
	date = {2024-12},
	langid = {english},
	note = {1 citations (Semantic Scholar/{DOI}) [2024-10-15]
0 citations (Crossref) [2024-10-14]},
	keywords = {Review},
}

@misc{chandra_bayesian_2024,
	title = {Bayesian neural networks via {MCMC}: a Python-based tutorial},
	url = {http://arxiv.org/abs/2304.02595},
	doi = {10.48550/arXiv.2304.02595},
	shorttitle = {Bayesian neural networks via {MCMC}},
	abstract = {Bayesian inference provides a methodology for parameter estimation and uncertainty quantification in machine learning and deep learning methods. Variational inference and Markov Chain Monte-Carlo ({MCMC}) sampling methods are used to implement Bayesian inference. In the past three decades, {MCMC} sampling methods have faced some challenges in being adapted to larger models (such as in deep learning) and big data problems. Advanced proposal distributions that incorporate gradients, such as a Langevin proposal distribution, provide a means to address some of the limitations of {MCMC} sampling for Bayesian neural networks. Furthermore, {MCMC} methods have typically been constrained to statisticians and currently not well-known among deep learning researchers. We present a tutorial for {MCMC} methods that covers simple Bayesian linear and logistic models, and Bayesian neural networks. The aim of this tutorial is to bridge the gap between theory and implementation via coding, given a general sparsity of libraries and tutorials to this end. This tutorial provides code in Python with data and instructions that enable their use and extension. We provide results for some benchmark problems showing the strengths and weaknesses of implementing the respective Bayesian models via {MCMC}. We highlight the challenges in sampling multi-modal posterior distributions for the case of Bayesian neural networks and the need for further improvement of convergence diagnosis methods.},
	number = {{arXiv}:2304.02595},
	publisher = {{arXiv}},
	author = {Chandra, Rohitash and Chen, Royce and Simmons, Joshua},
	urldate = {2024-06-20},
	date = {2024-04-02},
	eprinttype = {arxiv},
	eprint = {2304.02595 [cs, stat]},
	note = {5 citations (Semantic Scholar/{arXiv}) [2024-10-15]},
	keywords = {Initial reading list},
}

@inproceedings{chen_hierarchical_2024,
	location = {Ikuta Japan},
	title = {A Hierarchical Underwater Acoustic Target Recognition Method Based on Transformer and Transfer Learning},
	isbn = {9798400716829},
	url = {https://dl.acm.org/doi/10.1145/3655755.3655758},
	doi = {10.1145/3655755.3655758},
	eventtitle = {{IVSP} 2024: 2024 6th International Conference on Image, Video and Signal Processing},
	pages = {16--24},
	booktitle = {2024 6th International Conference on Image, Video and Signal Processing},
	publisher = {{ACM}},
	author = {Chen, Lu and Luo, Xinwei and Zhou, Hanlu},
	urldate = {2024-08-13},
	date = {2024-03-14},
	langid = {english},
	note = {0 citations (Semantic Scholar/{DOI}) [2024-10-15]
0 citations (Crossref) [2024-10-14]},
	keywords = {{DeepShip}, {ShipsEar}},
}

@article{chen_ship-radiated_2024,
	title = {A ship-radiated noise classification method based on domain knowledge embedding and attention mechanism},
	volume = {127},
	issn = {09521976},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S095219762301504X},
	doi = {10.1016/j.engappai.2023.107320},
	pages = {107320},
	journaltitle = {Engineering Applications of Artificial Intelligence},
	shortjournal = {Engineering Applications of Artificial Intelligence},
	author = {Chen, Lu and Luo, Xinwei and Zhou, Hanlu},
	urldate = {2024-08-06},
	date = {2024-01},
	langid = {english},
	note = {2 citations (Semantic Scholar/{DOI}) [2024-10-15]
4 citations (Crossref) [2024-10-14]},
	keywords = {{DeepShip}, {ShipsEar}},
}

@misc{du_qiandaoear22_2024,
	title = {{QiandaoEar}22: A high quality noise dataset for identifying specific ship from multiple underwater acoustic targets using ship-radiated noise},
	url = {http://arxiv.org/abs/2406.04354},
	shorttitle = {{QiandaoEar}22},
	abstract = {Target identification of ship-radiated noise is a crucial area in underwater target recognition. However, there is currently a lack of multi-target ship datasets that accurately represent real-world underwater acoustic conditions. To tackle this issue, we conducted experimental data acquisition, resulting in the release of {QiandaoEar}22 {\textbackslash}textemdash a comprehensive underwater acoustic multi-target dataset. This dataset encompasses 9 hours and 28 minutes of real-world ship-radiated noise data and 21 hours and 58 minutes of background noise data. To demonstrate the availability of {QiandaoEar}22, we executed two experimental tasks. The first task focuses on assessing the presence of ship-radiated noise, while the second task involves identifying specific ships within the recognized targets in the multi-ship mixed data. In the latter task, we extracted eight features from the data and employed six deep learning networks for classification, aiming to evaluate and compare the performance of various features and networks. The experimental results reveal that ship-radiated noise can be successfully identified from background noise in over 99{\textbackslash}\% of cases. Additionally, for the specific identification of individual ships, the optimal recognition accuracy achieves 99.56{\textbackslash}\%. Finally, based on our findings, we provide advice on selecting appropriate features and deep learning networks, which may offer valuable insights for related research. Our work not only establishes a benchmark for algorithm evaluation but also inspires the development of innovative methods to enhance {UATD} and {UATR} systems.},
	number = {{arXiv}:2406.04354},
	publisher = {{arXiv}},
	author = {Du, Xiaoyang and Hong, Feng},
	urldate = {2024-09-10},
	date = {2024-05-15},
	eprinttype = {arxiv},
	eprint = {2406.04354 [eess]},
	note = {0 citations (Semantic Scholar/{arXiv}) [2024-10-15]},
}

@misc{gao_underwater_2024,
	title = {Underwater Acoustic Signal Denoising Algorithms: A Survey of the State-of-the-art},
	url = {http://arxiv.org/abs/2407.13264},
	doi = {10.48550/arXiv.2407.13264},
	shorttitle = {Underwater Acoustic Signal Denoising Algorithms},
	abstract = {This paper comprehensively reviews recent advances in underwater acoustic signal denoising, an area critical for improving the reliability and clarity of underwater communication and monitoring systems. Despite significant progress in the field, the complex nature of underwater environments poses unique challenges that complicate the denoising process. We begin by outlining the fundamental challenges associated with underwater acoustic signal processing, including signal attenuation, noise variability, and the impact of environmental factors. The review then systematically categorizes and discusses various denoising algorithms, such as conventional, decomposition-based, and learning-based techniques, highlighting their applications, advantages, and limitations. Evaluation metrics and experimental datasets are also reviewed. The paper concludes with a list of open questions and recommendations for future research directions, emphasizing the need for developing more robust denoising techniques that can adapt to the dynamic underwater acoustic environment.},
	number = {{arXiv}:2407.13264},
	publisher = {{arXiv}},
	author = {Gao, Ruobin and Liang, Maohan and Dong, Heng and Luo, Xuewen and Suganthan, P. N.},
	urldate = {2024-09-24},
	date = {2024-07-18},
	eprinttype = {arxiv},
	eprint = {2407.13264 [cs, eess]},
	note = {0 citations (Semantic Scholar/{arXiv}) [2024-10-15]
0 citations (Semantic Scholar/{DOI}) [2024-10-15]},
}

@article{hummel_survey_2024,
	title = {A survey on machine learning in ship radiated noise},
	volume = {298},
	issn = {00298018},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0029801824005894},
	doi = {10.1016/j.oceaneng.2024.117252},
	pages = {117252},
	journaltitle = {Ocean Engineering},
	shortjournal = {Ocean Engineering},
	author = {Hummel, Hilde I. and Van Der Mei, Rob and Bhulai, Sandjai},
	urldate = {2024-10-08},
	date = {2024-04},
	langid = {english},
	note = {3 citations (Semantic Scholar/{DOI}) [2024-10-15]
3 citations (Crossref) [2024-10-14]},
	keywords = {Review},
}

@book{mccorduck_machines_2018,
	location = {Boca Raton London New York},
	title = {Machines who think: a personal inquiry into the history and prospects of artificial intelligence},
	isbn = {978-1-56881-205-2},
	series = {An A K Peters book},
	shorttitle = {Machines who think},
	pagetotal = {565},
	publisher = {{CRC} Press},
	author = {{McCorduck}, Pamela},
	date = {2018},
}

@article{li_weak_2024,
	title = {Weak fluctuating spectral line reconstruction using deep learning},
	volume = {2718},
	issn = {1742-6588, 1742-6596},
	url = {https://iopscience.iop.org/article/10.1088/1742-6596/2718/1/012085},
	doi = {10.1088/1742-6596/2718/1/012085},
	abstract = {Abstract
            The detection of weak fluctuating spectral lines emitted by underwater and surface vehicles poses a challenging problem for passive sonar system. Therefore, a spectral line reconstruction algorithm based on deep learning called the {DEDAN}, is proposed. The {DEDAN} learns the time-frequency correlation of spectral lines through end-to-end training and then reconstructs the spatial location of spectral lines. Simulation results show that the {DEDAN} is robust to ambient noise, and outperforms other reconstruction algorithms at a mixed signal-to-noise ratio as low as -22 {dB} to -26 {dB}. Its reconstruction performance is also verified by the measured South China Sea data.},
	pages = {012085},
	number = {1},
	journaltitle = {Journal of Physics: Conference Series},
	shortjournal = {J. Phys.: Conf. Ser.},
	author = {Li, Zhen and Guo, Junyuan and Wang, Xiaohan},
	urldate = {2024-08-13},
	date = {2024-03-01},
	note = {0 citations (Semantic Scholar/{DOI}) [2024-10-15]
0 citations (Crossref) [2024-10-14]},
}

@article{song_method_2024,
	title = {Method of Underwater Acoustic Signal Denoising Based on Dual-Path Transformer Network},
	volume = {12},
	rights = {https://creativecommons.org/licenses/by/4.0/legalcode},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/9963926/},
	doi = {10.1109/ACCESS.2022.3224752},
	pages = {81483--81494},
	journaltitle = {{IEEE} Access},
	shortjournal = {{IEEE} Access},
	author = {Song, Yongqiang and Liu, Feng and Shen, Tongsheng},
	urldate = {2024-09-24},
	date = {2024},
	note = {4 citations (Semantic Scholar/{DOI}) [2024-10-15]
3 citations (Crossref) [2024-10-14]},
}

@article{tang_deep_2024,
	title = {Deep Learning Based Underwater Acoustic Target Recognition: Introduce a Recent Temporal 2D Modeling Method},
	volume = {24},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/24/5/1633},
	doi = {10.3390/s24051633},
	shorttitle = {Deep Learning Based Underwater Acoustic Target Recognition},
	abstract = {In recent years, the application of deep learning models for underwater target recognition has become a popular trend. Most of these are pure 1D models used for processing time-domain signals or pure 2D models used for processing time-frequency spectra. In this paper, a recent temporal 2D modeling method is introduced into the construction of ship radiation noise classification models, combining 1D and 2D. This method is based on the periodic characteristics of time-domain signals, shaping them into 2D signals and discovering long-term correlations between sampling points through 2D convolution to compensate for the limitations of 1D convolution. Integrating this method with the current state-of-the-art model structure and using samples from the Deepship database for network training and testing, it was found that this method could further improve the accuracy (0.9\%) and reduce the parameter count (30\%), providing a new option for model construction and optimization. Meanwhile, the effectiveness of training models using time-domain signals or time-frequency representations has been compared, finding that the model based on time-domain signals is more sensitive and has a smaller storage footprint (reduced to 30\%), whereas the model based on time-frequency representation can achieve higher accuracy (1–2\%).},
	pages = {1633},
	number = {5},
	journaltitle = {Sensors},
	shortjournal = {Sensors},
	author = {Tang, Jun and Gao, Wenbo and Ma, Enxue and Sun, Xinmiao and Ma, Jinying},
	urldate = {2024-08-06},
	date = {2024-03-02},
	langid = {english},
	note = {0 citations (Semantic Scholar/{DOI}) [2024-10-15]
0 citations (Crossref) [2024-10-14]},
	keywords = {{DeepShip}},
}

@article{wang_underwater_2024,
	title = {Underwater acoustic signal classification based on a spatial–temporal fusion neural network},
	volume = {11},
	issn = {2296-7745},
	url = {https://www.frontiersin.org/articles/10.3389/fmars.2024.1331717/full},
	doi = {10.3389/fmars.2024.1331717},
	abstract = {In this paper, a novel fusion network for automatic modulation classification ({AMC}) is proposed in underwater acoustic communication, which consists of a Transformer and depth-wise convolution ({DWC}) network. Transformer breaks the limitation of sequential signal input and establishes the connection between different modulations in a parallel manner. Its attention mechanism can improve the modulation recognition ability by focusing on the key information. {DWC} is regularly inserted in the Transformer network to constitute a spatial–temporal structure, which can enhance the classification results at lower signal-to-noise ratios ({SNRs}). The proposed method can obtain more deep features of underwater acoustic signals. The experiment results achieve an average of 92.1\% at −4 {dB} ≤ {SNR} ≤ 0 {dB}, which exceed other state-of-the-art neural networks.},
	pages = {1331717},
	journaltitle = {Frontiers in Marine Science},
	shortjournal = {Front. Mar. Sci.},
	author = {Wang, Yan and Xiao, Jing and Cheng, Xiao and Wei, Qiang and Tang, Ning},
	urldate = {2024-08-06},
	date = {2024-03-12},
	note = {0 citations (Semantic Scholar/{DOI}) [2024-10-15]
0 citations (Crossref) [2024-10-14]},
}

@article{xu_self-supervised_2024,
	title = {Self-Supervised Learning-For Underwater Acoustic Signal Classification With Mixup},
	volume = {17},
	rights = {https://creativecommons.org/licenses/by-nc-nd/4.0/},
	issn = {1939-1404, 2151-1535},
	url = {https://ieeexplore.ieee.org/document/10288071/},
	doi = {10.1109/JSTARS.2023.3325921},
	pages = {3530--3542},
	journaltitle = {{IEEE} Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	shortjournal = {{IEEE} J. Sel. Top. Appl. Earth Observations Remote Sensing},
	author = {Xu, Qisheng and Jiang, Jingfei and Xu, Kele and Dou, Yong and Gao, Caili and Zhu, Boqing and You, Kang and Zhu, Qian},
	urldate = {2024-08-06},
	date = {2024},
	note = {3 citations (Semantic Scholar/{DOI}) [2024-10-15]
2 citations (Crossref) [2024-10-14]},
	keywords = {{DeepShip}},
}

@article{yan_lightweight_2024,
	title = {A Lightweight Network Based on Multi-Scale Asymmetric Convolutional Neural Networks with Attention Mechanism for Ship-Radiated Noise Classification},
	volume = {12},
	rights = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2077-1312},
	url = {https://www.mdpi.com/2077-1312/12/1/130},
	doi = {10.3390/jmse12010130},
	abstract = {Ship-radiated noise classification is critical in ocean acoustics. Recently, the feature extraction method combined with time–frequency spectrograms and convolutional neural networks ({CNNs}) has effectively described the differences between various underwater targets. However, many existing {CNNs} are challenging to apply to embedded devices because of their high computational costs. This paper introduces a lightweight network based on multi-scale asymmetric {CNNs} with an attention mechanism ({MA}-{CNN}-A) for ship-radiated noise classification. Specifically, according to the multi-resolution analysis relying on the relationship between multi-scale convolution kernels and feature maps, {MA}-{CNN}-A can autonomously extract more fine-grained multi-scale features from the time–frequency domain. Meanwhile, the {MA}-{CNN}-A maintains its light weight by employing asymmetric convolutions to balance accuracy and efficiency. The number of parameters introduced by the attention mechanism only accounts for 0.02‰ of the model parameters. Experiments on the {DeepShip} dataset demonstrate that the {MA}-{CNN}-A outperforms some state-of-the-art networks with a recognition accuracy of 98.2\% and significantly decreases the parameters. Compared with the {CNN} based on three-scale square convolutions, our method has a 68.1\% reduction in parameters with improved recognition accuracy. The results of ablation explorations prove that the improvements benefit from asymmetric convolution, multi-scale block, and attention mechanism. Additionally, {MA}-{CNN}-A shows a robust performance against various interferences.},
	pages = {130},
	number = {1},
	journaltitle = {Journal of Marine Science and Engineering},
	shortjournal = {{JMSE}},
	author = {Yan, Chenhong and Yan, Shefeng and Yao, Tianyi and Yu, Yang and Pan, Guang and Liu, Lu and Wang, Mou and Bai, Jisheng},
	urldate = {2024-08-06},
	date = {2024-01-09},
	langid = {english},
	note = {1 citations (Semantic Scholar/{DOI}) [2024-10-15]
0 citations (Crossref) [2024-10-14]},
	keywords = {{DeepShip}},
}

@article{yang_underwater_2024,
	title = {Underwater acoustic signal denoising based on sparse {TQWT} and wavelet thresholding},
	volume = {153},
	issn = {10512004},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1051200424002264},
	doi = {10.1016/j.dsp.2024.104601},
	pages = {104601},
	journaltitle = {Digital Signal Processing},
	shortjournal = {Digital Signal Processing},
	author = {Yang, Jirui and Yan, Shefeng and Mao, {LinLin} and Sui, Zeping and Wang, Wei and Zeng, Di},
	urldate = {2024-09-24},
	date = {2024-10},
	langid = {english},
	note = {0 citations (Semantic Scholar/{DOI}) [2024-10-15]
0 citations (Crossref) [2024-10-14]},
}

@article{yao_underwater_2024,
	title = {Underwater acoustic target recognition based on Hilbert–Huang transform and data augmentation},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {0018-9251, 1557-9603, 2371-9877},
	url = {https://ieeexplore.ieee.org/document/10568336/},
	doi = {10.1109/TAES.2024.3417435},
	pages = {1--19},
	journaltitle = {{IEEE} Transactions on Aerospace and Electronic Systems},
	shortjournal = {{IEEE} Trans. Aerosp. Electron. Syst.},
	author = {Yao, Qihai and Wang, Yong and Yang, Yixin},
	urldate = {2024-08-06},
	date = {2024},
	note = {0 citations (Semantic Scholar/{DOI}) [2024-10-15]
0 citations (Crossref) [2024-10-14]},
	keywords = {{DeepShip}},
}

@article{yao_underwater_2024-1,
	title = {Underwater Acoustic Target Classification Using Scattering Transform with Small Sample Size},
	rights = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
	issn = {1530-437X, 1558-1748, 2379-9153},
	url = {https://ieeexplore.ieee.org/document/10582822/},
	doi = {10.1109/JSEN.2024.3419434},
	pages = {1--1},
	journaltitle = {{IEEE} Sensors Journal},
	shortjournal = {{IEEE} Sensors J.},
	author = {Yao, Xiling and Liu, Shumin and Chen, Jie and Yan, Shefeng and Ji, Fei and Liu, Hongwei and Chen, Jingdong},
	urldate = {2024-08-06},
	date = {2024},
	note = {0 citations (Semantic Scholar/{DOI}) [2024-10-15]
0 citations (Crossref) [2024-10-14]},
	keywords = {{DeepShip}, {ShipsEar}},
}

@article{zhang_new_2024,
	title = {A New Method for Denoising Underwater Acoustic Signals Based on {EEMD}, Correlation Coefficient, Permutation Entropy, and Wavelet Threshold Denoising},
	volume = {23},
	issn = {1671-9433, 1993-5048},
	url = {https://link.springer.com/10.1007/s11804-024-00386-6},
	doi = {10.1007/s11804-024-00386-6},
	pages = {222--237},
	number = {1},
	journaltitle = {Journal of Marine Science and Application},
	shortjournal = {J. Marine. Sci. Appl.},
	author = {Zhang, Yuyan and Yang, Zhixia and Du, Xiaoli and Luo, Xiaoyuan},
	urldate = {2024-09-24},
	date = {2024-03},
	langid = {english},
	note = {0 citations (Semantic Scholar/{DOI}) [2024-10-15]
0 citations (Crossref) [2024-10-14]},
}

@article{selvaraju_grad-cam_2016,
	title = {Grad-{CAM}: Visual Explanations from Deep Networks via Gradient-based Localization},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/1610.02391},
	doi = {10.48550/ARXIV.1610.02391},
	shorttitle = {Grad-{CAM}},
	abstract = {We propose a technique for producing "visual explanations" for decisions from a large class of {CNN}-based models, making them more transparent. Our approach - Gradient-weighted Class Activation Mapping (Grad-{CAM}), uses the gradients of any target concept, flowing into the final convolutional layer to produce a coarse localization map highlighting important regions in the image for predicting the concept. Grad-{CAM} is applicable to a wide variety of {CNN} model-families: (1) {CNNs} with fully-connected layers, (2) {CNNs} used for structured outputs, (3) {CNNs} used in tasks with multimodal inputs or reinforcement learning, without any architectural changes or re-training. We combine Grad-{CAM} with fine-grained visualizations to create a high-resolution class-discriminative visualization and apply it to off-the-shelf image classification, captioning, and visual question answering ({VQA}) models, including {ResNet}-based architectures. In the context of image classification models, our visualizations (a) lend insights into their failure modes, (b) are robust to adversarial images, (c) outperform previous methods on localization, (d) are more faithful to the underlying model and (e) help achieve generalization by identifying dataset bias. For captioning and {VQA}, we show that even non-attention based models can localize inputs. We devise a way to identify important neurons through Grad-{CAM} and combine it with neuron names to provide textual explanations for model decisions. Finally, we design and conduct human studies to measure if Grad-{CAM} helps users establish appropriate trust in predictions from models and show that Grad-{CAM} helps untrained users successfully discern a 'stronger' nodel from a 'weaker' one even when both make identical predictions. Our code is available at https://github.com/ramprs/grad-cam/, along with a demo at http://gradcam.cloudcv.org, and a video at youtu.be/{COjUB}9Izk6E.},
	author = {Selvaraju, Ramprasaath R. and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
	urldate = {2024-09-23},
	date = {2016},
	note = {9999 citations (Semantic Scholar/{arXiv}) [2024-10-14]
Publisher: {arXiv}
Version Number: 4},
}

@article{hinton_reducing_2006,
	title = {Reducing the Dimensionality of Data with Neural Networks},
	volume = {313},
	issn = {0036-8075, 1095-9203},
	url = {https://www.science.org/doi/10.1126/science.1127647},
	doi = {10.1126/science.1127647},
	abstract = {High-dimensional data can be converted to low-dimensional codes by training a multilayer neural network with a small central layer to reconstruct high-dimensional input vectors. Gradient descent can be used for fine-tuning the weights in such “autoencoder” networks, but this works well only if the initial weights are close to a good solution. We describe an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data.},
	pages = {504--507},
	number = {5786},
	journaltitle = {Science},
	shortjournal = {Science},
	author = {Hinton, G. E. and Salakhutdinov, R. R.},
	urldate = {2024-09-16},
	date = {2006-07-28},
	langid = {english},
	note = {14115 citations (Crossref) [2024-10-14]},
}

@online{carnegie_mellon_university_human_2001,
	title = {Human and Machine Minds},
	url = {http://shelf1.library.cmu.edu/IMLS/MindModels/humanandmachine.html},
	titleaddon = {Human and Machine Minds},
	author = {{Carnegie Mellon University}},
	urldate = {2024-10-14},
	date = {2001-10},
}

@book{russell_artificial_2021,
	location = {Hoboken, {NJ}},
	edition = {Fourth Edition},
	title = {Artificial intelligence: a modern approach},
	isbn = {978-0-13-461099-3},
	series = {Pearson Series in Artificial Intelligence},
	shorttitle = {Artificial intelligence},
	abstract = {"Updated edition of popular textbook on Artificial Intelligence. This edition specific looks at ways of keeping artificial intelligence under control"--},
	pagetotal = {1115},
	publisher = {Pearson},
	author = {Russell, Stuart J. and Norvig, Peter},
	editora = {Chang, Ming-wei and Devlin, Jacob and Dragan, Anca and Forsyth, David and Goodfellow, Ian and Malik, Jitendra and Mansinghka, Vikash and Pearl, Judea and Wooldridge, Michael J.},
	editoratype = {collaborator},
	date = {2021},
}

@incollection{huang_oceanship_2024,
	location = {Singapore},
	title = {Oceanship: A Large-Scale Dataset for Underwater Audio Target Recognition},
	volume = {14865},
	isbn = {978-981-9755-90-5},
	url = {https://link.springer.com/10.1007/978-981-97-5591-2_40},
	shorttitle = {Oceanship},
	pages = {475--486},
	booktitle = {Advanced Intelligent Computing Technology and Applications},
	publisher = {Springer Nature Singapore},
	author = {Li, Zeyu and Xiang, Suncheng and Yu, Tong and Gao, Jingsheng and Ruan, Jiacheng and Hu, Yanping and Liu, Ting and Fu, Yuzhuo},
	editor = {Huang, De-Shuang and Zhang, Chuanlei and Chen, Wei},
	urldate = {2024-09-09},
	date = {2024},
	langid = {english},
	doi = {10.1007/978-981-97-5591-2_40},
	note = {Series Title: Lecture Notes in Computer Science},
}

@online{amick_how_2020,
	title = {How Submarine Sonarmen Tirelessly Hunt For Enemies They Can't Even See},
	url = {https://www.twz.com/35603/veteran-submariner-on-how-sonar-crews-tirelessly-hunt-enemies-they-cant-even-see},
	titleaddon = {The Warzone},
	author = {Amick, Aaron},
	urldate = {2024-10-13},
	date = {2020-11-27},
}

@article{malinowski_underwater_2001,
	title = {Underwater noise radiated by ships, their propulsion and auxiliary machinery, and propellers},
	volume = {4},
	url = {https://www.semanticscholar.org/paper/Underwater-noise-radiated-by-ships%2C-their-and-and-Malinowski-Gloza/a4120cd772ef8178efc1d28d489375277e182a95},
	abstract = {These underwater radiated noise and vibration measurements were conducted on a full-scale ship in August 2000. During the trails it was found that several spike noises are dominant. To find the location oj high vibration level places and its frequencies, and the machines, which generated high level point noise components, 4 accelerometers were fixed in the engine and auxiliary rooms .We were using this system to find the relationship between certain manoeuvres and the vibratlon level caused by them. Propellers and engines are usually the major sources of noise in ships but gearboxes can also be significant contributors. The way of mounting of the machines and the resulting vibration oj the hull are determining issues in the radiation ot underwater noise. Naval Test and Evaluation Acoustic Ranges contain an accurate radiated noise measurement system consisting of a bottom-mounted hydrophone array for sailing condition and a stationary range. The sophisticated digital narrow-band instruments and analogue recorders were used by us.},
	pages = {165--168},
	journaltitle = {Hydroacoustics},
	author = {Malinowski, S. J. and Gloza, I. and Domagalski, J.},
	urldate = {2024-09-09},
	date = {2001},
}

@incollection{hutchison_novel_2004,
	location = {Berlin, Heidelberg},
	title = {A Novel Modeling and Recognition Method for Underwater Sound Based on {HMT} in Wavelet Domain},
	volume = {3339},
	isbn = {978-3-540-24059-4 978-3-540-30549-1},
	url = {http://link.springer.com/10.1007/978-3-540-30549-1_30},
	pages = {332--343},
	booktitle = {{AI} 2004: Advances in Artificial Intelligence},
	publisher = {Springer Berlin Heidelberg},
	author = {Yue, Zhou and Wei, Kong and Qing, Xu},
	editor = {Webb, Geoffrey I. and Yu, Xinghuo},
	editorb = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard},
	editorbtype = {redactor},
	urldate = {2024-10-10},
	date = {2004},
	doi = {10.1007/978-3-540-30549-1_30},
	note = {Series Title: Lecture Notes in Computer Science},
}

@incollection{mantoro_underwater_2021,
	location = {Cham},
	title = {Underwater Acoustic Target Recognition with Fusion Feature},
	volume = {13108},
	isbn = {978-3-030-92184-2 978-3-030-92185-9},
	url = {https://link.springer.com/10.1007/978-3-030-92185-9_50},
	pages = {609--620},
	booktitle = {Neural Information Processing},
	publisher = {Springer International Publishing},
	author = {Qi, Pengyuan and Sun, Jianguo and Long, Yunfei and Zhang, Liguo and {Tianye}},
	editor = {Mantoro, Teddy and Lee, Minho and Ayu, Media Anugerah and Wong, Kok Wai and Hidayanto, Achmad Nizar},
	urldate = {2024-10-10},
	date = {2021},
	langid = {english},
	doi = {10.1007/978-3-030-92185-9_50},
	note = {Series Title: Lecture Notes in Computer Science},
}

@incollection{shao_recognition_2021,
	location = {Singapore},
	title = {Recognition of Underwater Acoustic Target Using Sub-pretrained Convolutional Neural Networks},
	volume = {761},
	isbn = {9789811616488 9789811616495},
	url = {https://link.springer.com/10.1007/978-981-16-1649-5_10},
	pages = {113--123},
	booktitle = {Proceedings of the 8th Conference on Sound and Music Technology},
	publisher = {Springer Singapore},
	author = {Pan, Andi and Chen, Xi and Li, Wei},
	editor = {Shao, Xi and Qian, Kun and Zhou, Li and Wang, Xin and Zhao, Ziping},
	urldate = {2024-10-10},
	date = {2021},
	langid = {english},
	doi = {10.1007/978-981-16-1649-5_10},
	note = {Series Title: Lecture Notes in Electrical Engineering},
}

@article{khalilabadi_underwater_2023,
	title = {Underwater Ship-radiated Acoustic Noise Recognition Based on Mel-Spectrogram and Convolutional Neural Network},
	volume = {8},
	url = {https://doi.org/10.22034/ijcoe.2023.166732},
	doi = {10.22034/ijcoe.2023.166732},
	number = {1},
	journaltitle = {International Journal Of Coastal, Offshore And Environmental Engineering},
	shortjournal = {{IJCOE}},
	author = {Khalilabadi, Mohammad Reza},
	urldate = {2024-10-09},
	date = {2023-02},
}

@incollection{ngatched_nkouatchah_detection_2023,
	location = {Cham},
	title = {Detection and Classification of Underwater Acoustic Events},
	volume = {459},
	isbn = {978-3-031-25270-9 978-3-031-25271-6},
	url = {https://link.springer.com/10.1007/978-3-031-25271-6_16},
	pages = {251--269},
	booktitle = {Pan-African Artificial Intelligence and Smart Systems},
	publisher = {Springer Nature Switzerland},
	author = {Kammegne, Caouis and Bayet, Theophile and Brochier, Timothee and Idy, Diop and Denis, Christophe and Tremblay, Yann},
	editor = {Ngatched Nkouatchah, Telex Magloire and Woungang, Isaac and Tapamo, Jules-Raymond and Viriri, Serestina},
	urldate = {2024-10-09},
	date = {2023},
	langid = {english},
	doi = {10.1007/978-3-031-25271-6_16},
	note = {Series Title: Lecture Notes of the Institute for Computer Sciences, Social Informatics and Telecommunications Engineering},
}

@thesis{cheng_deep_2024,
	title = {Deep Learning for Models for Underwater Ship Radiated Noise Classification},
	institution = {The University of Sydney},
	type = {Honours},
	author = {Cheng, Chris},
	date = {2024},
}

@incollection{de_moura_passive_2011,
	title = {Passive Sonar Signal Detection and Classification Based on Independent Component Analysis},
	isbn = {978-953-307-345-3},
	pages = {93--104},
	booktitle = {Sonar Systems},
	author = {de Moura, N. N. and de Seixas, J. M. and Ramos, Ricardo},
	date = {2011},
}

@thesis{can_classification_2016,
	location = {Turkey},
	title = {Classification of Vessel Acoustic Signatures Using Non-Linear Scattering Based Feature Extraction},
	url = {https://www.proquest.com/dissertations-theses/classification-vessel-acoustic-signatures-using/docview/2649751434/se-2?accountid=14757},
	abstract = {This thesis proposes a vessel recognition and classification system based on acoustic signatures. Conventionally, acoustic sounds are recognized by sonar operators who listen to audio signals received by ship sonars. The aim of this work is to replace this conventional human-based recognition system with an automatic feature-based classification system. Therefore, it can be regarded reasonable to adopt the speech recognition algorithms in classification of underwater acoustic signal recognition ({UASR}). The most widely used feature extraction methods of speech recognition are Linear Predictive Coding ({LPC}) and Mel Frequency Cepstral Coefficients ({MFCC}) and they are also used in {UASR}. In addition, the Scattering transform is used to obtain filter bank instead of mel-scale filter bank in {MFCC} algorithm. The scattering cascade decomposes an input signal into its wavelet modulus coeffcients and various non-linearities are used between wavelet stages. The new proposed method is labeled as Scattering Transform Cepstral Coefficients ({STCC}). Sensitivity of human hearing system is not the same in all frequency bands and mel-scale filter bank in {MFCC} is more sensitive to small changes in low frequencies than high frequencies. Therefore, number of {DWT} decomposition levels is increased in low frequencies to determine accurate representation and experimental results shows that non-uniform filter banks provide better success rates. Non-linear Teager energy and hyperbolic tangent operators are used to increase the performance of classification in proposed features extraction methods. Non-linear operators and scattering transforms are used for the first time in {UASR} to identify the acoustic sounds of the platforms. Teager Energy Operator ({TEO}) estimates the true energy of the source of a resonance signal. {TEO} based {MFCC}, being more robust in noisy conditions than conventional {MFCC}, provides a better estimation of the platform energy. Although {TEO} has positive effect on {MFCC}, it decreases the performance of {STCC}. Di erent non-linear tanh operator is also applied to {LPC}, {MFCC} and {STCC} algorithms and experimental results show that tanh operator increases the performance of the classification in all feature extraction methods. This analysis and implementation was carried out with datasets of 24 different vessel signals recordings that belong to 10 separate classes of vessels. Artificial Neural Networks ({ANN}) and Support Vector Machines ({SVM}) are used as classifiers. Performance of the proposed methods is compared and experimental results demonstrate that {STCC} have the best performance and tanh based {STCC} achieves highest success rate with 98.50\% accuracy in classification of vessel sounds.Alternate abstract:Bu tez gemilerin akustik izlerine dayanan gemi tanıma ve sınaflandırma sistemi önermektedir. Sonar operatörlerin, gemi sonarları tarafından algılanan akustik sesleri dinleyerek geleneksel yöntemlerle tanıma yapmaktadır. Bu çalışımanın amacı, insana dayanan tanıma sistemini otomatik bilgisayar tabanı sınıflandırma sistemi ile değiştirmektir. Bundan dolayı, konuşma tanıma algoritmalarındaki öenitelik vektörleri sualtı akustik sinyallerin tanımmasında da ({UASR}) kabul et- mek mantıklı bir düşünce olacaktır. Konaşma tanımada en yaygın kullanılan öenitelik vektör çıkurma algoritmaları Doğrusal Kestirimci Kodlama ({LPC}) ve Mel Frekans Kepstral katsayılarıdır ({MFCC}) ve ayrıca bu iki metot {UASR}'de de kullanılmıştır. Ek olarak, süzgeç bankasını elde etmek için {MFCC} algo- ritmasında balunan mel ölçekli süzgeç bankasa yerine Saçılma döniüişümüi kul- Lanalmıştır. Saçılma, sinyali ardı ardına aralarında doğrusal olmayan operatörlerin bulunduğu dalgacık dönüşümleriyle bölmüiş ve dalgacık katsayılarını elde etmiştir. Önerilen yeni metod Saçılma Döniüşümü Kepstral katsayıları ({STCC}) olarak isimlendirilmiştir. İnsanım duyma hassasiyeti bütün frekans bantlarında aynı değildir ve {MFCC} düşük frekanslardaki değişimlere yüksek frekansa göre daha hassastır. Bu nedenle daha doğru bir gösterim yapabilmek için düşük frekanslarda {DWT} saymı arttırarak daha çok böliinme işlemi yapılmıştır ve deneysel sonuçlar göstermiştir ki eşdağılım yapmayan sizgeç bankası daha iyi başarı göstermiştir. Önerilen öznitelik çıkarma metodlarında sınaflandırma performansını arttırmak için farklı doğrısal olmayan operatörler kullanılmaştır. Doğrısal olmayan op- eratörler ve saçılma dönüşümünün uygulanması akustik gürültü üreten platform- lan tanımada ilk kez kullanılacaktır. Teager enerji operatörüi ({TEO}) bulunan {MFCC}'nin gürültülü ortamlara daha dayanıklı olduğu ve platformların enerji- lerinin daha iyi tahmin edilmesini sağladığı görülmiüştür. {TEO}'nun {MFCC}'de positif etkisi olmasına rağmen {STCC}'de performansa düşürmüştür. Aynca farklı bir doğrusal olmayan tanh operatörü {LPC}, {MFOC} ve {STCC}'ye uygulanmış ve deneysel sonuçlar bu operatörün bütün öznitelik çıkarma metodlarında perfor- mansı arttırdığı gösterilmiştir. Analiz ve uygulama 10 farklı sanıfa ait 24 farklı gemi sesi kaydınm olduğu veri kümesi ile yürütülmüştür. Sınıflandırıcı olarak Ya- pay Sinir Ağı ({YSA}) ve Destekçi Vektör Makinası ({DVM}) kullanılmıştır. Onerilen metotların performansları karşılaştırılmıştır ve deneysel sonuçlar {STCC}'nin en iyi sınıflandırma performansına sahip olduğu kanıtlanmıştır ve tanh uygulanan {STOC}'nin gemi seslerini sınıflandırmada \%98,50 doğruluk ile en yüksek oranı başarmaştır.},
	pagetotal = {72},
	institution = {Bilkent Universitesi (Turkey)},
	type = {M.S.},
	author = {Can, Gökmen},
	editora = {Çetin, A. Enis},
	editoratype = {collaborator},
	date = {2016},
	note = {{ISBN}: 979-8-209-97269-3
Publication Title: {PQDT} - Global
29048293},
}

@thesis{applelid_classify_2019,
	title = {Classify different types of boat engine sounds with machine learning},
	url = {https://urn.kb.se/resolve?urn=urn:nbn:se:kth:diva-254645},
	abstract = {When a boat moves in water, it creates a sound with unique features which makes it possible to identify different boat types or even a specific boat. The ability to identify boats is important in the military sector for surveillance purposes.This thesis describes how different audio processing methods and machine learning approaches are implemented, tested and evaluated in order to create a prototype that identifies boats. A total of 87 boat sounds were used and processed in seven different ways. The machine learning approaches Dense Neural Network, Convolutional Neural Network and Recurrent Neural Network were implemented and trained with the processed audio files in order to identify different boat types. Different combinations of audio processing methods and machine learning approaches ability to classify different boat types, were tested with a stratified Kfold test.The result is a prototype with an audio processing method that divides an audio file to equally large segments. Each segment is converted to a logarithmic mel-scaled spectrogram and a delta feature is calculated and added as an extra dimension for each segment. A Convolutional Neural Network is trained with processed audio files and manages to distinguish different boat types with an accuracy of 75\%.},
	institution = {{KTH} Royal Institute of Technology},
	type = {Bachelor},
	author = {Applelid, Gunnar and Karlsson, Mikael},
	urldate = {2024-10-09},
	date = {2019},
}

@misc{long_fully_2014,
	title = {Fully Convolutional Networks for Semantic Segmentation},
	rights = {{arXiv}.org perpetual, non-exclusive license},
	url = {https://arxiv.org/abs/1411.4038},
	doi = {10.48550/ARXIV.1411.4038},
	abstract = {Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, exceed the state-of-the-art in semantic segmentation. Our key insight is to build "fully convolutional" networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks ({AlexNet}, the {VGG} net, and {GoogLeNet}) into fully convolutional networks and transfer their learned representations by fine-tuning to the segmentation task. We then define a novel architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. Our fully convolutional network achieves state-of-the-art segmentation of {PASCAL} {VOC} (20\% relative improvement to 62.2\% mean {IU} on 2012), {NYUDv}2, and {SIFT} Flow, while inference takes one third of a second for a typical image.},
	publisher = {{arXiv}},
	author = {Long, Jonathan and Shelhamer, Evan and Darrell, Trevor},
	urldate = {2024-09-23},
	date = {2014},
	note = {Version Number: 2},
}

@book{jackson_high-frequency_2007,
	location = {New York, {NY}},
	title = {High-Frequency Seafloor Acoustics},
	rights = {http://www.springer.com/tdm},
	url = {http://link.springer.com/10.1007/978-0-387-36945-7},
	publisher = {Springer New York},
	author = {Jackson, Darrell R. and Richardson, Michael D.},
	urldate = {2024-09-17},
	date = {2007},
	langid = {english},
	doi = {10.1007/978-0-387-36945-7},
}

@online{sinay_diving_2024,
	title = {Diving into the depths: Understanding underwater acoustics and its impact on marine life.},
	url = {https://sinay.ai/en/exploring-the-science-of-underwater-acoustics-how-sound-travels-beneath-the-waves/},
	shorttitle = {Diving into the depths},
	abstract = {Explore the depths of underwater acoustics and its influence on marine life. From sound propagation to marine technology, uncover the mysteries beneath the waves for sustainable ocean exploration and conservation.},
	titleaddon = {https://sinay.ai/},
	author = {{SINAY}},
	urldate = {2024-09-17},
	date = {2024-03-27},
	langid = {english},
	note = {Section: Acoustics},
}

@article{srivastava_dropout_2014,
	title = {Dropout: A Simple Way to Prevent Neural Networks from Overﬁtting},
	volume = {15},
	abstract = {Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overﬁtting is a serious problem in such networks. Large networks are also slow to use, making it diﬃcult to deal with overﬁtting by combining the predictions of many diﬀerent large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of diﬀerent “thinned” networks. At test time, it is easy to approximate the eﬀect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This signiﬁcantly reduces overﬁtting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classiﬁcation and computational biology, obtaining state-of-the-art results on many benchmark data sets.},
	pages = {1929--1958},
	number = {56},
	journaltitle = {Journal of Machine Learning Research},
	author = {Srivastava, Nitish and Hinton, Geoﬀrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
	date = {2014},
	langid = {english},
}

@thesis{muhaddisa_barat_ali_use_2015,
	title = {Use of dropouts and sparsity for regularisation of autoencoders in deep neural networks},
	institution = {Bilkent University},
	type = {Masters},
	author = {{Muhaddisa Barat Ali}},
	date = {2015-01},
}

@incollection{tacconi_multipath_1977,
	location = {Dordrecht},
	title = {Multipath Propagation and its Effects on Sonar Design and Performance in the Real Ocean},
	url = {http://link.springer.com/10.1007/978-94-010-1223-2_1},
	pages = {3--18},
	booktitle = {Aspects of Signal Processing},
	publisher = {Springer Netherlands},
	author = {Urick, R. J.},
	editor = {Tacconi, G.},
	urldate = {2024-09-12},
	date = {1977},
	doi = {10.1007/978-94-010-1223-2_1},
}

@online{national_oceanic_and_atmospheric_association_what_2024,
	title = {What is {SOFAR}?},
	url = {https://oceanservice.noaa.gov/facts/sofar.html},
	abstract = {{SOFAR} is an ocean 'channel' that allows sound to carry great distances.},
	author = {{National Oceanic and Atmospheric Association}},
	urldate = {2024-09-11},
	date = {2024-06-16},
}

@incollection{richardson_marine_1995,
	title = {Marine Mammal Sounds},
	isbn = {978-0-08-057303-8},
	url = {https://linkinghub.elsevier.com/retrieve/pii/B9780080573038500100},
	pages = {159--204},
	booktitle = {Marine Mammals and Noise},
	publisher = {Elsevier},
	author = {Richardson, W. John and Greene, Charles R. and Malme, Charles I. and Thomson, Denis H.},
	urldate = {2024-09-10},
	date = {1995},
	langid = {english},
	doi = {10.1016/B978-0-08-057303-8.50010-0},
}

@online{helgason_asdic_2011,
	title = {{ASDIC} / Sonar},
	url = {https://www.uboat.net/allies/technical/asdic.htm},
	author = {Helgason, Guðmundur},
	urldate = {2024-09-12},
	date = {2011-10-09},
}

@incollection{dixon_ward_musical_1970,
	title = {Musical Perception},
	volume = {1},
	pages = {438},
	booktitle = {Foundations of Modern Auditory Theory},
	publisher = {Academic Press},
	author = {Dixon Ward, W},
	date = {1970},
}

@book{tobias_foundations_1970,
	location = {New York},
	title = {Foundations of modern auditory theory},
	isbn = {978-0-12-691901-1},
	pagetotal = {2},
	publisher = {Academic Press},
	author = {Tobias, Jerry V.},
	date = {1970},
}

@book{rodriguez_fundamentals_2023,
	location = {Cham},
	title = {Fundamentals of Underwater Acoustics},
	rights = {https://www.springernature.com/gp/researchers/text-and-data-mining},
	url = {https://link.springer.com/10.1007/978-3-031-31319-6},
	publisher = {Springer Nature Switzerland},
	author = {Rodríguez, Orlando Camargo},
	urldate = {2024-09-11},
	date = {2023},
	langid = {english},
	doi = {10.1007/978-3-031-31319-6},
}

@book{ross_mechanics_1976,
	location = {New York},
	title = {Mechanics of underwater noise},
	publisher = {Pergamon Press},
	author = {Ross, Donald},
	date = {1976},
}

@book{urick_principles_1975,
	location = {New York},
	edition = {2. ed},
	title = {Principles of underwater sound},
	isbn = {978-0-07-066086-1},
	abstract = {Das "Standardwerk" zum Thema Wasserschall. Urick behandelt alle wichtigen Erscheinungen des Wasserschallś einschließlich Körperschall im Meer},
	pagetotal = {384},
	publisher = {{McGraw}-Hill},
	author = {Urick, Robert J.},
	date = {1975},
}

@book{cato_ultrasonic_1992,
	title = {Ultrasonic ambient noise in Australian shallow waters at frequencies up to 200 {kHz}},
	isbn = {0-646-10798-4},
	series = {{MRL} technical report},
	pagetotal = {27},
	number = {{MRL}-{TR}-91-23},
	author = {Cato, Douglas H. and Bell, Michael J.},
	date = {1992},
}

@incollection{siano_underwater_2021,
	title = {Underwater Ambient Noise},
	rights = {https://creativecommons.org/licenses/by/3.0/legalcode},
	isbn = {978-1-83968-239-1 978-1-83968-240-7},
	url = {https://www.intechopen.com/books/noise-and-environment/underwater-ambient-noise},
	abstract = {Underwater ambient noise is primarily a background noise which is a function of time, location, and depth. Background baseline of the noise in ocean is represented by ambient noise generated from the ocean surface due to wind and rain. This understanding pertained to ambient noise under various conditions will help in improving the signal-to-noise ratio ({SNR}) of marine instruments. It is of prime importance to detect the signals such as sound of a submarine or echo from a target surpassing this ambient noise. Ambient noise excludes all forms of self noise, such as the noise of current flow around the measurement hydrophone and its supporting structure. It should also exclude all forms of electrical noise. It is also defined as the residual noise that remains after all easily identifiable sound sources are eliminated. In the absence of sound from ships and marine life, underwater ambient noise levels ({NL}) are dependent mainly on wind speeds at frequencies between 100 Hz and 25 {KHz}.},
	booktitle = {Noise and Environment},
	publisher = {{IntechOpen}},
	author = {Baskar Veeriayan, Vijaya and V., Rajendran},
	editor = {Siano, Daniela and Elizabeth González, Alice},
	urldate = {2024-09-11},
	date = {2021-02-03},
	langid = {english},
	doi = {10.5772/intechopen.93057},
}

@book{bjorno_applied_2017,
	location = {Amsterdam, Netherlands},
	title = {Applied underwater acoustics},
	isbn = {978-0-12-811240-3},
	pagetotal = {964},
	publisher = {Elsevier},
	author = {Bjørnø, Leif and Neighbors, Thomas H. and Bradley, David},
	date = {2017},
	note = {{OCLC}: ocn987797700},
}

@book{hovem_marine_2012,
	location = {Los Altos Hills, California},
	title = {Marine acoustics: the physics of sound in underwater environments},
	isbn = {978-0-932146-65-6},
	shorttitle = {Marine acoustics},
	pagetotal = {641},
	publisher = {Peninsula Publishing},
	author = {Hovem, Jens M.},
	date = {2012},
}

@article{pricop_underwater_2010,
	title = {Underwater Radiated Noise of Ships' Machinery in Shallow Water},
	issn = {1792-4693},
	journaltitle = {Advanced Manufacturing Engineering, Quality and Production Systems},
	author = {Pricop, Mihail and Pazara, Tiberiu and Oncica, Valentin and Atodiresei, Dinu},
	date = {2010},
}

@article{zak_ships_2008,
	title = {Ships Classification Basing On Acoustic Signatures},
	volume = {4},
	issn = {1790-5052},
	pages = {137--149},
	number = {4},
	journaltitle = {{WSEAS} Transactions on Signal Processing},
	author = {Zak, Andrzej},
	date = {2008-04},
}

@article{russell_inductive_1991,
	title = {Inductive Learning by Machines},
	volume = {64},
	issn = {0031-8116},
	url = {https://www.jstor.org/stable/4320245},
	pages = {37--64},
	number = {1},
	journaltitle = {Philosophical Studies: An International Journal for Philosophy in the Analytic Tradition},
	author = {Russell, Stuart},
	urldate = {2024-09-09},
	date = {1991},
	note = {Publisher: Springer},
}

@incollection{montavon_practical_2012,
	location = {Berlin, Heidelberg},
	title = {A Practical Guide to Training Restricted Boltzmann Machines},
	volume = {7700},
	rights = {http://www.springer.com/tdm},
	url = {http://link.springer.com/10.1007/978-3-642-35289-8_32},
	pages = {599--619},
	booktitle = {Neural Networks: Tricks of the Trade},
	publisher = {Springer Berlin Heidelberg},
	author = {Hinton, Geoffrey E.},
	editor = {Montavon, Grégoire and Orr, Geneviève B. and Müller, Klaus-Robert},
	urldate = {2024-06-20},
	date = {2012},
	langid = {english},
	doi = {10.1007/978-3-642-35289-8_32},
	note = {Series Title: Lecture Notes in Computer Science},
	keywords = {Initial reading list, {RBM}},
}

@article{bahrami_sonar_2015,
	title = {Sonar Signal Classification using Neural Networks},
	volume = {12},
	pages = {129--133},
	number = {1},
	journaltitle = {International Journal of Computer Science Issues},
	shortjournal = {{IJCSI}},
	author = {Bahrami, Hossein and Talebiyan, Seyyed Reza},
	date = {2015-01},
}

@book{waite_sonar_2002,
	location = {Chichester},
	edition = {3rd ed},
	title = {Sonar for practising engineers},
	isbn = {978-0-471-49750-9},
	pagetotal = {298},
	publisher = {Wiley},
	author = {Waite, A. D.},
	date = {2002},
	note = {{OCLC}: ocm47271347},
	keywords = {Initial reading list},
}

@report{erbe_technical_2021,
	title = {Technical Report: Underwater noise signatures of ships in Australian waters},
	author = {Erbe, Christine and Duncan, Alec and Peel, David and Smith, Joshua N},
	date = {2021-04},
	langid = {english},
	keywords = {Initial reading list},
}

@article{dietterich_solving_1995,
	title = {Solving multiclass learning problems via error-correcting output codes},
	volume = {2},
	issn = {1076-9757},
	abstract = {Multiclass learning problems involve finding a definition for an unknown function f(x) whose range is a discrete set containing k {\textgreater} 2 values (i.e., k "classes"). The definition is acquired by studying collections of training examples of the form (xi, f(xi)). Existing approaches to multiclass learning problems include direct application of multiclass algorithms such as the decision-tree algorithms C4.5 and {CART}, application of binary concept learning algorithms to learn individual binary functions for each of the k classes, and application of binary concept learning algorithms with distributed output representations. This paper compares these three approaches to a new technique in which error-correcting codes are employed as a distributed output representation. We show that these output representations improve the generalization performance of both C4.5 and backpropagation on a wide range of multiclass learning tasks. We also demonstrate that this approach is robust with respect to changes in the size of the training sample, the assignment of distributed representations to particular classes, and the application of overfitting avoidance techniques such as decision-tree pruning. Finally, we show that--like the other methods--the error-correcting code technique can provide reliable class probability estimates. Taken together, these results demonstrate that error-correcting output codes provide a general-purpose method for improving the performance of inductive learning programs on multiclass problems.},
	pages = {263--286},
	number = {1},
	journaltitle = {Journal of Artificial Intelligence Research},
	shortjournal = {J. Artif. Int. Res.},
	author = {Dietterich, Thomas G. and Bakiri, Ghulum},
	date = {1995-01-01},
	keywords = {Initial reading list},
}

@article{durrant-whyte_simultaneous_2006,
	title = {Simultaneous Localisation and Mapping ({SLAM}): Part I The Essential Algorithms},
	volume = {13},
	issn = {1070-9932},
	abstract = {This tutorial provides an introduction to Simultaneous Localisation and Mapping ({SLAM}) and the extensive research on {SLAM} that has been undertaken over the past decade. {SLAM} is the process by which a mobile robot can build a map of an environment and at the same time use this map to compute it’s own location. The past decade has seen rapid and exciting progress in solving the {SLAM} problem together with many compelling implementations of {SLAM} methods. Part I of this tutorial (this paper), describes the probabilistic form of the {SLAM} problem, essential solution methods and signiﬁcant implementations. Part {II} of this tutorial will be concerned with recent advances in computational methods and new formulations of the {SLAM} problem for large scale and complex environments.},
	number = {2},
	journaltitle = {Robotics and Automation Magazine},
	author = {Durrant-Whyte, Hugh and Bailey, Tim},
	date = {2006-06},
	langid = {english},
	keywords = {Initial reading list},
}

@inproceedings{han_convolutional_2017,
	title = {Convolutional Neural Networks with Binaural Representations and Background Subtraction for Acoustic Scene Classification},
	url = {https://www.semanticscholar.org/paper/Convolutional-Neural-Networks-with-Binaural-and-for-Han-Park/a51094715013c4163256e4d1124cec2013601f8f},
	abstract = {In this paper, we demonstrate how we applied convolutional neural network for {DCASE} 2017 task 1, acoustic scene classification. We propose a variety of preprocessing methods that emphasise different acoustic characteristics such as binaural representations, harmonicpercussive source separation, and background subtraction. We also present a network structure designed for paired input to make the most of the spatial information contained in the stereo. The experimental results show that the proposed network structures and the preprocessing methods effectively learn acoustic characteristics from the audio recordings, and their ensemble model significantly reduces the error rate further, exhibiting an accuracy of 0.917 for 4-fold cross-validation on the development. The proposed system achieved second place in {DCASE} 2017 task 1 with an accuracy of 0.804 on the evaluation set.},
	eventtitle = {Workshop on Detection and Classification of Acoustic Scenes and Events},
	author = {Han, Yoonchang and Park, Jeongsoon and Lee, Kyogu},
	urldate = {2024-06-20},
	date = {2017},
	keywords = {Initial reading list},
}

@article{shridhar_comprehensive_2019,
	title = {A Comprehensive guide to Bayesian Convolutional Neural Network with Variational Inference},
	url = {https://www.semanticscholar.org/paper/A-Comprehensive-guide-to-Bayesian-Convolutional-Shridhar-Laumann/a962b134cc85fc15af2aca7c3cf8655b2ca70d94},
	abstract = {Artificial Neural Networks are connectionist systems that perform a given task by learning on examples without having prior knowledge about the task. This is done by finding an optimal point estimate for the weights in every node. Generally, the network using point estimates as weights perform well with large datasets, but they fail to express uncertainty in regions with little or no data, leading to overconfident decisions. 
In this paper, Bayesian Convolutional Neural Network ({BayesCNN}) using Variational Inference is proposed, that introduces probability distribution over the weights. Furthermore, the proposed {BayesCNN} architecture is applied to tasks like Image Classification, Image Super-Resolution and Generative Adversarial Networks. The results are compared to point-estimates based architectures on {MNIST}, {CIFAR}-10 and {CIFAR}-100 datasets for Image {CLassification} task, on {BSD}300 dataset for Image Super Resolution task and on {CIFAR}10 dataset again for Generative Adversarial Network task. 
{BayesCNN} is based on Bayes by Backprop which derives a variational approximation to the true posterior. We, therefore, introduce the idea of applying two convolutional operations, one for the mean and one for the variance. Our proposed method not only achieves performances equivalent to frequentist inference in identical architectures but also incorporate a measurement for uncertainties and regularisation. It further eliminates the use of dropout in the model. Moreover, we predict how certain the model prediction is based on the epistemic and aleatoric uncertainties and empirically show how the uncertainty can decrease, allowing the decisions made by the network to become more deterministic as the training accuracy increases. Finally, we propose ways to prune the Bayesian architecture and to make it more computational and time effective.},
	journaltitle = {{ArXiv}},
	author = {Shridhar, K. and Laumann, F. and Liwicki, M.},
	urldate = {2024-06-20},
	date = {2019-01-08},
	keywords = {Initial reading list},
}

@thesis{pfau_multi-label_2020,
	title = {Multi-Label Classification of Underwater Soundscapes using Deep Convolutional Neural Networks},
	url = {https://apps.dtic.mil/sti/citations/AD1127045},
	abstract = {The detection and classification of passive sonar acoustics is a challenging problem faced by surface, subsurface, and naval air assets. The potential benefit of machine learning systems to assist in this task is appealing. However, little work has been conducted to develop and test machine learning models for this type of data or task. This thesis presents a custom convolutional neural network ({CNN}) model designed specifically for underwater acoustic classification. This model is compared to several common {CNN} architectures on two datasets of hydrophone recordings of passing ships. These datasets are some of the largest datasets of ship recordings used for training {CNNs} to date, composed of over 4,000 hours of recordings and hundreds of unique ships. This thesis’s main contribution is in demonstrating multi- label classification on underwater ship acoustics where the proposed model achieved an average micro-F1 score of 0.97. The custom {CNN} shows marked improvement in performance over standard models in both multi-class and multi-label classification tasks. This work also presents research into the inclusion of synthetic ship sounds and their potential use in training classification models. This thesis demonstrates the capability of machine learning models to enhance human and unmanned systems operating in the undersea domain.},
	pagetotal = {61},
	institution = {Naval Postgraduate School},
	type = {Master's thesis},
	author = {Pfau, Andrew M.},
	date = {2020-12},
	keywords = {Initial reading list},
}
